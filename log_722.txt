{
  "continuation_token": null,
  "count": 2708,
  "value": [
    "2025-11-25T22:38:18.3429012Z ##[section]Starting: Unit Test",
    "2025-11-25T22:38:18.3436294Z ==============================================================================",
    "2025-11-25T22:38:18.3436705Z Task         : Azure CLI",
    "2025-11-25T22:38:18.3436948Z Description  : Run Azure CLI commands against an Azure subscription in a PowerShell Core/Shell script when running on Linux agent or PowerShell/PowerShell Core/Batch script when running on Windows agent.",
    "2025-11-25T22:38:18.3437338Z Version      : 2.264.0",
    "2025-11-25T22:38:18.3437558Z Author       : Microsoft Corporation",
    "2025-11-25T22:38:18.3437789Z Help         : https://docs.microsoft.com/azure/devops/pipelines/tasks/deploy/azure-cli",
    "2025-11-25T22:38:18.3438049Z ==============================================================================",
    "2025-11-25T22:38:18.6642165Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az version",
    "2025-11-25T22:38:18.9135171Z {",
    "2025-11-25T22:38:18.9136618Z   \"azure-cli\": \"2.60.0\",",
    "2025-11-25T22:38:18.9137679Z   \"azure-cli-core\": \"2.60.0\",",
    "2025-11-25T22:38:18.9138431Z   \"azure-cli-telemetry\": \"1.1.0\",",
    "2025-11-25T22:38:18.9139114Z   \"extensions\": {",
    "2025-11-25T22:38:18.9139765Z     \"azure-devops\": \"1.0.2\"",
    "2025-11-25T22:38:18.9140396Z   }",
    "2025-11-25T22:38:18.9141024Z }",
    "2025-11-25T22:38:18.9167405Z Setting AZURE_CONFIG_DIR env variable to: /home/vsts/work/_temp/.azclitask",
    "2025-11-25T22:38:18.9177074Z Setting active cloud to: AzureCloud",
    "2025-11-25T22:38:18.9182260Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az cloud set -n AzureCloud",
    "2025-11-25T22:38:19.7077318Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az login --service-principal -u *** --tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 --allow-no-subscriptions --federated-token ***",
    "2025-11-25T22:38:20.4172480Z [",
    "2025-11-25T22:38:20.4173625Z   {",
    "2025-11-25T22:38:20.4194835Z     \"cloudName\": \"AzureCloud\",",
    "2025-11-25T22:38:20.4195386Z     \"homeTenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:38:20.4195810Z     \"id\": \"e342c2c0-f844-4b18-9208-52c8c234c30e\",",
    "2025-11-25T22:38:20.4196142Z     \"isDefault\": true,",
    "2025-11-25T22:38:20.4196481Z     \"managedByTenants\": [",
    "2025-11-25T22:38:20.4196751Z       {",
    "2025-11-25T22:38:20.4197053Z         \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"",
    "2025-11-25T22:38:20.4197347Z       }",
    "2025-11-25T22:38:20.4197588Z     ],",
    "2025-11-25T22:38:20.4197870Z     \"name\": \"Synapse_OSS_ML_DevTest_001\",",
    "2025-11-25T22:38:20.4198155Z     \"state\": \"Enabled\",",
    "2025-11-25T22:38:20.4198467Z     \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:38:20.4198761Z     \"user\": {",
    "2025-11-25T22:38:20.4199156Z       \"name\": \"***\",",
    "2025-11-25T22:38:20.4199450Z       \"type\": \"servicePrincipal\"",
    "2025-11-25T22:38:20.4199728Z     }",
    "2025-11-25T22:38:20.4199965Z   }",
    "2025-11-25T22:38:20.4200187Z ]",
    "2025-11-25T22:38:20.4200532Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account set --subscription e342c2c0-f844-4b18-9208-52c8c234c30e",
    "2025-11-25T22:38:21.2852496Z [command]/usr/bin/bash /home/vsts/work/_temp/azureclitaskscript1764110298660.sh",
    "2025-11-25T22:38:23.2670910Z [info] welcome to sbt 1.10.11 (Eclipse Adoptium Java 17.0.17)",
    "2025-11-25T22:38:24.4995542Z [info] loading settings for project s-build from assembly.sbt, build.sbt, plugins.sbt...",
    "2025-11-25T22:38:25.7708397Z [info] loading project definition from /home/vsts/work/1/s/project",
    "2025-11-25T22:38:28.3962076Z [info] loading settings for project root from build.sbt, sonatype.sbt...",
    "2025-11-25T22:38:29.3827640Z [warn] Secret pgp-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:38:29.3828462Z [warn] Secret pgp-private not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:38:29.3828946Z [warn] Secret pgp-public not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:38:30.3150283Z [info] set current project to synapseml (in build file:/home/vsts/work/1/s/)",
    "2025-11-25T22:38:30.7902117Z [warn] Secret nexus-un not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:38:30.7903524Z [warn] Secret nexus-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:38:30.7905400Z [warn] Secret ado-feed-token not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:38:37.9019544Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:38:37.9065613Z [info] No tests to run for core / Test / testOnly",
    "2025-11-25T22:38:37.9817022Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:38:37.9818448Z [info] No tests to run for lightgbm / Test / testOnly",
    "2025-11-25T22:38:37.9819024Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:38:37.9819409Z [info] No tests to run for vw / Test / testOnly",
    "2025-11-25T22:38:39.4588192Z [info] AzMapsSearchAddressSuite:",
    "2025-11-25T22:38:41.3841664Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties",
    "2025-11-25T22:38:41.4024822Z 25/11/25 22:38:41 INFO AddressGeocoder: {\"protocolVersion\":\"0.0.1\",\"method\":\"constructor\",\"libraryName\":\"SynapseML\",\"className\":\"class com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"AddressGeocoder_5fdcd1c43734\"}",
    "2025-11-25T22:38:41.8966465Z [info] fetching secret: azuremaps-api-key from e342c2c0-f844-4b18-9208-52c8c234c30e",
    "2025-11-25T22:38:42.9616097Z 25/11/25 22:38:42 INFO FixedMiniBatchTransformer: {\"protocolVersion\":\"0.0.1\",\"method\":\"constructor\",\"libraryName\":\"SynapseML\",\"className\":\"class com.microsoft.azure.synapse.ml.stages.FixedMiniBatchTransformer\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"FixedMiniBatchTransformer_36180878323a\"}",
    "2025-11-25T22:38:43.3218395Z 25/11/25 22:38:43 INFO SparkContext: Running Spark version 4.0.1",
    "2025-11-25T22:38:43.3221933Z 25/11/25 22:38:43 INFO SparkContext: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:38:43.3229793Z 25/11/25 22:38:43 INFO SparkContext: Java version 17.0.17",
    "2025-11-25T22:38:43.5353704Z 25/11/25 22:38:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable",
    "2025-11-25T22:38:43.6058980Z 25/11/25 22:38:43 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:38:43.6085548Z 25/11/25 22:38:43 INFO ResourceUtils: No custom resources configured for spark.driver.",
    "2025-11-25T22:38:43.6086930Z 25/11/25 22:38:43 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:38:43.6102772Z 25/11/25 22:38:43 INFO SparkContext: Submitted application: com.microsoft.azure.synapse.ml.core.test.base.TestBase$@43638972",
    "2025-11-25T22:38:43.6180405Z 25/11/25 22:38:43 INFO SparkContext: Spark configuration:",
    "2025-11-25T22:38:43.6182072Z spark.app.name=com.microsoft.azure.synapse.ml.core.test.base.TestBase$@43638972",
    "2025-11-25T22:38:43.6183056Z spark.app.startTime=1764110323312",
    "2025-11-25T22:38:43.6185005Z spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:38:43.6186652Z spark.driver.maxResultSize=6g",
    "2025-11-25T22:38:43.6187831Z spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:38:43.6189599Z spark.hadoop.fs.s3a.vectored.read.max.merged.size=2M",
    "2025-11-25T22:38:43.6190161Z spark.hadoop.fs.s3a.vectored.read.min.seek.size=128K",
    "2025-11-25T22:38:43.6190475Z spark.logConf=true",
    "2025-11-25T22:38:43.6190740Z spark.master=local[*]",
    "2025-11-25T22:38:43.6191011Z spark.sql.crossJoin.enabled=true",
    "2025-11-25T22:38:43.6191294Z spark.sql.shuffle.partitions=20",
    "2025-11-25T22:38:43.6191604Z spark.sql.warehouse.dir=file:/home/vsts/work/1/s/cognitive/spark-warehouse",
    "2025-11-25T22:38:43.6539024Z 25/11/25 22:38:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)",
    "2025-11-25T22:38:43.6571666Z 25/11/25 22:38:43 INFO ResourceProfile: Limiting resource is cpu",
    "2025-11-25T22:38:43.6590871Z 25/11/25 22:38:43 INFO ResourceProfileManager: Added ResourceProfile id: 0",
    "2025-11-25T22:38:43.7099119Z 25/11/25 22:38:43 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:38:43.7109454Z 25/11/25 22:38:43 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:38:43.7114791Z 25/11/25 22:38:43 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:38:43.7119448Z 25/11/25 22:38:43 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:38:43.7135664Z 25/11/25 22:38:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:38:43.9867920Z 25/11/25 22:38:43 INFO Utils: Successfully started service 'sparkDriver' on port 44485.",
    "2025-11-25T22:38:44.0119670Z 25/11/25 22:38:44 INFO SparkEnv: Registering MapOutputTracker",
    "2025-11-25T22:38:44.0257087Z 25/11/25 22:38:44 INFO SparkEnv: Registering BlockManagerMaster",
    "2025-11-25T22:38:44.0419145Z 25/11/25 22:38:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information",
    "2025-11-25T22:38:44.0436996Z 25/11/25 22:38:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up",
    "2025-11-25T22:38:44.0476535Z 25/11/25 22:38:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat",
    "2025-11-25T22:38:44.0714339Z 25/11/25 22:38:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-76ec03aa-b40d-4267-8ad5-60fed15351d1",
    "2025-11-25T22:38:44.1167028Z 25/11/25 22:38:44 INFO SparkEnv: Registering OutputCommitCoordinator",
    "2025-11-25T22:38:44.2388041Z 25/11/25 22:38:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI",
    "2025-11-25T22:38:44.3200475Z 25/11/25 22:38:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.",
    "2025-11-25T22:38:44.4113448Z 25/11/25 22:38:44 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:38:44.4115019Z 25/11/25 22:38:44 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:38:44.4118340Z 25/11/25 22:38:44 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:38:44.4118984Z 25/11/25 22:38:44 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:38:44.4136373Z 25/11/25 22:38:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:38:44.5634882Z 25/11/25 22:38:44 INFO Executor: Starting executor ID driver on host runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net",
    "2025-11-25T22:38:44.5644794Z 25/11/25 22:38:44 INFO Executor: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:38:44.5653337Z 25/11/25 22:38:44 INFO Executor: Java version 17.0.17",
    "2025-11-25T22:38:44.5856037Z 25/11/25 22:38:44 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''",
    "2025-11-25T22:38:44.5867091Z 25/11/25 22:38:44 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@66680b20 for default.",
    "2025-11-25T22:38:44.6153762Z 25/11/25 22:38:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46747.",
    "2025-11-25T22:38:44.6240661Z 25/11/25 22:38:44 INFO NettyBlockTransferService: Server created on runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net:46747",
    "2025-11-25T22:38:44.6286229Z 25/11/25 22:38:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy",
    "2025-11-25T22:38:44.6534990Z 25/11/25 22:38:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 46747, None)",
    "2025-11-25T22:38:44.6612416Z 25/11/25 22:38:44 INFO BlockManagerMasterEndpoint: Registering block manager runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net:46747 with 1012.8 MiB RAM, BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 46747, None)",
    "2025-11-25T22:38:44.6641572Z 25/11/25 22:38:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 46747, None)",
    "2025-11-25T22:38:44.6654674Z 25/11/25 22:38:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 46747, None)",
    "2025-11-25T22:38:54.8186156Z 25/11/25 22:38:54 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/batch/544d3279-41bf-411d-bce1-bf0e389d3b8a?api-version=1.0",
    "2025-11-25T22:38:54.8192966Z 25/11/25 22:38:54 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/batch/2e4515fc-e70e-49a2-9f57-92faeb0c51d0?api-version=1.0",
    "2025-11-25T22:38:54.8194814Z 25/11/25 22:38:54 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)",
    "2025-11-25T22:38:54.8195535Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:54.8196243Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:54.8197055Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:54.8197804Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8198492Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:54.8199265Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:54.8199933Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:54.8200541Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:54.8201150Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:54.8201832Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:54.8202901Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8203570Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:54.8204404Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8205006Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8205630Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8206220Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8206937Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8209281Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:54.8209844Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:54.8210369Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8210945Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:54.8211425Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:54.8211859Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:54.8212378Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:54.8212960Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:54.8213530Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:54.8214071Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8214709Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8215137Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8215620Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8216119Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8216771Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8217337Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:54.8560179Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8560716Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8561235Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8561782Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:54.8562357Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:54.8562913Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:54.8563443Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:54.8563920Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:54.8564546Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:54.8565085Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:54.8565648Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:54.8566594Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:54.8567149Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:54.8567760Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:54.8568383Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:54.8568955Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:54.8569497Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:54.8570082Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:54.8570681Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:54.8571465Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:54.8571955Z 25/11/25 22:38:54 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 3)",
    "2025-11-25T22:38:54.8572417Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:54.8572929Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:54.8573576Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:54.8574361Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8575002Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:54.8575708Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:54.8576346Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:54.8576878Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:54.8577448Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:54.8578119Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:54.8578765Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8579446Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:54.8580093Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8580650Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8581190Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8581765Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8582382Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8583007Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:54.8583566Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:54.8584345Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8584999Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:54.8585592Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:54.8586099Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:54.8586712Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:54.8587344Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:54.8588100Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:54.8588661Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8589191Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8589663Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8590224Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8590826Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8591510Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8592370Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:54.8592942Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8593552Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8594381Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8595110Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:54.8595693Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:54.8596256Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:54.8596825Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:54.8597413Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:54.8597929Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:54.8598435Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:54.8598990Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:54.8599482Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:54.8599996Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:54.8600578Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:54.8601150Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:54.8601725Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:54.8602228Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:54.8602814Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:54.8603413Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:54.8603946Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:54.8604801Z 25/11/25 22:38:54 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 3) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:54.8605507Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:54.8606131Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:54.8606751Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8607426Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:54.8608293Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:54.8608959Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:54.8609458Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:54.8610058Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:54.8610704Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:54.8611365Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8612044Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:54.8612867Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8613429Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8614022Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8614743Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8615371Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8615955Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:54.8616476Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:54.8617012Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8617656Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:54.8618229Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:54.8618738Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:54.8619379Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:54.8620039Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:54.8620748Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:54.8621361Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8621903Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8622407Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8622881Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8623444Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8624238Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8624903Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:54.8625474Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8626079Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8626779Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8627504Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:54.8628273Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:54.8628762Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:54.8629300Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:54.8629787Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:54.8630265Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:54.8630763Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:54.8631335Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:54.8631780Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:54.8632181Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:54.8632819Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:54.8633324Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:54.8633770Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:54.8634382Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:54.8634871Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:54.8635335Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:54.8635742Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:54.8635929Z ",
    "2025-11-25T22:38:54.8636206Z 25/11/25 22:38:54 ERROR TaskSetManager: Task 1 in stage 2.0 failed 1 times; aborting job",
    "2025-11-25T22:38:54.8636580Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:38:54.8637171Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2.0 (TID 3) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:54.8637925Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:54.8638520Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:54.8639079Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8639645Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:54.8640242Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:54.8640738Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:54.8641191Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:54.8641712Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:54.8642259Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:54.8642799Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8643366Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:54.8643908Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8896908Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8897601Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:54.8898514Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:54.8899106Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8899708Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:54.8900230Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:54.8900741Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:54.8901329Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:54.8901849Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:54.8902327Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:54.8903192Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:54.8903878Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:54.8904807Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:54.8905420Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8905960Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8906509Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:54.8907085Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8907717Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8908453Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8909139Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:54.8909734Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:54.8910315Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:54.8910966Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:54.8911656Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:54.8912177Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:54.8912711Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:54.8913254Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:54.8913745Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:54.8944591Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:54.8945238Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:54.8945796Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:54.8946359Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:54.8946895Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:54.8947474Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:54.8948162Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:54.8948956Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:54.8949548Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:54.8950183Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:54.8950782Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:54.8951353Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:54.8951775Z [info] ",
    "2025-11-25T22:38:54.8952123Z [info] Driver stacktrace:",
    "2025-11-25T22:38:54.8952625Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:38:54.8953139Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:38:54.8953757Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:38:54.8954473Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:38:54.8954945Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:38:54.8955377Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:38:54.8955884Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:54.8956396Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:54.8956866Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:38:54.8957303Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:54.8957661Z [info]   ...",
    "2025-11-25T22:38:54.8957968Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:54.8958441Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:54.8958981Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:54.8959524Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8960215Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:54.8960925Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:54.8961568Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:54.8962103Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:54.8962718Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:54.8963387Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:54.8963997Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:54.8984978Z [info]   ...",
    "2025-11-25T22:38:54.8985405Z [info] + Test Serialization Fuzzing took 15.238s ",
    "2025-11-25T22:38:55.8188365Z [info] - Experiment Fuzzing",
    "2025-11-25T22:38:55.8190016Z [info] + Test Experiment Fuzzing took 0.317s ",
    "2025-11-25T22:38:55.8190656Z Testing parameter AADToken",
    "2025-11-25T22:38:55.8191329Z 25/11/25 22:38:55 WARN DefaultParamInfo: unsupported type AddressGeocoder_5fdcd1c43734__AADToken",
    "2025-11-25T22:38:55.8191980Z Could not test Service parameter value API  AADToken",
    "2025-11-25T22:38:55.8192565Z Testing parameter address",
    "2025-11-25T22:38:55.8193149Z Could not test Service parameter value API  address",
    "2025-11-25T22:38:55.8194311Z Testing parameter backoffs",
    "2025-11-25T22:38:55.8195851Z Testing parameter concurrency",
    "2025-11-25T22:38:55.8196311Z Testing parameter concurrentTimeout",
    "2025-11-25T22:38:55.8196735Z Could not test parameter concurrentTimeout",
    "2025-11-25T22:38:55.8197139Z Testing parameter errorCol",
    "2025-11-25T22:38:55.8197559Z Testing parameter initialPollingDelay",
    "2025-11-25T22:38:55.8198264Z Testing parameter maxPollingRetries",
    "2025-11-25T22:38:55.8198727Z Testing parameter outputCol",
    "2025-11-25T22:38:55.8199129Z Testing parameter pollingDelay",
    "2025-11-25T22:38:55.8199537Z Testing parameter subscriptionKey",
    "2025-11-25T22:38:55.8199962Z Testing parameter suppressMaxRetriesException",
    "2025-11-25T22:38:55.8200387Z Testing parameter timeout",
    "2025-11-25T22:38:55.8200765Z Testing parameter url",
    "2025-11-25T22:38:55.8201170Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:38:55.8201873Z [info] + Test Getters and Setters work as anticipated took 0.052s ",
    "2025-11-25T22:38:55.8202494Z 25/11/25 22:38:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.",
    "2025-11-25T22:38:56.9944315Z 25/11/25 22:38:56 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/batch/9fe6a7b6-2672-4775-a46f-3a9ea54a738a?api-version=1.0",
    "2025-11-25T22:38:56.9963398Z 25/11/25 22:38:56 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 4)",
    "2025-11-25T22:38:56.9964375Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:56.9965059Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:56.9965767Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:56.9966447Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:56.9967164Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:56.9967866Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:56.9968495Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:56.9969041Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:56.9969650Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:56.9977740Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:56.9978340Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:56.9978911Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:56.9979449Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:56.9979882Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:56.9980306Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:56.9980727Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:56.9981183Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:56.9981644Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:56.9982041Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:56.9982454Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:56.9982937Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:56.9983670Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:56.9984064Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:56.9984761Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:56.9985253Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:56.9985759Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:56.9986206Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:56.9986571Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:56.9986934Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:56.9987494Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:56.9987953Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:56.9988493Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:56.9989006Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:56.9989380Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:56.9989751Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:56.9990116Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:38:56.9990478Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:56.9990889Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:56.9991339Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:56.9991882Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:56.9992415Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:56.9992847Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:56.9993256Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:56.9993669Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:56.9994043Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:56.9994581Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:56.9994960Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:56.9995352Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:56.9995727Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:56.9996115Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:56.9996536Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:56.9996961Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:56.9997353Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:56.9997726Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:56.9998129Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:56.9998557Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:56.9999052Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:57.0042055Z 25/11/25 22:38:57 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 4) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:57.0043790Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:57.0044652Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:57.0045279Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:57.0045888Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:57.0046649Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:57.0047410Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:57.0047891Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:57.0053499Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:57.0054398Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:57.0055066Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:57.0055718Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:57.0056349Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:57.0057055Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:57.0058386Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:57.0059105Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:57.0060162Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:57.0060806Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:57.0061369Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:57.0061880Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:57.0062446Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:57.0063239Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:57.0063750Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:57.0064520Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:57.0065139Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:57.0065727Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:57.0073903Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:57.0074552Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:57.0074919Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:57.0075318Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:57.0075754Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:57.0076278Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:57.0076924Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0077281Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0077620Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0077971Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:38:57.0078314Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0078695Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:57.0079094Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:57.0079593Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:57.0080198Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:57.0080596Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:57.0080996Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:57.0081409Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:57.0081785Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:57.0082138Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:57.0082507Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:57.0082895Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:57.0083256Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:57.0083640Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:57.0084059Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:57.0084653Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:57.0085058Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:57.0085444Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:57.0085863Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:57.0086301Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:57.0086682Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:57.0086851Z ",
    "2025-11-25T22:38:57.0115063Z 25/11/25 22:38:57 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job",
    "2025-11-25T22:38:57.0145384Z [info] - Basic Batch Geocode Usage *** FAILED ***",
    "2025-11-25T22:38:57.0147453Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 4) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:57.0149917Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:57.0150494Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:57.0151014Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:57.0151540Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:57.0152109Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:57.0152770Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:57.0153176Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:57.0153628Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:57.0154314Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:57.0154851Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:57.0155404Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:57.0156030Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:57.0156477Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:57.0156903Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:57.0157336Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:57.0157809Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:57.0158286Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:57.0158699Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:57.0159178Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:57.0159678Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:57.0160109Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:57.0160512Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:57.0160988Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:57.0161492Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:57.0162016Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:57.0162481Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:57.0162865Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:57.0163243Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:57.0163665Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:57.0214440Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:57.0215321Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:57.0215927Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0216352Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0216792Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0217276Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:38:57.0217725Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:57.0218208Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:57.0218937Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:57.0219555Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:57.0220169Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:57.0220653Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:57.0221132Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:57.0221594Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:57.0222018Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:57.0222567Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:57.0222975Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:57.0223426Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:57.0223853Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:57.0224516Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:57.0224980Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:57.0225408Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:57.0225796Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:57.0226165Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:57.0226694Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:57.0227161Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:57.0227547Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:57.0227821Z [info] ",
    "2025-11-25T22:38:57.0228051Z [info] Driver stacktrace:",
    "2025-11-25T22:38:57.0228415Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:38:57.0228811Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:38:57.0229198Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:38:57.0229669Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:38:57.0230084Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:38:57.0284907Z Alert Provided - Suite AzMapsSearchAddressSuite took 17.464s",
    "2025-11-25T22:38:57.0324735Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:38:57.0352968Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:57.0353807Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:57.0354616Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:38:57.0355210Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:57.0355746Z [info]   ...",
    "2025-11-25T22:38:57.0356186Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:57.0356799Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:57.0357500Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:57.0358185Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:38:57.0359179Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:57.0359866Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:57.0360538Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:57.0361114Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:57.0361780Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:57.0362531Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:57.0363505Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:38:57.0364227Z [info]   ...",
    "2025-11-25T22:38:57.0364675Z [info] + Test Basic Batch Geocode Usage took 1.857s ",
    "2025-11-25T22:38:57.1786025Z [info] AzMapsSearchReverseAddressSuite:",
    "2025-11-25T22:38:58.9042076Z 25/11/25 22:38:58 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/878a2114-85ef-49ed-bd45-c89875c354dd?api-version=1.0",
    "2025-11-25T22:38:58.9076566Z 25/11/25 22:38:58 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 7)",
    "2025-11-25T22:38:58.9077867Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:58.9078628Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:58.9079293Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:58.9079909Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9080491Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:58.9081116Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:58.9081633Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:58.9082093Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:58.9082616Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:58.9083200Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:58.9083735Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9084477Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:58.9085593Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9086133Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9086687Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9087182Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9087719Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9088283Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:58.9088792Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:58.9089296Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9090332Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:58.9090864Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:58.9091382Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:58.9091943Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:58.9092552Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:58.9093167Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:58.9093748Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9118467Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9119327Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9119811Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9120303Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9120973Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9121617Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:58.9122175Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9122783Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9123511Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9124331Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:58.9124825Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:58.9125279Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:58.9125741Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:58.9126174Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:58.9126573Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:58.9126993Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:58.9127417Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:58.9127904Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:58.9128386Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:58.9128966Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:58.9129562Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:58.9130085Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:58.9130611Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:58.9131189Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:58.9131757Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:58.9132300Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:58.9133009Z 25/11/25 22:38:58 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 7) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:58.9133895Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:58.9134645Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:58.9135247Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9135855Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:58.9136482Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:58.9137064Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:58.9137561Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:58.9138261Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:58.9138864Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:58.9139457Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9140083Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:58.9140678Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9141192Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9141691Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9142198Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9142759Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9143337Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:58.9143845Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:58.9144507Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9145119Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:58.9145632Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:58.9146089Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:58.9146603Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:58.9147134Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:58.9147684Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:58.9148306Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9148795Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9149248Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9149748Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9150276Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9150912Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9151503Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:58.9152024Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9152768Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9153444Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9154060Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:58.9207008Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:58.9207496Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:58.9207912Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:58.9208326Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:58.9209007Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:58.9209382Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:58.9209819Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:58.9210234Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:58.9210640Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:58.9211057Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:58.9211468Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:58.9211874Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:58.9212278Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:58.9212723Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:58.9213207Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:58.9213612Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:58.9213793Z ",
    "2025-11-25T22:38:58.9214309Z 25/11/25 22:38:58 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job",
    "2025-11-25T22:38:58.9226304Z 25/11/25 22:38:58 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/a968b31a-394a-4863-a635-17fafa4b9f57?api-version=1.0",
    "2025-11-25T22:38:58.9226903Z 25/11/25 22:38:58 ERROR Executor: Exception in task 1.0 in stage 6.0 (TID 8)",
    "2025-11-25T22:38:58.9227275Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:58.9227712Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:58.9228257Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:58.9228805Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9229367Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:58.9229938Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:58.9230426Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:58.9230839Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:58.9231290Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:58.9231713Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:58.9232189Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9232792Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:58.9233667Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9252456Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9253157Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9253688Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9254402Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9254942Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:58.9255385Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:58.9256041Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9256606Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:58.9257040Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:58.9257461Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:58.9257979Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:58.9258503Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:58.9259075Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:58.9259578Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9259987Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9260409Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9260883Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9261378Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9262055Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9262667Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:58.9263170Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9263750Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9294776Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9295553Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:58.9296043Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:58.9296480Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:58.9296940Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:58.9297385Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:58.9297782Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:58.9298200Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:58.9298634Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:58.9299042Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:58.9299470Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:58.9300105Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:58.9300560Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:58.9301008Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:58.9301416Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:58.9301871Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:58.9302360Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:58.9302789Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:58.9324376Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:38:58.9731772Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 7) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:58.9762159Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:58.9763410Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:58.9764370Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9765276Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:58.9766159Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:58.9767005Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:58.9767761Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:58.9768560Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:58.9769613Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:58.9770452Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9771429Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:38:58.9772323Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9773131Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9773929Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:38:58.9848766Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:38:58.9850359Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9851452Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:38:58.9852381Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:38:58.9853294Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:38:58.9854534Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:38:58.9855607Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:38:58.9856675Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:38:58.9858129Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:38:58.9859297Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:38:58.9860448Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:38:58.9861485Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9862430Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9863592Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:38:58.9864852Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9866171Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9867330Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9868440Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:38:58.9872122Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:38:58.9878588Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:38:58.9879941Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:38:58.9895611Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:38:58.9896870Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:38:58.9898090Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:38:58.9899234Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:38:58.9934770Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:38:58.9935817Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:38:58.9936694Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:38:58.9937547Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:38:58.9938381Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:38:58.9939222Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:38:58.9940481Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:38:58.9941408Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:38:58.9942251Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:38:58.9943086Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:38:58.9943922Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:38:58.9945089Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:38:58.9945930Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:38:58.9946640Z [info] ",
    "2025-11-25T22:38:58.9947322Z [info] Driver stacktrace:",
    "2025-11-25T22:38:58.9948108Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:38:58.9948909Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:38:58.9949780Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:38:58.9950878Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:38:58.9951737Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:38:58.9952575Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:38:58.9953444Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:58.9954623Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:58.9955827Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:38:58.9956926Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:38:58.9958061Z [info]   ...",
    "2025-11-25T22:38:58.9958915Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:38:58.9960163Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:38:58.9961250Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:38:58.9962362Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:38:58.9963432Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:38:59.0004904Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:38:59.0006153Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:38:59.0007009Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:38:59.0007923Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:38:59.0009046Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:38:59.0010142Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:38:59.0011197Z [info]   ...",
    "2025-11-25T22:38:59.0012151Z [info] + Test Serialization Fuzzing took 1.884s ",
    "2025-11-25T22:38:59.3761386Z [info] - Experiment Fuzzing",
    "2025-11-25T22:38:59.3762493Z [info] + Test Experiment Fuzzing took 0.447s ",
    "2025-11-25T22:38:59.3776358Z Testing parameter AADToken",
    "2025-11-25T22:38:59.3787174Z Could not test Service parameter value API  AADToken",
    "2025-11-25T22:38:59.3790211Z Testing parameter backoffs",
    "2025-11-25T22:38:59.3793410Z 25/11/25 22:38:59 WARN DefaultParamInfo: unsupported type ReverseAddressGeocoder_53350f46c518__AADToken",
    "2025-11-25T22:38:59.3798814Z Testing parameter concurrency",
    "2025-11-25T22:38:59.3803965Z Testing parameter concurrentTimeout",
    "2025-11-25T22:38:59.3809659Z Could not test parameter concurrentTimeout",
    "2025-11-25T22:38:59.3812769Z Testing parameter errorCol",
    "2025-11-25T22:38:59.3817789Z Testing parameter initialPollingDelay",
    "2025-11-25T22:38:59.3826173Z Testing parameter latitude",
    "2025-11-25T22:38:59.3830764Z Could not test Service parameter value API  latitude",
    "2025-11-25T22:38:59.3833797Z Testing parameter longitude",
    "2025-11-25T22:38:59.3840962Z Could not test Service parameter value API  longitude",
    "2025-11-25T22:38:59.3856479Z Testing parameter maxPollingRetries",
    "2025-11-25T22:38:59.3857194Z Testing parameter outputCol",
    "2025-11-25T22:38:59.3857927Z Testing parameter pollingDelay",
    "2025-11-25T22:38:59.3859311Z Testing parameter subscriptionKey",
    "2025-11-25T22:38:59.3862427Z Testing parameter suppressMaxRetriesException",
    "2025-11-25T22:38:59.3868320Z Testing parameter timeout",
    "2025-11-25T22:38:59.3873528Z Testing parameter url",
    "2025-11-25T22:38:59.3881913Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:38:59.3888784Z [info] + Test Getters and Setters work as anticipated took 0.012s ",
    "2025-11-25T22:39:01.0442781Z 25/11/25 22:39:01 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/63eb9412-54b4-4977-85db-4c1d9317d238?api-version=1.0",
    "2025-11-25T22:39:01.0471445Z 25/11/25 22:39:01 ERROR Executor: Exception in task 1.0 in stage 7.0 (TID 10)",
    "2025-11-25T22:39:01.0471934Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:01.0472595Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:01.0473287Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:01.0473947Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0475198Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:01.0475992Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:01.0476660Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:01.0477195Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:01.0477792Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:01.0478513Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:01.0479182Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0479895Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:01.0480562Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.0481130Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.0481683Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.0482173Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.0494274Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.0511477Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:01.0512117Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:01.0514646Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.0520077Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:01.0522128Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:01.0522820Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:01.0523456Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:01.0524344Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:01.0525236Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:01.0525948Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0526553Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0527089Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0527676Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:01.0529075Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.0529815Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.0530481Z \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:39:01.0531058Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:39:01.0533233Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:01.0536481Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.0537525Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.0538300Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:01.0539819Z \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:39:01.0551262Z \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:39:01.0552030Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:39:01.0552696Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:39:01.0553364Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:01.0554375Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:01.0555130Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:01.0555836Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:01.0556531Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:01.0557516Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:01.0558048Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:01.0558551Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:01.0559086Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:01.0559537Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:01.0560085Z 25/11/25 22:39:01 WARN TaskSetManager: Lost task 1.0 in stage 7.0 (TID 10) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:01.0560777Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:01.0561344Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:01.0561899Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0562458Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:01.0563065Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:01.0563605Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:01.0564044Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:01.0564785Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:01.0565380Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:01.0566137Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0566779Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:01.0567354Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.0567815Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.0568282Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.0568766Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.0569315Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.0570014Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:01.0570490Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:01.0570981Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.0571528Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:01.0571986Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:01.0572424Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:01.0572949Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:01.0573500Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:01.0604447Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:01.0605243Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0605685Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0606084Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0606537Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:01.0607045Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.0607634Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.0608182Z \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:39:01.0608685Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:39:01.0609208Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:01.0609703Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.0610293Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.0610837Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:01.0611304Z \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:39:01.0611807Z \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:39:01.0612255Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:39:01.0612701Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:39:01.0613271Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:01.0613658Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:01.0614072Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:01.0614773Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:01.0615218Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:01.0615635Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:01.0616017Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:01.0616456Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:01.0616932Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:01.0617533Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:01.0617730Z ",
    "2025-11-25T22:39:01.0618079Z 25/11/25 22:39:01 ERROR TaskSetManager: Task 1 in stage 7.0 failed 1 times; aborting job",
    "2025-11-25T22:39:01.0705171Z [info] - Usage with strange address responses *** FAILED ***",
    "2025-11-25T22:39:01.0725006Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 7.0 failed 1 times, most recent failure: Lost task 1.0 in stage 7.0 (TID 10) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:01.0726245Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:01.0727217Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:01.0728088Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0728972Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:01.0729851Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:01.0730655Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:01.0731356Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:01.0732107Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:01.0732951Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:01.0733800Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0735043Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:01.0735911Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.0736700Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.0737461Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.0738210Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.0739002Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.0740092Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:01.0740661Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:01.0741576Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.0742205Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:01.0746634Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:01.0751344Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:01.0791987Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:01.0792629Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:01.0793181Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:01.0793831Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0794447Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0794857Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.0795292Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:01.0795778Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.0796388Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.0796959Z [info] \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:39:01.0797462Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:39:01.0798002Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:01.0798511Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.0799097Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.0799655Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:01.0800141Z [info] \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:39:01.0800663Z [info] \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:39:01.0801139Z [info] \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:39:01.0801596Z [info] \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:39:01.0802040Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:01.0802436Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:01.0802840Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:01.0803281Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:01.0803743Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:01.0804361Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:01.0804813Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:01.0805312Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:01.0805854Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:01.0806459Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:01.0806744Z [info] ",
    "2025-11-25T22:39:01.0806990Z [info] Driver stacktrace:",
    "2025-11-25T22:39:01.0807391Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:39:01.0807806Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:39:01.0808220Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:39:01.0808693Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:39:01.0809130Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:39:01.0809553Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:39:01.0810028Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:39:01.0810708Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:39:01.0811200Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:39:01.0811641Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:39:01.0812034Z [info]   ...",
    "2025-11-25T22:39:01.0812353Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:01.0812843Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:01.0813409Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:01.0813965Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0814761Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:01.0815366Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:01.0815880Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:01.0816300Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:01.0816765Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:01.0817304Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:01.0817843Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:01.0818237Z [info]   ...",
    "2025-11-25T22:39:01.0818518Z [info] + Test Usage with strange address responses took 1.678s ",
    "2025-11-25T22:39:01.5468774Z 25/11/25 22:39:01 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/dffd9e84-366b-4db6-acf3-a0bcbc86d0f9?api-version=1.0",
    "2025-11-25T22:39:01.5541082Z 25/11/25 22:39:01 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 9) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 1 in stage 7.0 failed 1 times, most recent failure: Lost task 1.0 in stage 7.0 (TID 10) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:01.5542176Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:01.5542730Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:01.5543299Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:01.5544401Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:01.5544974Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:01.5545431Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:01.5545809Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:01.5546257Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:01.5546748Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:01.5547246Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:01.5548216Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:01.5548726Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.5549315Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.5549894Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:01.5550475Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:01.5551076Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.5551687Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:01.5552229Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:01.5552785Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:01.5553430Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:01.5553977Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:01.5554715Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:01.5555323Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:01.5555961Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:01.5556634Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:01.5557219Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.5557740Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.5558248Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:01.5558822Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:01.5559415Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.5560103Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.5560775Z \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:39:01.5561355Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:39:01.5561992Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:01.5562695Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:01.5563557Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:01.5591003Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:01.5592122Z \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:39:01.5592970Z \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:39:01.5593740Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:39:01.5594656Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:39:01.5595384Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:01.5596289Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:01.5597096Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:01.5597849Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:01.5614896Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:01.5615717Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:01.5616418Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:01.5617142Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:01.5617867Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:01.5618557Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:01.5618973Z ",
    "2025-11-25T22:39:01.5619471Z Driver stacktrace:)",
    "2025-11-25T22:39:02.4004005Z 25/11/25 22:39:02 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/e8c04c4a-72dd-45de-9c4c-17ecbd42b750?api-version=1.0",
    "2025-11-25T22:39:02.4021211Z 25/11/25 22:39:02 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 11)",
    "2025-11-25T22:39:02.4022119Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:02.4022933Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:02.4023728Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:02.4024788Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4025585Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:02.4026371Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:02.4027110Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:02.4027738Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:02.4028803Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:02.4029554Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:02.4030330Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4031169Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:02.4032761Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:02.4033371Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:02.4034697Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:02.4049573Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:02.4050365Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:02.4051022Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:02.4051571Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:02.4055669Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:02.4056487Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:02.4057059Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:02.4057584Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:02.4058394Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:02.4059025Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:02.4059661Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:02.4060230Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4060930Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4061413Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4061932Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:02.4062622Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:02.4063528Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:02.4064435Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4064995Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4065485Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4065983Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:39:02.4066471Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4066993Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:02.4067562Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:02.4068221Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:02.4068902Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:39:02.4069448Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:39:02.4069979Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:39:02.4070517Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:39:02.4071030Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:39:02.4081758Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:39:02.4082567Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:39:02.4083126Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:02.4083640Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:02.4084349Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:02.4085086Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:02.4085644Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:02.4086192Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:02.4086733Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:02.4087277Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:02.4087855Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:02.4088363Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:02.4089164Z 25/11/25 22:39:02 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 11) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:02.4090888Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:02.4091555Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:02.4095645Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4096363Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:02.4097034Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:02.4099352Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:02.4099912Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:02.4100492Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:02.4101254Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:02.4101928Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4102616Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:02.4103247Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:02.4103843Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:02.4104645Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:02.4105222Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:02.4105862Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:02.4106511Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:02.4107066Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:02.4107555Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:02.4108099Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:02.4108613Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:02.4109154Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:02.4109754Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:02.4133622Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:02.4134808Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:02.4135447Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4136056Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4136738Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4137365Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:02.4138027Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:02.4145859Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:02.4146742Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4149324Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4149961Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4150557Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:39:02.4151101Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4151660Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:02.4152264Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:02.4165812Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:02.4166611Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:39:02.4167174Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:39:02.4167705Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:39:02.4168236Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:39:02.4168743Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:39:02.4169367Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:39:02.4174698Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:39:02.4175449Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:02.4177318Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:02.4177946Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:02.4178532Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:02.4179119Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:02.4179684Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:02.4180213Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:02.4180777Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:02.4191828Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:02.4192438Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:02.4192742Z ",
    "2025-11-25T22:39:02.4193614Z 25/11/25 22:39:02 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job",
    "2025-11-25T22:39:02.4194952Z Info Provided - Suite AzMapsSearchReverseAddressSuite took 5.367s",
    "2025-11-25T22:39:02.4198951Z [info] - Basic Batch Reverse Geocode Usage *** FAILED ***",
    "2025-11-25T22:39:02.4200060Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 11) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:02.4202156Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:02.4203449Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:02.4205084Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4205737Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:02.4206387Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:02.4207231Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:02.4207745Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:02.4208311Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:02.4287034Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:02.4287754Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4288405Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:39:02.4288921Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:02.4289379Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:02.4289860Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:39:02.4290282Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:39:02.4290755Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:39:02.4291220Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:39:02.4291623Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:39:02.4292036Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:39:02.4292548Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:39:02.4292976Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:39:02.4293389Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:39:02.4293873Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:39:02.4294713Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:39:02.4295289Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:39:02.4295788Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4296212Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4296622Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:39:02.4297059Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:39:02.4297565Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:02.4298375Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:02.4298932Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4299332Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4299739Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4300151Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:39:02.4300576Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:39:02.4301034Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:39:02.4301516Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:39:02.4302274Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:39:02.4302883Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:39:02.4303360Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:39:02.4303820Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:39:02.4304505Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:39:02.4304961Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:39:02.4305321Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:39:02.4305677Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:39:02.4306106Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:39:02.4306486Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:39:02.4306872Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:39:02.4307305Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:39:02.4307728Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:39:02.4308127Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:39:02.4308526Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:39:02.4308959Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:39:02.4309374Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:39:02.4309735Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:39:02.4309995Z [info] ",
    "2025-11-25T22:39:02.4310218Z [info] Driver stacktrace:",
    "2025-11-25T22:39:02.4349773Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:39:02.4350799Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:39:02.4351350Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:39:02.4351913Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:39:02.4352563Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:39:02.4353072Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:39:02.4353615Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:39:02.4354420Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:39:02.4355128Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:39:02.4355619Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:39:02.4356101Z [info]   ...",
    "2025-11-25T22:39:02.4396108Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:39:02.4421701Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:39:02.4422741Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:39:02.4423428Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4424368Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:39:02.4454759Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:39:02.4455410Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:39:02.4455832Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:39:02.4456308Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:39:02.4456848Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:39:02.4457381Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:39:02.4457765Z [info]   ...",
    "2025-11-25T22:39:02.4458056Z [info] + Test Basic Batch Reverse Geocode Usage took 1.346s ",
    "2025-11-25T22:39:02.4793587Z [info] AzMapsPointInPolygonSuite:",
    "2025-11-25T22:39:02.9368808Z RETRYING after 3000 ms:  Caught error: java.lang.RuntimeException: Resource location is empty in LongRunningOperationResult ",
    "2025-11-25T22:39:06.1052749Z RETRYING after 5000 ms:  Caught error: java.lang.RuntimeException: Resource location is empty in LongRunningOperationResult ",
    "2025-11-25T22:39:11.5656464Z RETRYING after 10000 ms:  Caught error: java.lang.RuntimeException: Resource location is empty in LongRunningOperationResult ",
    "2025-11-25T22:39:26.2873432Z [info] - Serialization Fuzzing",
    "2025-11-25T22:39:26.2875151Z [info] + Test Serialization Fuzzing took 4.548s ",
    "2025-11-25T22:39:26.3764350Z [info] - Experiment Fuzzing",
    "2025-11-25T22:39:26.3772848Z [info] + Test Experiment Fuzzing took 0.09s ",
    "2025-11-25T22:39:26.3788703Z Testing parameter AADToken",
    "2025-11-25T22:39:26.3794488Z 25/11/25 22:39:26 WARN DefaultParamInfo: unsupported type CheckPointInPolygon_9f25e4948e6b__AADToken",
    "2025-11-25T22:39:26.3814755Z Could not test Service parameter value API  AADToken",
    "2025-11-25T22:39:26.3815469Z Testing parameter concurrency",
    "2025-11-25T22:39:26.3815968Z Testing parameter concurrentTimeout",
    "2025-11-25T22:39:26.3843136Z Could not test parameter concurrentTimeout",
    "2025-11-25T22:39:26.3843862Z Testing parameter errorCol",
    "2025-11-25T22:39:26.3844614Z Testing parameter handler",
    "2025-11-25T22:39:26.3845148Z Could not test parameter handler",
    "2025-11-25T22:39:26.3845659Z Testing parameter latitude",
    "2025-11-25T22:39:26.3846150Z Could not test Service parameter value API  latitude",
    "2025-11-25T22:39:26.3846661Z Testing parameter longitude",
    "2025-11-25T22:39:26.3847241Z Could not test Service parameter value API  longitude",
    "2025-11-25T22:39:26.3847822Z Testing parameter outputCol",
    "2025-11-25T22:39:26.3848429Z Testing parameter subscriptionKey",
    "2025-11-25T22:39:26.3849131Z Testing parameter timeout",
    "2025-11-25T22:39:26.3851657Z Testing parameter url",
    "2025-11-25T22:39:26.3855240Z Testing parameter userDataIdentifier",
    "2025-11-25T22:39:26.3864578Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:39:26.3868544Z [info] + Test Getters and Setters work as anticipated took 0.01s ",
    "2025-11-25T22:39:26.3885879Z Using 5d923f6d-6657-4dfb-bdfe-d59335dbb8d0 as the user-data identifier for these tests",
    "2025-11-25T22:39:27.1297372Z [info] - Point in Polygon: Basic Usage",
    "2025-11-25T22:39:27.1298529Z [info] + Test Point in Polygon: Basic Usage took 0.741s ",
    "2025-11-25T22:39:27.5947881Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:27.5955284Z [info] No tests to run for opencv / Test / testOnly",
    "2025-11-25T22:39:27.6397180Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:27.6398886Z [info] No tests to run for deepLearning / Test / testOnly",
    "2025-11-25T22:39:27.6399289Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:27.6399600Z [info] No tests to run for Test / testOnly",
    "2025-11-25T22:39:27.6440040Z [info] Run completed in 49 seconds, 573 milliseconds.",
    "2025-11-25T22:39:27.6445220Z [info] Total number of tests run: 13",
    "2025-11-25T22:39:27.6450247Z [info] Suites: completed 3, aborted 0",
    "2025-11-25T22:39:27.6495629Z [info] Tests: succeeded 8, failed 5, canceled 0, ignored 0, pending 0",
    "2025-11-25T22:39:27.6496923Z [info] *** 5 TESTS FAILED ***",
    "2025-11-25T22:39:27.6502627Z [error] Failed tests:",
    "2025-11-25T22:39:27.6505916Z [error] \tcom.microsoft.azure.synapse.ml.services.geospatial.AzMapsSearchReverseAddressSuite",
    "2025-11-25T22:39:27.6515258Z [error] \tcom.microsoft.azure.synapse.ml.services.geospatial.AzMapsSearchAddressSuite",
    "2025-11-25T22:39:27.7079114Z [error] (cognitive / Test / testOnly) sbt.TestsFailedException: Tests unsuccessful",
    "2025-11-25T22:39:27.7167613Z [error] Total time: 57 s, completed Nov 25, 2025, 10:39:27 PM",
    "2025-11-25T22:39:28.1013467Z ",
    "2025-11-25T22:39:28.1031975Z ##[error]Script failed with exit code: 1",
    "2025-11-25T22:39:28.1040236Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account clear",
    "2025-11-25T22:39:28.5325951Z ##[warning]RetryHelper encountered task failure, will retry (attempt #: 1 out of 1) after 1000 ms",
    "2025-11-25T22:39:29.8168014Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az version",
    "2025-11-25T22:39:30.0685477Z {",
    "2025-11-25T22:39:30.0686307Z   \"azure-cli\": \"2.60.0\",",
    "2025-11-25T22:39:30.0686752Z   \"azure-cli-core\": \"2.60.0\",",
    "2025-11-25T22:39:30.0687176Z   \"azure-cli-telemetry\": \"1.1.0\",",
    "2025-11-25T22:39:30.0687602Z   \"extensions\": {",
    "2025-11-25T22:39:30.0688003Z     \"azure-devops\": \"1.0.2\"",
    "2025-11-25T22:39:30.0688393Z   }",
    "2025-11-25T22:39:30.0688759Z }",
    "2025-11-25T22:39:30.0698469Z Setting AZURE_CONFIG_DIR env variable to: /home/vsts/work/_temp/.azclitask",
    "2025-11-25T22:39:30.0711895Z Setting active cloud to: AzureCloud",
    "2025-11-25T22:39:30.0717475Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az cloud set -n AzureCloud",
    "2025-11-25T22:39:30.8460973Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az login --service-principal -u *** --tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 --allow-no-subscriptions --federated-token ***",
    "2025-11-25T22:39:31.5315494Z [",
    "2025-11-25T22:39:31.5316108Z   {",
    "2025-11-25T22:39:31.5316445Z     \"cloudName\": \"AzureCloud\",",
    "2025-11-25T22:39:31.5316860Z     \"homeTenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:39:31.5317269Z     \"id\": \"e342c2c0-f844-4b18-9208-52c8c234c30e\",",
    "2025-11-25T22:39:31.5317648Z     \"isDefault\": true,",
    "2025-11-25T22:39:31.5317984Z     \"managedByTenants\": [",
    "2025-11-25T22:39:31.5318289Z       {",
    "2025-11-25T22:39:31.5318628Z         \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"",
    "2025-11-25T22:39:31.5318986Z       }",
    "2025-11-25T22:39:31.5319255Z     ],",
    "2025-11-25T22:39:31.5319501Z     \"name\": \"Synapse_OSS_ML_DevTest_001\",",
    "2025-11-25T22:39:31.5319754Z     \"state\": \"Enabled\",",
    "2025-11-25T22:39:31.5320029Z     \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:39:31.5320298Z     \"user\": {",
    "2025-11-25T22:39:31.5320648Z       \"name\": \"***\",",
    "2025-11-25T22:39:31.5320923Z       \"type\": \"servicePrincipal\"",
    "2025-11-25T22:39:31.5321167Z     }",
    "2025-11-25T22:39:31.5321420Z   }",
    "2025-11-25T22:39:31.5321656Z ]",
    "2025-11-25T22:39:31.5336204Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account set --subscription e342c2c0-f844-4b18-9208-52c8c234c30e",
    "2025-11-25T22:39:31.9596566Z [command]/usr/bin/bash /home/vsts/work/_temp/azureclitaskscript1764110369813.sh",
    "2025-11-25T22:39:34.2131347Z [info] welcome to sbt 1.10.11 (Eclipse Adoptium Java 17.0.17)",
    "2025-11-25T22:39:35.5257288Z [info] loading settings for project s-build from assembly.sbt, build.sbt, plugins.sbt...",
    "2025-11-25T22:39:36.6617274Z [info] loading project definition from /home/vsts/work/1/s/project",
    "2025-11-25T22:39:39.1110038Z [info] loading settings for project root from build.sbt, sonatype.sbt...",
    "2025-11-25T22:39:40.0810243Z [warn] Secret pgp-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:39:40.0817068Z [warn] Secret pgp-private not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:39:40.0855865Z [warn] Secret pgp-public not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:39:40.9891680Z [info] set current project to synapseml (in build file:/home/vsts/work/1/s/)",
    "2025-11-25T22:39:41.4013506Z [warn] Secret nexus-un not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:39:41.4018604Z [warn] Secret nexus-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:39:41.4019792Z [warn] Secret ado-feed-token not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:39:48.0385605Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:48.0386498Z [info] No tests to run for core / Test / testOnly",
    "2025-11-25T22:39:48.1871991Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:48.1886615Z [info] No tests to run for vw / Test / testOnly",
    "2025-11-25T22:39:48.1889757Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:48.1898246Z [info] No tests to run for lightgbm / Test / testOnly",
    "2025-11-25T22:39:48.1898981Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:48.1899587Z [info] No tests to run for opencv / Test / testOnly",
    "2025-11-25T22:39:48.2956793Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:39:49.4819144Z [info] No tests to run for deepLearning / Test / testOnly",
    "2025-11-25T22:39:49.4819916Z [info] AzMapsSearchAddressSuite:",
    "2025-11-25T22:39:51.2184702Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties",
    "2025-11-25T22:39:51.2321858Z 25/11/25 22:39:51 INFO AddressGeocoder: {\"protocolVersion\":\"0.0.1\",\"method\":\"constructor\",\"libraryName\":\"SynapseML\",\"className\":\"class com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"AddressGeocoder_bb7fe14ad743\"}",
    "2025-11-25T22:39:51.6642804Z [info] fetching secret: azuremaps-api-key from e342c2c0-f844-4b18-9208-52c8c234c30e",
    "2025-11-25T22:39:52.7108231Z 25/11/25 22:39:52 INFO FixedMiniBatchTransformer: {\"protocolVersion\":\"0.0.1\",\"method\":\"constructor\",\"libraryName\":\"SynapseML\",\"className\":\"class com.microsoft.azure.synapse.ml.stages.FixedMiniBatchTransformer\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"FixedMiniBatchTransformer_30140e854662\"}",
    "2025-11-25T22:39:53.0496387Z 25/11/25 22:39:53 INFO SparkContext: Running Spark version 4.0.1",
    "2025-11-25T22:39:53.0498458Z 25/11/25 22:39:53 INFO SparkContext: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:39:53.0503596Z 25/11/25 22:39:53 INFO SparkContext: Java version 17.0.17",
    "2025-11-25T22:39:53.2196369Z 25/11/25 22:39:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable",
    "2025-11-25T22:39:53.2799153Z 25/11/25 22:39:53 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:39:53.2807397Z 25/11/25 22:39:53 INFO ResourceUtils: No custom resources configured for spark.driver.",
    "2025-11-25T22:39:53.2813331Z 25/11/25 22:39:53 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:39:53.2834915Z 25/11/25 22:39:53 INFO SparkContext: Submitted application: com.microsoft.azure.synapse.ml.core.test.base.TestBase$@43638972",
    "2025-11-25T22:39:53.2893987Z 25/11/25 22:39:53 INFO SparkContext: Spark configuration:",
    "2025-11-25T22:39:53.2894660Z spark.app.name=com.microsoft.azure.synapse.ml.core.test.base.TestBase$@43638972",
    "2025-11-25T22:39:53.2895014Z spark.app.startTime=1764110393041",
    "2025-11-25T22:39:53.2896279Z spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:39:53.2897740Z spark.driver.maxResultSize=6g",
    "2025-11-25T22:39:53.2899218Z spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:39:53.2900675Z spark.hadoop.fs.s3a.vectored.read.max.merged.size=2M",
    "2025-11-25T22:39:53.2901151Z spark.hadoop.fs.s3a.vectored.read.min.seek.size=128K",
    "2025-11-25T22:39:53.2901564Z spark.logConf=true",
    "2025-11-25T22:39:53.2901939Z spark.master=local[*]",
    "2025-11-25T22:39:53.2902328Z spark.sql.crossJoin.enabled=true",
    "2025-11-25T22:39:53.2902725Z spark.sql.shuffle.partitions=20",
    "2025-11-25T22:39:53.2903179Z spark.sql.warehouse.dir=file:/home/vsts/work/1/s/cognitive/spark-warehouse",
    "2025-11-25T22:39:53.3196654Z 25/11/25 22:39:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)",
    "2025-11-25T22:39:53.3226248Z 25/11/25 22:39:53 INFO ResourceProfile: Limiting resource is cpu",
    "2025-11-25T22:39:53.3243464Z 25/11/25 22:39:53 INFO ResourceProfileManager: Added ResourceProfile id: 0",
    "2025-11-25T22:39:53.3754999Z 25/11/25 22:39:53 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:39:53.3755932Z 25/11/25 22:39:53 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:39:53.3756497Z 25/11/25 22:39:53 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:39:53.3760717Z 25/11/25 22:39:53 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:39:53.3784360Z 25/11/25 22:39:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:39:53.6141269Z 25/11/25 22:39:53 INFO Utils: Successfully started service 'sparkDriver' on port 41343.",
    "2025-11-25T22:39:53.6419606Z 25/11/25 22:39:53 INFO SparkEnv: Registering MapOutputTracker",
    "2025-11-25T22:39:53.6536319Z 25/11/25 22:39:53 INFO SparkEnv: Registering BlockManagerMaster",
    "2025-11-25T22:39:53.6683031Z 25/11/25 22:39:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information",
    "2025-11-25T22:39:53.6693068Z 25/11/25 22:39:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up",
    "2025-11-25T22:39:53.6726268Z 25/11/25 22:39:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat",
    "2025-11-25T22:39:53.6946200Z 25/11/25 22:39:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0c77d847-7c33-4905-b390-e4b58d778ebe",
    "2025-11-25T22:39:53.7357054Z 25/11/25 22:39:53 INFO SparkEnv: Registering OutputCommitCoordinator",
    "2025-11-25T22:39:53.8609016Z 25/11/25 22:39:53 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI",
    "2025-11-25T22:39:53.9242229Z 25/11/25 22:39:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.",
    "2025-11-25T22:39:54.0105189Z 25/11/25 22:39:54 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:39:54.0106556Z 25/11/25 22:39:54 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:39:54.0107320Z 25/11/25 22:39:54 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:39:54.0107736Z 25/11/25 22:39:54 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:39:54.1532503Z 25/11/25 22:39:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:39:54.1533520Z 25/11/25 22:39:54 INFO Executor: Starting executor ID driver on host runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net",
    "2025-11-25T22:39:54.1564775Z 25/11/25 22:39:54 INFO Executor: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:39:54.1565364Z 25/11/25 22:39:54 INFO Executor: Java version 17.0.17",
    "2025-11-25T22:39:54.1685539Z 25/11/25 22:39:54 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''",
    "2025-11-25T22:39:54.1700015Z 25/11/25 22:39:54 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@52d7c0c4 for default.",
    "2025-11-25T22:39:54.1988260Z 25/11/25 22:39:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38249.",
    "2025-11-25T22:39:54.2136247Z 25/11/25 22:39:54 INFO NettyBlockTransferService: Server created on runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net:38249",
    "2025-11-25T22:39:54.2156004Z 25/11/25 22:39:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy",
    "2025-11-25T22:39:54.2318185Z 25/11/25 22:39:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 38249, None)",
    "2025-11-25T22:39:54.2348386Z 25/11/25 22:39:54 INFO BlockManagerMasterEndpoint: Registering block manager runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net:38249 with 1012.8 MiB RAM, BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 38249, None)",
    "2025-11-25T22:39:54.2372210Z 25/11/25 22:39:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 38249, None)",
    "2025-11-25T22:39:54.2386579Z 25/11/25 22:39:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net, 38249, None)",
    "2025-11-25T22:40:04.5334820Z 25/11/25 22:40:04 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/batch/e1154b34-62da-464e-99a7-0968a56d72ad?api-version=1.0",
    "2025-11-25T22:40:04.5338522Z 25/11/25 22:40:04 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/batch/f1bd6ccb-fe7c-4aea-a45d-2c9117e9ffeb?api-version=1.0",
    "2025-11-25T22:40:04.5357438Z 25/11/25 22:40:04 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 3)",
    "2025-11-25T22:40:04.5358192Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:04.5362637Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:04.5363465Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:04.5370343Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:04.5377544Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:04.5378367Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:04.5378822Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:04.5379187Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:04.5379647Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:04.5380170Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:04.5380714Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:04.5381279Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:04.5381795Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.5382232Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.5382672Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.5383153Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.5383678Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.5384396Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:04.5384871Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:04.5385346Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.5385830Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:04.5386215Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:04.5386559Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:04.5386998Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:04.5387507Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:04.5388171Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:04.5388641Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5389061Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5389471Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5389908Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:04.5390364Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.5391085Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.5391664Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:04.5392082Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:04.5392530Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.5393083Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.5393650Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:04.5394498Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:04.5394972Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:04.5395448Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:04.5395875Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:04.5396244Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:04.5396600Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:04.5397007Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:04.5397379Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:04.5397782Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:04.5398242Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:04.5398703Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:04.5399110Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:04.5399523Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:04.5399958Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:04.5400397Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:04.5400798Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:04.5401152Z 25/11/25 22:40:04 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)",
    "2025-11-25T22:40:04.5401489Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:04.5401920Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:04.5402435Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:04.5403003Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:04.5403556Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:04.5431400Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:04.5432178Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:04.5432740Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:04.5433335Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:04.5434039Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:04.5434964Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:04.5435999Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:04.5436656Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.5437256Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.5437838Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.5438419Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.5439014Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.5439777Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:04.5440337Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:04.5441083Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.5441758Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:04.5442305Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:04.5442808Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:04.5443413Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:04.5444292Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:04.5444975Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:04.5445575Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5446071Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5446589Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5447169Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:04.5447763Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.5448460Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.5449167Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:04.5449728Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:04.5450334Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.5451058Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.5451784Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:04.5452384Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:04.5452947Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:04.5453523Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:04.5454075Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:04.5486213Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:04.5486811Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:04.5487423Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:04.5487993Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:04.5488486Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:04.5494922Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:04.5495541Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:04.5495996Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:04.5496444Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:04.5496912Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:04.5497408Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:04.5497822Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:04.5547287Z 25/11/25 22:40:04 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 2) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:04.5571970Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:04.5572659Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:04.5573180Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:04.5573698Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:04.5574392Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:04.5574878Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:04.5575266Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:04.5575718Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:04.5576263Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:04.5576764Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:04.5577336Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:04.5577896Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.5578351Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.5578807Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.5579259Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.5579748Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.5580231Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:04.5580684Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:04.5581144Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.5581655Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:04.5582107Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:04.5582506Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:04.5582997Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:04.5583545Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:04.5584508Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:04.5585029Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5585413Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5585805Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.5586279Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:04.5586781Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.5587492Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.5588100Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:04.5588749Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:04.5589238Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.5589804Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.5590394Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:04.5590902Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:04.5591351Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:04.5591782Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:04.5592188Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:04.5592561Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:04.5592969Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:04.5593375Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:04.5593753Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:04.5614458Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:04.5615287Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:04.5634667Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:04.5635157Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:04.5635508Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:04.5635856Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:04.5636286Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:04.5636615Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:04.5636750Z ",
    "2025-11-25T22:40:04.5637030Z 25/11/25 22:40:04 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job",
    "2025-11-25T22:40:04.6078364Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:40:04.6135337Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 2) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:04.6136311Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:04.6145505Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:04.6146339Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:04.6146854Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:04.6147349Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:04.6147824Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:04.6148272Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:04.6148746Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:04.6149289Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:04.6150086Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:04.6150717Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:04.6151340Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.6151846Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.6152345Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:04.6153101Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:04.6153660Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.6154587Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:04.6155265Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:04.6155925Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:04.6156686Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:04.6157349Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:04.6157957Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:04.6158648Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:04.6159393Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:04.6160164Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:04.6160877Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.6161467Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.6162050Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:04.6162680Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:04.6163390Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.6164346Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.6165156Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:04.6165774Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:04.6166621Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:04.6167403Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:04.6168234Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:04.6168886Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:04.6169526Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:04.6170136Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:04.6170744Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:04.6171511Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:04.6172086Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:04.6172710Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:04.6173299Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:04.6173910Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:04.6174666Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:04.6175189Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:04.6175851Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:04.6176451Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:04.6177080Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:04.6177733Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:04.6178364Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:04.6178727Z [info] ",
    "2025-11-25T22:40:04.6214907Z [info] Driver stacktrace:",
    "2025-11-25T22:40:04.6215485Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:04.6216170Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:40:04.6216869Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:04.6217450Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:04.6217955Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:40:04.6218414Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:04.6218985Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:04.6219499Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:04.6219894Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:40:04.6220308Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:04.6220655Z [info]   ...",
    "2025-11-25T22:40:04.6220968Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:04.6221415Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:04.6221955Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:04.6222494Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:04.6223262Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:04.6223876Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:04.6224643Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:04.6225108Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:04.6225629Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:04.6226196Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:04.6226772Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:04.6227339Z [info]   ...",
    "2025-11-25T22:40:04.6357887Z [info] + Test Serialization Fuzzing took 15.096s ",
    "2025-11-25T22:40:04.9352506Z [info] - Experiment Fuzzing",
    "2025-11-25T22:40:04.9423471Z [info] + Test Experiment Fuzzing took 0.302s ",
    "2025-11-25T22:40:04.9504824Z Testing parameter AADToken",
    "2025-11-25T22:40:04.9633379Z 25/11/25 22:40:04 WARN DefaultParamInfo: unsupported type AddressGeocoder_bb7fe14ad743__AADToken",
    "2025-11-25T22:40:04.9721545Z Could not test Service parameter value API  AADToken",
    "2025-11-25T22:40:04.9735797Z Testing parameter address",
    "2025-11-25T22:40:04.9762792Z Could not test Service parameter value API  address",
    "2025-11-25T22:40:04.9816592Z Testing parameter backoffs",
    "2025-11-25T22:40:04.9817140Z Testing parameter concurrency",
    "2025-11-25T22:40:04.9817469Z Testing parameter concurrentTimeout",
    "2025-11-25T22:40:04.9828845Z Could not test parameter concurrentTimeout",
    "2025-11-25T22:40:04.9829666Z Testing parameter errorCol",
    "2025-11-25T22:40:04.9855458Z Testing parameter initialPollingDelay",
    "2025-11-25T22:40:04.9875544Z Testing parameter maxPollingRetries",
    "2025-11-25T22:40:04.9888788Z Testing parameter outputCol",
    "2025-11-25T22:40:04.9914283Z Testing parameter pollingDelay",
    "2025-11-25T22:40:04.9945356Z Testing parameter subscriptionKey",
    "2025-11-25T22:40:04.9982956Z Testing parameter suppressMaxRetriesException",
    "2025-11-25T22:40:04.9991865Z Testing parameter timeout",
    "2025-11-25T22:40:05.0021342Z Testing parameter url",
    "2025-11-25T22:40:05.0106991Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:40:05.0111296Z [info] + Test Getters and Setters work as anticipated took 0.064s ",
    "2025-11-25T22:40:05.4423337Z 25/11/25 22:40:05 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.",
    "2025-11-25T22:40:07.0139960Z 25/11/25 22:40:07 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/batch/359e6b36-66e6-4bd8-a1e4-2b64dca3f006?api-version=1.0",
    "2025-11-25T22:40:07.0165365Z 25/11/25 22:40:07 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 4)",
    "2025-11-25T22:40:07.0170290Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:07.0174691Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:07.0179172Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:07.0186746Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0187707Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:07.0194728Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:07.0195475Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:07.0196064Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:07.0198569Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:07.0200180Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:07.0202513Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0228433Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:07.0229093Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:07.0229651Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:07.0230121Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:07.0230835Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:07.0231347Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:07.0231832Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:07.0232256Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:07.0232689Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:07.0233209Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:07.0233649Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:07.0234047Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:07.0234744Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:07.0235293Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:07.0235837Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:07.0236311Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0236692Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0237073Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0237511Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:07.0237979Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:07.0238548Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:07.0239090Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0239487Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0239875Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0240272Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:40:07.0240660Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0241090Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:07.0241562Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:07.0242132Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:07.0242704Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:07.0243331Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:07.0243773Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:07.0298989Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:07.0301268Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:07.0311637Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:07.0312319Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:07.0312964Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:07.0378483Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:07.0379034Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:07.0379525Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:07.0380231Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:07.0380674Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:07.0381096Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:07.0381546Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:07.0382017Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:07.0382417Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:07.0383017Z 25/11/25 22:40:07 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 4) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:07.0383629Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:07.0384376Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:07.0384905Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0385419Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:07.0385991Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:07.0386471Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:07.0386866Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:07.0387348Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:07.0387894Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:07.0388432Z \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0388981Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:07.0389475Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:07.0389890Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:07.0390265Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:07.0390717Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:07.0391192Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:07.0391698Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:07.0392353Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:07.0392811Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:07.0393352Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:07.0393795Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:07.0394421Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:07.0394981Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:07.0395503Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:07.0396036Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:07.0396674Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0397058Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0397434Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0397866Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:07.0398324Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:07.0398882Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:07.0399418Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0399804Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0400189Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0400591Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:40:07.0400988Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0401413Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:07.0401878Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:07.0402438Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:07.0403001Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:07.0403433Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:07.0403946Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:07.0404598Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:07.0405015Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:07.0405383Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:07.0405767Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:07.0406172Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:07.0406557Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:07.0406965Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:07.0407404Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:07.0407853Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:07.0408276Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:07.0408687Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:07.0409260Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:07.0409714Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:07.0410115Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:07.0410289Z ",
    "2025-11-25T22:40:07.0410592Z 25/11/25 22:40:07 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job",
    "2025-11-25T22:40:07.0410942Z [info] - Basic Batch Geocode Usage *** FAILED ***",
    "2025-11-25T22:40:07.0411506Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 4) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:07.0412324Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:07.0412876Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:07.0413397Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0413950Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:07.0414758Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:07.0415284Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:07.0415734Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:07.0416234Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:07.0416819Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:07.0417554Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0418126Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:07.0418658Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:07.0419106Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:07.0419547Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:07.0419993Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:07.0420494Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:07.0420991Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:07.0421418Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:07.0421850Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:07.0422389Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:07.0422841Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:07.0423274Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:07.0423791Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:07.0424511Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:07.0425260Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:07.0425757Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0426156Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0426558Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:07.0427003Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:07.0427480Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:07.0428059Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:07.0428724Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0429129Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0429582Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0429984Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:40:07.0430381Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:07.0430817Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:07.0431287Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:07.0431865Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:07.0432461Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:07.0432933Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:07.0433388Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:07.0433828Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:07.0434416Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:07.0434833Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:07.0435230Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:07.0435646Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:07.0436049Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:07.0436460Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:07.0436927Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:07.0437386Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:07.0437815Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:07.0438348Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:07.0438800Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:07.0439266Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:07.0439698Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:07.0439974Z [info] ",
    "2025-11-25T22:40:07.0440204Z [info] Driver stacktrace:",
    "2025-11-25T22:40:07.0440569Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:07.0440991Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:40:07.0517697Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:07.0519177Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:07.0520446Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:40:07.0521449Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:07.0522500Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:07.0523675Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:07.0524922Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:40:07.0525770Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:07.0526761Z [info]   ...",
    "2025-11-25T22:40:07.0527415Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:07.0528235Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:07.0529786Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:07.0533064Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.queryForResult(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0600465Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:07.0601180Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:07.0601698Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:07.0602140Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:07.0602610Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:07.0603174Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:07.0603716Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.AddressGeocoder.handlingFunc(Geocoders.scala:27)",
    "2025-11-25T22:40:07.0604289Z [info]   ...",
    "2025-11-25T22:40:07.0604633Z [info] + Test Basic Batch Geocode Usage took 2.025s ",
    "2025-11-25T22:40:07.0604976Z Alert Provided - Suite AzMapsSearchAddressSuite took 17.487s",
    "2025-11-25T22:40:07.1833690Z [info] AzMapsSearchReverseAddressSuite:",
    "2025-11-25T22:40:09.0686308Z 25/11/25 22:40:09 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/3b7f7180-a667-4586-8257-0070cc9e7df2?api-version=1.0",
    "2025-11-25T22:40:09.0727099Z 25/11/25 22:40:09 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 7)",
    "2025-11-25T22:40:09.0740324Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:09.0746671Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:09.0747344Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:09.0748039Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:09.0748674Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:09.0749448Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:09.0764920Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:09.0767372Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:09.0768059Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:09.0768723Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:09.0769368Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:09.0770056Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:09.0770806Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.0771565Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.0772134Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.0772856Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.0773439Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.0774010Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:09.0774729Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:09.0775246Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.0775828Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:09.0776329Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:09.0776816Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:09.0777401Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:09.0778109Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:09.0778727Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:09.0779284Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.0779759Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.0780227Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.0780742Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:09.0781284Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.0781933Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.0782546Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:09.0783062Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:09.0783644Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.0784567Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.0785283Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:09.0786498Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:09.0804572Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:09.0805257Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:09.0805947Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:09.0806432Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:09.0806892Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:09.0807502Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:09.0807991Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:09.0808471Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:09.0809003Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:09.0809525Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:09.0810024Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:09.0810517Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:09.0811283Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:09.0811847Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:09.0812347Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:09.0812944Z 25/11/25 22:40:09 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 7) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:09.0813636Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:09.0814430Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:09.0815087Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:09.0815725Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:09.0816391Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:09.0816960Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:09.0817512Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:09.0818104Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:09.0822772Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:09.0823557Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:09.0824440Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:09.0825170Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.0825709Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.0826240Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.0828482Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.0829557Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.0830372Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:09.0831113Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:09.0831677Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.0835483Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:09.0836207Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:09.0836704Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:09.0837371Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:09.0837959Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:09.0838566Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:09.0839107Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.0839569Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.0840108Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.0840751Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:09.0841305Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.0841949Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.0842556Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:09.0843065Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:09.0843609Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.0844903Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.0845700Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:09.0846302Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:09.0846839Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:09.0847374Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:09.0847895Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:09.0848438Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:09.0849009Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:09.0849568Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:09.0850100Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:09.0850775Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:09.0853849Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:09.0855973Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:09.0856642Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:09.0857220Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:09.0857855Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:09.0858536Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:09.0859103Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:09.0859399Z ",
    "2025-11-25T22:40:09.0859823Z 25/11/25 22:40:09 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job",
    "2025-11-25T22:40:09.0890520Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:40:09.1395704Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 7) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:09.1436406Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:09.1437716Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:09.1438671Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:09.1439522Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:09.1440385Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:09.1441352Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:09.1442048Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:09.1442790Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:09.1443583Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:09.1444858Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:09.1445776Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:09.1446574Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.1447305Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.1448027Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.1448744Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.1449509Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.1450269Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:09.1451056Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:09.1451769Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.1452546Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:09.1453257Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:09.1453959Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:09.1454998Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:09.1455811Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:09.1456619Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:09.1457343Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.1457992Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.1458632Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.1459413Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:09.1460186Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.1461180Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.1462000Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:09.1462703Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:09.1463677Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.1464529Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.1484357Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:09.1485249Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:09.1485839Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:09.1486386Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:09.1516515Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:09.1517097Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:09.1517514Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:09.1517951Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:09.1518352Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:09.1518764Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:09.1519236Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:09.1519710Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:09.1520141Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:09.1520556Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:09.1520990Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:09.1521445Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:09.1521849Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:09.1522125Z [info] ",
    "2025-11-25T22:40:09.1522358Z [info] Driver stacktrace:",
    "2025-11-25T22:40:09.1522725Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:09.1523126Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:40:09.1523531Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:09.1524011Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:09.1524634Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:40:09.1525043Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:09.1525514Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:09.1526007Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:09.1526432Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:40:09.1526827Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:09.1527164Z [info]   ...",
    "2025-11-25T22:40:09.1527456Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:09.1528044Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:09.1528566Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:09.1529091Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:09.1529625Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:09.1530184Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:09.1530660Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:09.1531158Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:09.1531631Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:09.1532142Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:09.1532657Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:09.1533033Z [info]   ...",
    "2025-11-25T22:40:09.1538443Z [info] + Test Serialization Fuzzing took 2.011s ",
    "2025-11-25T22:40:09.3416235Z [info] - Experiment Fuzzing",
    "2025-11-25T22:40:09.3438206Z [info] + Test Experiment Fuzzing took 0.252s ",
    "2025-11-25T22:40:09.3441849Z Testing parameter AADToken",
    "2025-11-25T22:40:09.3442605Z 25/11/25 22:40:09 WARN DefaultParamInfo: unsupported type ReverseAddressGeocoder_70bc1985a5d2__AADToken",
    "2025-11-25T22:40:09.3467357Z Could not test Service parameter value API  AADToken",
    "2025-11-25T22:40:09.3468201Z Testing parameter backoffs",
    "2025-11-25T22:40:09.3472330Z Testing parameter concurrency",
    "2025-11-25T22:40:09.3473073Z Testing parameter concurrentTimeout",
    "2025-11-25T22:40:09.3480203Z Could not test parameter concurrentTimeout",
    "2025-11-25T22:40:09.3484055Z Testing parameter errorCol",
    "2025-11-25T22:40:09.3485348Z Testing parameter initialPollingDelay",
    "2025-11-25T22:40:09.3485935Z Testing parameter latitude",
    "2025-11-25T22:40:09.3486296Z Could not test Service parameter value API  latitude",
    "2025-11-25T22:40:09.3486583Z Testing parameter longitude",
    "2025-11-25T22:40:09.3486859Z Could not test Service parameter value API  longitude",
    "2025-11-25T22:40:09.3487159Z Testing parameter maxPollingRetries",
    "2025-11-25T22:40:09.3487579Z Testing parameter outputCol",
    "2025-11-25T22:40:09.3487970Z Testing parameter pollingDelay",
    "2025-11-25T22:40:09.3488328Z Testing parameter subscriptionKey",
    "2025-11-25T22:40:09.3488720Z Testing parameter suppressMaxRetriesException",
    "2025-11-25T22:40:09.3489103Z Testing parameter timeout",
    "2025-11-25T22:40:09.3489453Z Testing parameter url",
    "2025-11-25T22:40:09.3499965Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:40:09.3503028Z [info] + Test Getters and Setters work as anticipated took 0.007s ",
    "2025-11-25T22:40:09.5745056Z 25/11/25 22:40:09 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/f7f52fbd-0abe-4802-830c-e9ff4c44dc76?api-version=1.0",
    "2025-11-25T22:40:09.5817362Z 25/11/25 22:40:09 WARN TaskSetManager: Lost task 1.0 in stage 6.0 (TID 8) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 7) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:09.5818399Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:09.5819293Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:09.5819830Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:09.5820360Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:09.5820901Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:09.5821347Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:09.5821743Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:09.5822243Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:09.5823005Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:09.5823579Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:09.5824326Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:09.5824855Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.5825304Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.5825732Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:09.5826134Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:09.5826624Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.5827160Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:09.5827604Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:09.5828077Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:09.5828619Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:09.5829073Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:09.5829509Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:09.5830051Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:09.5830591Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:09.5855294Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:09.5856112Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.5856641Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.5857039Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:09.5857474Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:09.5857972Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.5858528Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.5859052Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:09.5859465Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:09.5859944Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:09.5860703Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:09.5861268Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:09.5861713Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:09.5862138Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:09.5862572Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:09.5862979Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:09.5863340Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:09.5863737Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:09.5864476Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:09.5864894Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:09.5865300Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:09.5865756Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:09.5866201Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:09.5866611Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:09.5867006Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:09.5867432Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:09.5867893Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:09.5868304Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:09.5868476Z ",
    "2025-11-25T22:40:09.5868716Z Driver stacktrace:)",
    "2025-11-25T22:40:11.0122073Z 25/11/25 22:40:11 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/dc9b40b6-e5b7-4050-ac7b-05ae59c75484?api-version=1.0",
    "2025-11-25T22:40:11.0155520Z 25/11/25 22:40:11 ERROR Executor: Exception in task 1.0 in stage 7.0 (TID 10)",
    "2025-11-25T22:40:11.0156481Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:11.0157433Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:11.0158116Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:11.0158730Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0159511Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:11.0172197Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:11.0177582Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:11.0178107Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:11.0178601Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:11.0179138Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:11.0179642Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0180190Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:11.0180692Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.0181446Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.0181877Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.0182302Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.0182753Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.0183236Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:11.0183622Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:11.0184071Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.0184797Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:11.0185383Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:11.0185819Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:11.0186340Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:11.0186888Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:11.0187473Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:11.0187953Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0188365Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0188782Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0189243Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:11.0189739Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.0190327Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.0190873Z \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:40:11.0191335Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:40:11.0191819Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:11.0192285Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.0192872Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.0193441Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:11.0193893Z \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:40:11.0214786Z \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:40:11.0215257Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:40:11.0215692Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:40:11.0216105Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:11.0216502Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:11.0216923Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:11.0217358Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:11.0217785Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:11.0218403Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:11.0218803Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:11.0219249Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:11.0219757Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:11.0220224Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:11.0220797Z 25/11/25 22:40:11 WARN TaskSetManager: Lost task 1.0 in stage 7.0 (TID 10) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:11.0221468Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:11.0222232Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:11.0222809Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0223399Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:11.0224057Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:11.0224823Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:11.0225267Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:11.0225762Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:11.0226328Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:11.0226914Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0227520Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:11.0228084Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.0228572Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.0229036Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.0229484Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.0229960Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.0230446Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:11.0230861Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:11.0231315Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.0231838Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:11.0232285Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:11.0232711Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:11.0233176Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:11.0233684Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:11.0252724Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:11.0253515Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0254537Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0255134Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0255744Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:11.0256282Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.0257066Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.0257737Z \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:40:11.0258344Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:40:11.0259198Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:11.0259885Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.0260618Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.0261306Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:11.0261914Z \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:40:11.0262583Z \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:40:11.0263236Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:40:11.0263845Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:40:11.0264663Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:11.0265206Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:11.0265726Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:11.0266270Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:11.0266879Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:11.0267412Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:11.0267937Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:11.0268492Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:11.0269143Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:11.0269659Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:11.0269926Z ",
    "2025-11-25T22:40:11.0270337Z 25/11/25 22:40:11 ERROR TaskSetManager: Task 1 in stage 7.0 failed 1 times; aborting job",
    "2025-11-25T22:40:11.0325904Z [info] - Usage with strange address responses *** FAILED ***",
    "2025-11-25T22:40:11.0326788Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 7.0 failed 1 times, most recent failure: Lost task 1.0 in stage 7.0 (TID 10) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:11.0327603Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:11.0328241Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:11.0414957Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0425119Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:11.0426437Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:11.0432022Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:11.0432925Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:11.0433893Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:11.0435072Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:11.0436035Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0437184Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:11.0438130Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.0439384Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.0440283Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.0450082Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.0451221Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.0451898Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:11.0452445Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:11.0452986Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.0453676Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:11.0454436Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:11.0454994Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:11.0455607Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:11.0463312Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:11.0464460Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:11.0465238Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0465860Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0466481Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.0467107Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:11.0467812Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.0468960Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.0469750Z [info] \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:40:11.0470433Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:40:11.0513490Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:11.0514474Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.0515145Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.0515739Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:11.0516222Z [info] \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:40:11.0516773Z [info] \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:40:11.0517289Z [info] \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:40:11.0517782Z [info] \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:40:11.0518455Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:11.0518923Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:11.0519404Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:11.0519907Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:11.0520420Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:11.0520919Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:11.0521400Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:11.0521972Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:11.0522488Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:11.0522961Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:11.0523288Z [info] ",
    "2025-11-25T22:40:11.0523568Z [info] Driver stacktrace:",
    "2025-11-25T22:40:11.0524005Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:11.0524718Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:40:11.0525191Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:11.0525729Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:11.0526236Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:40:11.0526697Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:11.0527215Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:11.0527794Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:11.0528268Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:40:11.0528706Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:11.0529108Z [info]   ...",
    "2025-11-25T22:40:11.0529437Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:11.0529922Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:11.0530504Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:11.0531069Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0531647Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:11.0532451Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:11.0532986Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:11.0533450Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:11.0533953Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:11.0534759Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:11.0535311Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:11.0535696Z [info]   ...",
    "2025-11-25T22:40:11.0535985Z [info] + Test Usage with strange address responses took 1.681s ",
    "2025-11-25T22:40:11.4998200Z 25/11/25 22:40:11 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/5aec5454-d49b-4083-b8b8-9310273c8ee0?api-version=1.0",
    "2025-11-25T22:40:11.5046811Z 25/11/25 22:40:11 WARN TaskSetManager: Lost task 0.0 in stage 7.0 (TID 9) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 1 in stage 7.0 failed 1 times, most recent failure: Lost task 1.0 in stage 7.0 (TID 10) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:11.5051307Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:11.5055519Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:11.5059697Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:11.5064380Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:11.5068431Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:11.5072395Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:11.5076408Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:11.5082031Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:11.5085690Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:11.5089057Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:11.5091567Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:11.5114653Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.5115211Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.5115658Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:11.5116124Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:11.5116661Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.5117129Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:11.5117528Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:11.5117953Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:11.5118452Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:11.5119173Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:11.5119564Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:11.5120029Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:11.5120523Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:11.5121020Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:11.5121458Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.5121827Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.5122313Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:11.5122720Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:11.5123178Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.5123706Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.5124387Z \tat scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:477)",
    "2025-11-25T22:40:11.5124834Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithoutKey_0$(Unknown Source)",
    "2025-11-25T22:40:11.5125309Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:11.5125755Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:11.5126305Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:11.5126821Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:11.5127251Z \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)",
    "2025-11-25T22:40:11.5127723Z \tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)",
    "2025-11-25T22:40:11.5128164Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)",
    "2025-11-25T22:40:11.5128576Z \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)",
    "2025-11-25T22:40:11.5128977Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:11.5129361Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:11.5129773Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:11.5130205Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:11.5130638Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:11.5131045Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:11.5131425Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:11.5131849Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:11.5132309Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:11.5132701Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:11.5132876Z ",
    "2025-11-25T22:40:11.5133116Z Driver stacktrace:)",
    "2025-11-25T22:40:12.2229277Z 25/11/25 22:40:12 WARN HandlingUtils: got error  401: Unauthorized on https://atlas.microsoft.com/search/address/reverse/batch/2e39d80c-5d1c-4ab4-a148-5a71412fd77d?api-version=1.0",
    "2025-11-25T22:40:12.2238978Z 25/11/25 22:40:12 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 11)",
    "2025-11-25T22:40:12.2241694Z java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:12.2242867Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:12.2243912Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:12.2244863Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2245512Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:12.2246177Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:12.2246968Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:12.2247468Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:12.2248087Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:12.2248876Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:12.2255009Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2255814Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:12.2256420Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:12.2256967Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:12.2257506Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:12.2258048Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:12.2258623Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:12.2259203Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:12.2259708Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:12.2260251Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:12.2268400Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:12.2269046Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:12.2269573Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:12.2270168Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:12.2270804Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:12.2271437Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:12.2271992Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2272484Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2272961Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2273597Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:12.2274381Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:12.2275160Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:12.2276051Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2276573Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2277107Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2277623Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:40:12.2278145Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2278702Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:12.2279294Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:12.2280118Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:12.2280927Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:12.2281483Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:12.2282001Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:12.2286094Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:12.2286751Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:12.2287264Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:12.2287794Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:12.2288324Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:12.2289212Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:12.2289762Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:12.2315015Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:12.2315705Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:12.2316251Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:12.2316751Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:12.2317275Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:12.2317826Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:12.2318321Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:12.2318978Z 25/11/25 22:40:12 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 11) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:12.2319672Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:12.2320285Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:12.2331607Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2332346Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:12.2333108Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:12.2333691Z \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:12.2337761Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:12.2338444Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:12.2344438Z \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:12.2345347Z \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2346630Z \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:12.2347262Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:12.2347870Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:12.2348520Z \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:12.2354897Z \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:12.2356548Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:12.2358129Z \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:12.2358660Z \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:12.2359163Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:12.2359743Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:12.2360249Z \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:12.2360778Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:12.2361391Z \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:12.2364986Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:12.2365679Z \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:12.2391623Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2392308Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2392860Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2393525Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:12.2394290Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:12.2394999Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:12.2460030Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2460605Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2461037Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2461447Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:40:12.2461906Z \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2462356Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:12.2462861Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:12.2463466Z \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:12.2464065Z \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:12.2464803Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:12.2465270Z \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:12.2465944Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:12.2466389Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:12.2466781Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:12.2467163Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:12.2467586Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:12.2467979Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:12.2468390Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:12.2468860Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:12.2469316Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:12.2469873Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:12.2470311Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:12.2470773Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:12.2471253Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:12.2471671Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:12.2471858Z ",
    "2025-11-25T22:40:12.2472235Z 25/11/25 22:40:12 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job",
    "2025-11-25T22:40:12.2472615Z [info] - Basic Batch Reverse Geocode Usage *** FAILED ***",
    "2025-11-25T22:40:12.2473224Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 11) (runnervmr8kkp.wvss2wrgoakedgvptaagxbm3bb.ex.internal.cloudapp.net executor driver): java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:12.2473952Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:12.2474756Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:12.2475300Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2475856Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:12.2476455Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:12.2476959Z [info] \tat scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:12.2477377Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:12.2477858Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:12.2478399Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:12.2478927Z [info] \tat com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2479499Z [info] \tat com.microsoft.azure.synapse.ml.services.CognitiveServicesBaseNoHandler.$anonfun$getInternalTransformer$7(CognitiveServiceBase.scala:589)",
    "2025-11-25T22:40:12.2480026Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:12.2480477Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:12.2480927Z [info] \tat org.apache.spark.injections.UDFUtils$$anon$2.call(UDFUtils.scala:29)",
    "2025-11-25T22:40:12.2481382Z [info] \tat org.apache.spark.sql.internal.ToScalaUDF$.$anonfun$apply$14(ToScalaUDF.scala:107)",
    "2025-11-25T22:40:12.2482026Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.$anonfun$handle$2(HTTPClients.scala:200)",
    "2025-11-25T22:40:12.2482526Z [info] \tat scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)",
    "2025-11-25T22:40:12.2482957Z [info] \tat scala.concurrent.package$.blocking(package.scala:124)",
    "2025-11-25T22:40:12.2483395Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.handle(HTTPClients.scala:200)",
    "2025-11-25T22:40:12.2483909Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.$anonfun$sendRequestWithContext$1(HTTPClients.scala:59)",
    "2025-11-25T22:40:12.2484558Z [info] \tat scala.Option.map(Option.scala:242)",
    "2025-11-25T22:40:12.2484986Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext(HTTPClients.scala:58)",
    "2025-11-25T22:40:12.2485491Z [info] \tat com.microsoft.azure.synapse.ml.io.http.HTTPClient.sendRequestWithContext$(HTTPClients.scala:57)",
    "2025-11-25T22:40:12.2486135Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedHTTPClient.sendRequestWithContext(HTTPClients.scala:196)",
    "2025-11-25T22:40:12.2486693Z [info] \tat com.microsoft.azure.synapse.ml.io.http.SingleThreadedClient.$anonfun$sendRequestsWithContext$1(Clients.scala:43)",
    "2025-11-25T22:40:12.2487178Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2487581Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2487976Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:40:12.2488419Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)",
    "2025-11-25T22:40:12.2488901Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:12.2489651Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:12.2490220Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2490628Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2491053Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2491450Z [info] \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)",
    "2025-11-25T22:40:12.2491851Z [info] \tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)",
    "2025-11-25T22:40:12.2492262Z [info] \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)",
    "2025-11-25T22:40:12.2492695Z [info] \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
    "2025-11-25T22:40:12.2493245Z [info] \tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)",
    "2025-11-25T22:40:12.2493830Z [info] \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)",
    "2025-11-25T22:40:12.2494452Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)",
    "2025-11-25T22:40:12.2494938Z [info] \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)",
    "2025-11-25T22:40:12.2495365Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:40:12.2495761Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:40:12.2496154Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:40:12.2496532Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:40:12.2496949Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:40:12.2497339Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:40:12.2497740Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:40:12.2498323Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:40:12.2498788Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:40:12.2499216Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:40:12.2499660Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:40:12.2500095Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:40:12.2500565Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:40:12.2501050Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:40:12.2501342Z [info] ",
    "2025-11-25T22:40:12.2501712Z [info] Driver stacktrace:",
    "2025-11-25T22:40:12.2502004Z Info Provided - Suite AzMapsSearchReverseAddressSuite took 5.161s",
    "2025-11-25T22:40:12.2571402Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:12.2575658Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:40:12.2576863Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:40:12.2578037Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:12.2580178Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:40:12.2580824Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:40:12.2582980Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:12.2583669Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:12.2584476Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:40:12.2585052Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:40:12.2636718Z [info]   ...",
    "2025-11-25T22:40:12.2637887Z [info]   Cause: java.lang.RuntimeException: Received unknown status code: 401",
    "2025-11-25T22:40:12.2638656Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult(AzureMapsTraits.scala:107)",
    "2025-11-25T22:40:12.2639394Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.queryForResult$(AzureMapsTraits.scala:93)",
    "2025-11-25T22:40:12.2639945Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.queryForResult(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2640483Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2(AzureMapsTraits.scala:119)",
    "2025-11-25T22:40:12.2641047Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.$anonfun$handlingFunc$2$adapted(AzureMapsTraits.scala:118)",
    "2025-11-25T22:40:12.2641551Z [info]   at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)",
    "2025-11-25T22:40:12.2641981Z [info]   at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)",
    "2025-11-25T22:40:12.2642447Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc(AzureMapsTraits.scala:126)",
    "2025-11-25T22:40:12.2642980Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.MapsAsyncReply.handlingFunc$(AzureMapsTraits.scala:111)",
    "2025-11-25T22:40:12.2643505Z [info]   at com.microsoft.azure.synapse.ml.services.geospatial.ReverseAddressGeocoder.handlingFunc(Geocoders.scala:78)",
    "2025-11-25T22:40:12.2643881Z [info]   ...",
    "2025-11-25T22:40:12.2644586Z [info] + Test Basic Batch Reverse Geocode Usage took 1.21s ",
    "2025-11-25T22:40:12.3026977Z [info] AzMapsPointInPolygonSuite:",
    "2025-11-25T22:40:12.7469533Z RETRYING after 3000 ms:  Caught error: java.lang.RuntimeException: Resource location is empty in LongRunningOperationResult ",
    "2025-11-25T22:40:15.8805534Z RETRYING after 5000 ms:  Caught error: java.lang.RuntimeException: Resource location is empty in LongRunningOperationResult ",
    "2025-11-25T22:40:25.6965245Z [info] - Serialization Fuzzing",
    "2025-11-25T22:40:25.6966816Z [info] + Test Serialization Fuzzing took 4.528s ",
    "2025-11-25T22:40:25.7830448Z [info] - Experiment Fuzzing",
    "2025-11-25T22:40:25.7843523Z [info] + Test Experiment Fuzzing took 0.09s ",
    "2025-11-25T22:40:25.7856986Z Testing parameter AADToken",
    "2025-11-25T22:40:25.7870323Z 25/11/25 22:40:25 WARN DefaultParamInfo: unsupported type CheckPointInPolygon_5d41b5651b0e__AADToken",
    "2025-11-25T22:40:25.7878253Z Could not test Service parameter value API  AADToken",
    "2025-11-25T22:40:25.7882436Z Testing parameter concurrency",
    "2025-11-25T22:40:25.7890227Z Testing parameter concurrentTimeout",
    "2025-11-25T22:40:25.7898167Z Could not test parameter concurrentTimeout",
    "2025-11-25T22:40:25.7907912Z Testing parameter errorCol",
    "2025-11-25T22:40:25.7908536Z Testing parameter handler",
    "2025-11-25T22:40:25.7913158Z Could not test parameter handler",
    "2025-11-25T22:40:25.7926501Z Testing parameter latitude",
    "2025-11-25T22:40:25.7927177Z Could not test Service parameter value API  latitude",
    "2025-11-25T22:40:25.7927734Z Testing parameter longitude",
    "2025-11-25T22:40:25.7928213Z Could not test Service parameter value API  longitude",
    "2025-11-25T22:40:25.7928676Z Testing parameter outputCol",
    "2025-11-25T22:40:25.7929578Z Testing parameter subscriptionKey",
    "2025-11-25T22:40:25.7935205Z Testing parameter timeout",
    "2025-11-25T22:40:25.7938226Z Testing parameter url",
    "2025-11-25T22:40:25.7943139Z Testing parameter userDataIdentifier",
    "2025-11-25T22:40:25.7960625Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:40:25.7961196Z Using b81448ae-3bfc-4801-98d1-ff066cc268a9 as the user-data identifier for these tests",
    "2025-11-25T22:40:25.7981201Z [info] + Test Getters and Setters work as anticipated took 0.012s ",
    "2025-11-25T22:40:26.5517088Z [info] - Point in Polygon: Basic Usage",
    "2025-11-25T22:40:26.5543858Z [info] + Test Point in Polygon: Basic Usage took 0.757s ",
    "2025-11-25T22:40:27.0740081Z [info] Run completed in 38 seconds, 787 milliseconds.",
    "2025-11-25T22:40:27.0755807Z [info] Total number of tests run: 13",
    "2025-11-25T22:40:27.0760915Z [info] Suites: completed 3, aborted 0",
    "2025-11-25T22:40:27.0762222Z [info] Tests: succeeded 8, failed 5, canceled 0, ignored 0, pending 0",
    "2025-11-25T22:40:27.0762752Z [info] *** 5 TESTS FAILED ***",
    "2025-11-25T22:40:27.0783322Z [error] Failed tests:",
    "2025-11-25T22:40:27.0786412Z [error] \tcom.microsoft.azure.synapse.ml.services.geospatial.AzMapsSearchReverseAddressSuite",
    "2025-11-25T22:40:27.0788636Z [error] \tcom.microsoft.azure.synapse.ml.services.geospatial.AzMapsSearchAddressSuite",
    "2025-11-25T22:40:27.0814792Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:40:27.0815855Z [info] No tests to run for Test / testOnly",
    "2025-11-25T22:40:27.1402846Z [error] (cognitive / Test / testOnly) sbt.TestsFailedException: Tests unsuccessful",
    "2025-11-25T22:40:27.1471759Z [error] Total time: 46 s, completed Nov 25, 2025, 10:40:27 PM",
    "2025-11-25T22:40:27.5281462Z ",
    "2025-11-25T22:40:27.5298734Z ##[error]Script failed with exit code: 1",
    "2025-11-25T22:40:27.5305005Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account clear",
    "2025-11-25T22:40:27.9525966Z ##[section]Finishing: Unit Test"
  ]
}
