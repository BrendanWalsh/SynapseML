{
  "continuation_token": null,
  "count": 6236,
  "value": [
    "2025-11-25T22:40:18.6311612Z ##[section]Starting: Unit Test",
    "2025-11-25T22:40:18.6319244Z ==============================================================================",
    "2025-11-25T22:40:18.6319627Z Task         : Azure CLI",
    "2025-11-25T22:40:18.6319765Z Description  : Run Azure CLI commands against an Azure subscription in a PowerShell Core/Shell script when running on Linux agent or PowerShell/PowerShell Core/Batch script when running on Windows agent.",
    "2025-11-25T22:40:18.6320107Z Version      : 2.264.0",
    "2025-11-25T22:40:18.6320249Z Author       : Microsoft Corporation",
    "2025-11-25T22:40:18.6320390Z Help         : https://docs.microsoft.com/azure/devops/pipelines/tasks/deploy/azure-cli",
    "2025-11-25T22:40:18.6320556Z ==============================================================================",
    "2025-11-25T22:40:19.0672231Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az version",
    "2025-11-25T22:40:19.4200799Z {",
    "2025-11-25T22:40:19.4204580Z   \"azure-cli\": \"2.60.0\",",
    "2025-11-25T22:40:19.4206033Z   \"azure-cli-core\": \"2.60.0\",",
    "2025-11-25T22:40:19.4211889Z   \"azure-cli-telemetry\": \"1.1.0\",",
    "2025-11-25T22:40:19.4215506Z   \"extensions\": {",
    "2025-11-25T22:40:19.4217174Z     \"azure-devops\": \"1.0.2\"",
    "2025-11-25T22:40:19.4218642Z   }",
    "2025-11-25T22:40:19.4219375Z }",
    "2025-11-25T22:40:19.4270234Z Setting AZURE_CONFIG_DIR env variable to: /home/vsts/work/_temp/.azclitask",
    "2025-11-25T22:40:19.4271721Z Setting active cloud to: AzureCloud",
    "2025-11-25T22:40:19.4272100Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az cloud set -n AzureCloud",
    "2025-11-25T22:40:20.1998584Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az login --service-principal -u *** --tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 --allow-no-subscriptions --federated-token ***",
    "2025-11-25T22:40:21.3808462Z [",
    "2025-11-25T22:40:21.3819146Z   {",
    "2025-11-25T22:40:21.3820015Z     \"cloudName\": \"AzureCloud\",",
    "2025-11-25T22:40:21.3820476Z     \"homeTenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:40:21.3820940Z     \"id\": \"e342c2c0-f844-4b18-9208-52c8c234c30e\",",
    "2025-11-25T22:40:21.4029429Z     \"isDefault\": true,",
    "2025-11-25T22:40:21.4029981Z     \"managedByTenants\": [",
    "2025-11-25T22:40:21.4030217Z       {",
    "2025-11-25T22:40:21.4030483Z         \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"",
    "2025-11-25T22:40:21.4030759Z       }",
    "2025-11-25T22:40:21.4030958Z     ],",
    "2025-11-25T22:40:21.4031200Z     \"name\": \"Synapse_OSS_ML_DevTest_001\",",
    "2025-11-25T22:40:21.4031476Z     \"state\": \"Enabled\",",
    "2025-11-25T22:40:21.4031750Z     \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:40:21.4032015Z     \"user\": {",
    "2025-11-25T22:40:21.4032426Z       \"name\": \"***\",",
    "2025-11-25T22:40:21.4032675Z       \"type\": \"servicePrincipal\"",
    "2025-11-25T22:40:21.4032916Z     }",
    "2025-11-25T22:40:21.4033136Z   }",
    "2025-11-25T22:40:21.4033336Z ]",
    "2025-11-25T22:40:21.4033664Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account set --subscription e342c2c0-f844-4b18-9208-52c8c234c30e",
    "2025-11-25T22:40:22.0093863Z [command]/usr/bin/bash /home/vsts/work/_temp/azureclitaskscript1764110419062.sh",
    "2025-11-25T22:40:24.4583372Z [info] welcome to sbt 1.10.11 (Eclipse Adoptium Java 17.0.17)",
    "2025-11-25T22:40:25.8389750Z [info] loading settings for project s-build from assembly.sbt, build.sbt, plugins.sbt...",
    "2025-11-25T22:40:26.9533641Z [info] loading project definition from /home/vsts/work/1/s/project",
    "2025-11-25T22:40:29.5689686Z [info] loading settings for project root from build.sbt, sonatype.sbt...",
    "2025-11-25T22:40:30.4578430Z [warn] Secret pgp-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:40:30.4603858Z [warn] Secret pgp-public not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:40:30.4604675Z [warn] Secret pgp-private not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:40:31.4958692Z [info] set current project to synapseml (in build file:/home/vsts/work/1/s/)",
    "2025-11-25T22:40:31.9031260Z [warn] Secret nexus-un not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:40:31.9032878Z [warn] Secret nexus-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:40:31.9076524Z [warn] Secret ado-feed-token not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:40:42.4480880Z [info] RankingAdapterModelSpec:",
    "2025-11-25T22:40:43.0983010Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties",
    "2025-11-25T22:40:43.1249903Z 25/11/25 22:40:43 INFO RecommendationIndexer: {\"protocolVersion\":\"0.0.1\",\"method\":\"constructor\",\"libraryName\":\"SynapseML\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RecommendationIndexer\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RecommendationIndexer_6dd2a72a245a\"}",
    "2025-11-25T22:40:44.5642300Z 25/11/25 22:40:44 INFO SparkContext: Running Spark version 4.0.1",
    "2025-11-25T22:40:44.5654756Z 25/11/25 22:40:44 INFO SparkContext: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:40:44.5665036Z 25/11/25 22:40:44 INFO SparkContext: Java version 17.0.17",
    "2025-11-25T22:40:44.7820822Z 25/11/25 22:40:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable",
    "2025-11-25T22:40:44.8527069Z 25/11/25 22:40:44 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:40:44.8538616Z 25/11/25 22:40:44 INFO ResourceUtils: No custom resources configured for spark.driver.",
    "2025-11-25T22:40:44.8546538Z 25/11/25 22:40:44 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:40:44.8581145Z 25/11/25 22:40:44 INFO SparkContext: Submitted application: com.microsoft.azure.synapse.ml.core.test.base.TestBase$@16806222",
    "2025-11-25T22:40:44.8641040Z 25/11/25 22:40:44 INFO SparkContext: Spark configuration:",
    "2025-11-25T22:40:44.8641776Z spark.app.name=com.microsoft.azure.synapse.ml.core.test.base.TestBase$@16806222",
    "2025-11-25T22:40:44.8642229Z spark.app.startTime=1764110444556",
    "2025-11-25T22:40:44.8643597Z spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:40:44.8644972Z spark.driver.maxResultSize=6g",
    "2025-11-25T22:40:44.8646318Z spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:40:44.8647686Z spark.hadoop.fs.s3a.vectored.read.max.merged.size=2M",
    "2025-11-25T22:40:44.8648645Z spark.hadoop.fs.s3a.vectored.read.min.seek.size=128K",
    "2025-11-25T22:40:44.8649022Z spark.logConf=true",
    "2025-11-25T22:40:44.8649382Z spark.master=local[*]",
    "2025-11-25T22:40:44.8649730Z spark.sql.crossJoin.enabled=true",
    "2025-11-25T22:40:44.8650102Z spark.sql.shuffle.partitions=20",
    "2025-11-25T22:40:44.8650495Z spark.sql.warehouse.dir=file:/home/vsts/work/1/s/core/spark-warehouse",
    "2025-11-25T22:40:44.8930198Z 25/11/25 22:40:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)",
    "2025-11-25T22:40:44.8956268Z 25/11/25 22:40:44 INFO ResourceProfile: Limiting resource is cpu",
    "2025-11-25T22:40:44.8971216Z 25/11/25 22:40:44 INFO ResourceProfileManager: Added ResourceProfile id: 0",
    "2025-11-25T22:40:44.9591757Z 25/11/25 22:40:44 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:40:44.9621714Z 25/11/25 22:40:44 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:40:44.9622358Z 25/11/25 22:40:44 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:40:44.9622740Z 25/11/25 22:40:44 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:40:44.9644675Z 25/11/25 22:40:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:40:45.2701034Z 25/11/25 22:40:45 INFO Utils: Successfully started service 'sparkDriver' on port 38225.",
    "2025-11-25T22:40:45.2995174Z 25/11/25 22:40:45 INFO SparkEnv: Registering MapOutputTracker",
    "2025-11-25T22:40:45.3129369Z 25/11/25 22:40:45 INFO SparkEnv: Registering BlockManagerMaster",
    "2025-11-25T22:40:45.3284980Z 25/11/25 22:40:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information",
    "2025-11-25T22:40:45.3302718Z 25/11/25 22:40:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up",
    "2025-11-25T22:40:45.3337336Z 25/11/25 22:40:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat",
    "2025-11-25T22:40:45.3577162Z 25/11/25 22:40:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5884ea46-b4bf-465b-ba40-3538d76dcee2",
    "2025-11-25T22:40:45.4076038Z 25/11/25 22:40:45 INFO SparkEnv: Registering OutputCommitCoordinator",
    "2025-11-25T22:40:45.5417831Z 25/11/25 22:40:45 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI",
    "2025-11-25T22:40:45.6194823Z 25/11/25 22:40:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.",
    "2025-11-25T22:40:45.6948444Z 25/11/25 22:40:45 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:40:45.6950008Z 25/11/25 22:40:45 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:40:45.6950884Z 25/11/25 22:40:45 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:40:45.6968547Z 25/11/25 22:40:45 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:40:45.6969977Z 25/11/25 22:40:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:40:45.8587741Z 25/11/25 22:40:45 INFO Executor: Starting executor ID driver on host runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net",
    "2025-11-25T22:40:45.8590241Z 25/11/25 22:40:45 INFO Executor: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:40:45.8610813Z 25/11/25 22:40:45 INFO Executor: Java version 17.0.17",
    "2025-11-25T22:40:45.8759728Z 25/11/25 22:40:45 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''",
    "2025-11-25T22:40:45.8790852Z 25/11/25 22:40:45 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@33e1bd6a for default.",
    "2025-11-25T22:40:45.9051872Z 25/11/25 22:40:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36399.",
    "2025-11-25T22:40:45.9152011Z 25/11/25 22:40:45 INFO NettyBlockTransferService: Server created on runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net:36399",
    "2025-11-25T22:40:45.9201592Z 25/11/25 22:40:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy",
    "2025-11-25T22:40:45.9432144Z 25/11/25 22:40:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 36399, None)",
    "2025-11-25T22:40:45.9530666Z 25/11/25 22:40:45 INFO BlockManagerMasterEndpoint: Registering block manager runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net:36399 with 861.6 MiB RAM, BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 36399, None)",
    "2025-11-25T22:40:45.9581571Z 25/11/25 22:40:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 36399, None)",
    "2025-11-25T22:40:45.9585612Z 25/11/25 22:40:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 36399, None)",
    "2025-11-25T22:40:57.4513830Z 25/11/25 22:40:57 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS",
    "2025-11-25T22:41:08.3915310Z [info] - Serialization Fuzzing",
    "2025-11-25T22:41:08.4182172Z [info] + Test Serialization Fuzzing took 25.882s ",
    "2025-11-25T22:41:10.2330140Z [info] - Experiment Fuzzing",
    "2025-11-25T22:41:10.2460331Z [info] + Test Experiment Fuzzing took 1.812s ",
    "2025-11-25T22:41:11.6933432Z Testing parameter itemCol",
    "2025-11-25T22:41:11.6955126Z Testing parameter k",
    "2025-11-25T22:41:11.6979014Z Testing parameter labelCol",
    "2025-11-25T22:41:11.6979521Z Testing parameter minRatingsPerItem",
    "2025-11-25T22:41:11.6979814Z Testing parameter minRatingsPerUser",
    "2025-11-25T22:41:11.6992213Z Testing parameter mode",
    "2025-11-25T22:41:11.7009920Z Testing parameter ratingCol",
    "2025-11-25T22:41:11.7010809Z Testing parameter recommender",
    "2025-11-25T22:41:11.7136119Z 25/11/25 22:41:11 WARN DefaultParamInfo: unsupported type RankingAdapterModel_c7efc90ad414__recommender",
    "2025-11-25T22:41:11.7139370Z Could not test parameter recommender",
    "2025-11-25T22:41:11.7140871Z Testing parameter recommenderModel",
    "2025-11-25T22:41:11.7142337Z Testing parameter userCol",
    "2025-11-25T22:41:11.7213578Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:41:11.7215842Z [info] + Test Getters and Setters work as anticipated took 1.48s ",
    "2025-11-25T22:41:11.7254016Z Alert Provided - Suite RankingAdapterModelSpec took 29.174s",
    "2025-11-25T22:41:11.7749677Z 25/11/25 22:41:11 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:11.8159365Z [info] RankingAdapterSpec:",
    "2025-11-25T22:41:29.3225564Z [info] - Serialization Fuzzing",
    "2025-11-25T22:41:29.3250658Z [info] + Test Serialization Fuzzing took 17.579s ",
    "2025-11-25T22:41:30.6842483Z [info] - Experiment Fuzzing",
    "2025-11-25T22:41:30.6843618Z [info] + Test Experiment Fuzzing took 1.359s ",
    "2025-11-25T22:41:30.6868559Z Testing parameter itemCol",
    "2025-11-25T22:41:30.6869623Z Testing parameter k",
    "2025-11-25T22:41:30.6890498Z Testing parameter labelCol",
    "2025-11-25T22:41:30.6891266Z Testing parameter minRatingsPerItem",
    "2025-11-25T22:41:30.6891734Z Testing parameter minRatingsPerUser",
    "2025-11-25T22:41:30.6920397Z Testing parameter mode",
    "2025-11-25T22:41:30.6921162Z Testing parameter ratingCol",
    "2025-11-25T22:41:30.6921954Z Testing parameter recommender",
    "2025-11-25T22:41:30.6922543Z Could not test parameter recommender",
    "2025-11-25T22:41:30.6923076Z Testing parameter userCol",
    "2025-11-25T22:41:30.6923601Z Alert Provided - Suite RankingAdapterSpec took 18.946s",
    "2025-11-25T22:41:30.6984645Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:41:30.6985724Z [info] + Test Getters and Setters work as anticipated took 0.008s ",
    "2025-11-25T22:41:30.7138763Z [info] SARModelSpec:",
    "2025-11-25T22:41:30.7406459Z 25/11/25 22:41:30 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:39.2219562Z [info] - Serialization Fuzzing",
    "2025-11-25T22:41:39.2220506Z [info] + Test Serialization Fuzzing took 8.52s ",
    "2025-11-25T22:41:40.0544380Z [info] - Experiment Fuzzing",
    "2025-11-25T22:41:40.0545308Z [info] + Test Experiment Fuzzing took 0.83s ",
    "2025-11-25T22:41:40.8559529Z Testing parameter activityTimeFormat",
    "2025-11-25T22:41:40.8569725Z Could not test parameter activityTimeFormat",
    "2025-11-25T22:41:40.8575452Z Testing parameter alpha",
    "2025-11-25T22:41:40.8583913Z Testing parameter blockSize",
    "2025-11-25T22:41:40.8591758Z Testing parameter checkpointInterval",
    "2025-11-25T22:41:40.8598735Z Testing parameter coldStartStrategy",
    "2025-11-25T22:41:40.8605563Z Testing parameter finalStorageLevel",
    "2025-11-25T22:41:40.8613451Z Testing parameter implicitPrefs",
    "2025-11-25T22:41:40.8620950Z Testing parameter intermediateStorageLevel",
    "2025-11-25T22:41:40.8641680Z Testing parameter itemCol",
    "2025-11-25T22:41:40.8643620Z Testing parameter itemDataFrame",
    "2025-11-25T22:41:40.8644993Z Testing parameter maxIter",
    "2025-11-25T22:41:40.8650715Z Testing parameter nonnegative",
    "2025-11-25T22:41:40.8651547Z Testing parameter numItemBlocks",
    "2025-11-25T22:41:40.8652130Z Testing parameter numUserBlocks",
    "2025-11-25T22:41:40.8652784Z Testing parameter predictionCol",
    "2025-11-25T22:41:40.8681109Z Testing parameter rank",
    "2025-11-25T22:41:40.8682584Z Testing parameter ratingCol",
    "2025-11-25T22:41:40.8683268Z Testing parameter regParam",
    "2025-11-25T22:41:40.8683543Z Testing parameter seed",
    "2025-11-25T22:41:40.8683833Z Testing parameter similarityFunction",
    "2025-11-25T22:41:40.8684511Z Could not test parameter similarityFunction",
    "2025-11-25T22:41:40.8684886Z Testing parameter startTime",
    "2025-11-25T22:41:40.8685202Z Could not test parameter startTime",
    "2025-11-25T22:41:40.8685489Z Testing parameter startTimeFormat",
    "2025-11-25T22:41:40.8691841Z Could not test parameter startTimeFormat",
    "2025-11-25T22:41:40.8696676Z Testing parameter supportThreshold",
    "2025-11-25T22:41:40.8717812Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:41:40.8721112Z Could not test parameter supportThreshold",
    "2025-11-25T22:41:40.8721439Z Testing parameter timeCol",
    "2025-11-25T22:41:40.8721708Z Could not test parameter timeCol",
    "2025-11-25T22:41:40.8721972Z Testing parameter timeDecayCoeff",
    "2025-11-25T22:41:40.8722259Z Could not test parameter timeDecayCoeff",
    "2025-11-25T22:41:40.8722525Z Testing parameter userCol",
    "2025-11-25T22:41:40.8722787Z Testing parameter userDataFrame",
    "2025-11-25T22:41:40.8723141Z [info] + Test Getters and Setters work as anticipated took 0.82s ",
    "2025-11-25T22:41:40.8730665Z Alert Provided - Suite SARModelSpec took 10.17s",
    "2025-11-25T22:41:40.8898995Z [info] RankingEvaluatorSpec:",
    "2025-11-25T22:41:41.0083722Z 25/11/25 22:41:41 WARN BlockManager: Putting block rdd_3191_0 failed due to exception scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:41.0121839Z 25/11/25 22:41:41 WARN BlockManager: Block rdd_3191_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:41.0141648Z 25/11/25 22:41:41 ERROR Executor: Exception in task 0.0 in stage 1930.0 (TID 1969)",
    "2025-11-25T22:41:41.0142456Z scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.0143127Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.0143716Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.0144267Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.0144802Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.0159246Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.0160321Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.0160878Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.0161349Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.0161831Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.0162286Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.0162678Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.0163094Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0163549Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0164081Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0164519Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0164960Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0165362Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0165793Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0166225Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0166627Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0167050Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.0167489Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.0167903Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.0168492Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.0168979Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.0169478Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.0169929Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.0170362Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.0171042Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.0171622Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.0172157Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.0340650Z 25/11/25 22:41:41 WARN TaskSetManager: Lost task 0.0 in stage 1930.0 (TID 1969) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.0365880Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.0366701Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.0367274Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.0367919Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.0368700Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.0730764Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.0731347Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.0842813Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.0843810Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.0844530Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.0844900Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.0845310Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0845719Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0846090Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0846493Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0846903Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0847274Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0847673Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0848078Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0848709Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0849107Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.0849519Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.0849921Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.0850318Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.0850756Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.0851214Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.0851628Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.0852027Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.0852470Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.0852929Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.0853340Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.0853503Z ",
    "2025-11-25T22:41:41.0853813Z 25/11/25 22:41:41 ERROR TaskSetManager: Task 0 in stage 1930.0 failed 1 times; aborting job",
    "2025-11-25T22:41:41.0854163Z [info] - testAllTrue *** FAILED ***",
    "2025-11-25T22:41:41.0854795Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1930.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1930.0 (TID 1969) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.0855584Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.0856050Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.0856489Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.0856948Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.0857420Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.0857928Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.0889299Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.0889817Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.0890287Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.0890726Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.0891113Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.0891746Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0892168Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0892569Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0892967Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0893400Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0893780Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0894179Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.0894604Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.0895084Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.0895472Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.0895913Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.0896311Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.0896723Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.0897220Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.0897687Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.0898311Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.0898738Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.0899232Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.0899755Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.0900203Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.0900537Z [info] ",
    "2025-11-25T22:41:41.0900819Z [info] Driver stacktrace:",
    "2025-11-25T22:41:41.0901231Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.0901688Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:41.0902137Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.0902652Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.0903145Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:41.0903599Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.0904104Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.0904664Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.0905129Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:41.0905587Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.0905968Z [info]   ...",
    "2025-11-25T22:41:41.0906374Z [info]   Cause: scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.0906948Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.0907448Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.0907923Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.1009374Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.1010260Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.1010764Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.1011285Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.1011726Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.1012193Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.1012600Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.1012901Z [info]   ...",
    "2025-11-25T22:41:41.1069081Z [info] + Test testAllTrue took 0.199s ",
    "2025-11-25T22:41:41.1617097Z 25/11/25 22:41:41 WARN BlockManager: Putting block rdd_3200_0 failed due to exception scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:41.1624959Z 25/11/25 22:41:41 WARN BlockManager: Block rdd_3200_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:41.1641565Z 25/11/25 22:41:41 ERROR Executor: Exception in task 0.0 in stage 1931.0 (TID 1970)",
    "2025-11-25T22:41:41.1642573Z scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.1643657Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.1645069Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.1645585Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.1646098Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.1646615Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.1647146Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.1647656Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.1648262Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.1648758Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.1649210Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.1649616Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.1650054Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1650506Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1650911Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1651341Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1651785Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1652200Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1652628Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1653061Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1653470Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1653885Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.1654336Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.1654761Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.1655200Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.1656106Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.1656594Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.1657049Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.1657490Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.1657962Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.1658550Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.1659040Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.1701208Z 25/11/25 22:41:41 WARN TaskSetManager: Lost task 0.0 in stage 1931.0 (TID 1970) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.1702648Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.1703170Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.1703638Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.1704134Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.1704633Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.1705157Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.1705677Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.1706156Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.1706642Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.1707091Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.1707492Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.1707923Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1708551Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1708969Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1709403Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1709855Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1710265Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1710698Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1711198Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1711666Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1712088Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.1712540Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.1712976Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.1713426Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.1713910Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.1714401Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.1714866Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.1715306Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.1715783Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.1716423Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.1716866Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.1717066Z ",
    "2025-11-25T22:41:41.1717429Z 25/11/25 22:41:41 ERROR TaskSetManager: Task 0 in stage 1931.0 failed 1 times; aborting job",
    "2025-11-25T22:41:41.1762382Z [info] - testAllMiss *** FAILED ***",
    "2025-11-25T22:41:41.1799352Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1931.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1931.0 (TID 1970) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.1800783Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.1801424Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.1801963Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.1802541Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.1803117Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.1803700Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.1804282Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.1804812Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.1805371Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.1805880Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.1806352Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.1806839Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1807363Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1807833Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1808445Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1808978Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1809443Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1809947Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.1810447Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.1810930Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.1811411Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.1811914Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.1812406Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.1812902Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.1813451Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.1813992Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.1814523Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.1815070Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.1815600Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.1816322Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.1816805Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.1817182Z [info] ",
    "2025-11-25T22:41:41.1817477Z [info] Driver stacktrace:",
    "2025-11-25T22:41:41.1817858Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.1818454Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:41.1818961Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.1819547Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.1820068Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:41.1820702Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.1821286Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.1821894Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.1822407Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:41.1822831Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.1823233Z [info]   ...",
    "2025-11-25T22:41:41.1823612Z [info]   Cause: scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.1824267Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.1824863Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.1825407Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.1825958Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.1826530Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.1827117Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.1827708Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.1828319Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.1828912Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.1829447Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.1829827Z [info]   ...",
    "2025-11-25T22:41:41.1830183Z [info] + Test testAllMiss took 0.097s ",
    "2025-11-25T22:41:41.2549346Z 25/11/25 22:41:41 WARN BlockManager: Putting block rdd_3209_0 failed due to exception scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:41.2599947Z 25/11/25 22:41:41 WARN BlockManager: Block rdd_3209_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:41.2601537Z 25/11/25 22:41:41 ERROR Executor: Exception in task 0.0 in stage 1932.0 (TID 1971)",
    "2025-11-25T22:41:41.2601944Z scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.2602528Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.2602997Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.2603453Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.2604253Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.2604735Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.2605206Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.2605680Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.2606107Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.2606551Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.2606972Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.2607342Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.2607860Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2608388Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2609186Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2610059Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2610599Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2610955Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2611270Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2611614Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2611915Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2612215Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.2612757Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.2613111Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.2613498Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.2613900Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.2614334Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.2614725Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.2615086Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.2615494Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.2615907Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.2616266Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.2616816Z 25/11/25 22:41:41 WARN TaskSetManager: Lost task 0.0 in stage 1932.0 (TID 1971) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.2617438Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.2617863Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.2618340Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.2618753Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.2619181Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.2619651Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.2620097Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.2620667Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.2621071Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.2621456Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.2621779Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.2622131Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2622516Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2622853Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2623221Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2623593Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2624009Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2624379Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2624751Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2625087Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2625442Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.2625815Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.2626345Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.2626770Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.2627204Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.2627655Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.2628066Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.2628567Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.2629017Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.2629544Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.2629975Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.2630152Z ",
    "2025-11-25T22:41:41.2630455Z 25/11/25 22:41:41 ERROR TaskSetManager: Task 0 in stage 1932.0 failed 1 times; aborting job",
    "2025-11-25T22:41:41.2756351Z [info] - testOrder *** FAILED ***",
    "2025-11-25T22:41:41.2757392Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1932.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1932.0 (TID 1971) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.2789254Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.2790046Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.2790554Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.2791046Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.2791654Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.2792137Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.2792611Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.2793074Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.2793767Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.2794205Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.2794585Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.2794991Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2795430Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2795824Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2796228Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2796703Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2797091Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2797597Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.2798041Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.2798552Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.2799227Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.2799657Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.2800061Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.2800493Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.2800950Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.2801408Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.2801862Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.2802285Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.2802753Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.2803214Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.2803625Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.2803937Z [info] ",
    "2025-11-25T22:41:41.2804200Z [info] Driver stacktrace:",
    "2025-11-25T22:41:41.2804575Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.2805002Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:41.2805450Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.2805938Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.2806383Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:41.2806802Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.2807303Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.2807802Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.2808292Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:41.2808721Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.2809114Z [info]   ...",
    "2025-11-25T22:41:41.2809502Z [info]   Cause: scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.2810017Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.2810575Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.2811018Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.2811475Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.2811959Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.2812450Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.2812925Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.2813380Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.2814099Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.2814572Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.2814914Z [info]   ...",
    "2025-11-25T22:41:41.2815202Z [info] + Test testOrder took 0.094s ",
    "2025-11-25T22:41:41.3522191Z 25/11/25 22:41:41 WARN BlockManager: Putting block rdd_3218_0 failed due to exception scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:41.3544679Z 25/11/25 22:41:41 WARN BlockManager: Block rdd_3218_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:41.3545419Z 25/11/25 22:41:41 ERROR Executor: Exception in task 0.0 in stage 1933.0 (TID 1972)",
    "2025-11-25T22:41:41.3550284Z scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.3551010Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.3551560Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.3552005Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.3552501Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.3552974Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.3553503Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.3553999Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.3554470Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.3554967Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.3555398Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.3555778Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.3556203Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3556636Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3557053Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3557462Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3557895Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3558476Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3558908Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3559364Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3559786Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3560195Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.3560650Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.3561424Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.3561860Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.3562351Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.3562829Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.3563280Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.3563736Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.3564201Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.3564701Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.3565241Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.3579046Z 25/11/25 22:41:41 WARN TaskSetManager: Lost task 0.0 in stage 1933.0 (TID 1972) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.3579953Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.3582127Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.3583351Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.3584093Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.3584803Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.3588274Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.3590135Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.3591002Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.3592730Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.3593557Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.3595191Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.3596016Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3597678Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3598583Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3603390Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3604565Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3606236Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3607044Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3615951Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3616881Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3618609Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.3619401Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.3620992Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.3621686Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.3623304Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.3624081Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.3625823Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.3626420Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.3627067Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.3627727Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.3628461Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.3628857Z ",
    "2025-11-25T22:41:41.3629426Z 25/11/25 22:41:41 ERROR TaskSetManager: Task 0 in stage 1933.0 failed 1 times; aborting job",
    "2025-11-25T22:41:41.3669172Z [info] - testExtra *** FAILED ***",
    "2025-11-25T22:41:41.3670533Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1933.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1933.0 (TID 1972) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.3672923Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.3674506Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.3676058Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.3677593Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.3679854Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.3699794Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.3704695Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.3723752Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.3724401Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.3724850Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.3725335Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:41.3725701Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3726105Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3726482Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3726849Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3727257Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3727607Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3727973Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:41.3728536Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:41.3728887Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:41.3729249Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:41.3729653Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:41.3730060Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:41.3730553Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:41.3730917Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:41.3731290Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:41.3731818Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:41.3732150Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:41.3732528Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:41.3732902Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:41.3733225Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:41.3733466Z [info] ",
    "2025-11-25T22:41:41.3733661Z [info] Driver stacktrace:",
    "2025-11-25T22:41:41.3733959Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.3734303Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:41.3734715Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:41.3735105Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.3735475Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:41.3735808Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:41.3736196Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.3736600Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.3736933Z Info Provided - Suite RankingEvaluatorSpec took 0.487s",
    "2025-11-25T22:41:41.3739499Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:41.3740396Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:41.3740950Z [info]   ...",
    "2025-11-25T22:41:41.3741492Z [info]   Cause: scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:41.3742121Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:41.3746756Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:41.3747697Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:41.3748569Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:41.3749258Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:41.3750240Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:41.3750908Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:41.3751509Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:41.3762620Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:41.3763484Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:41.3768942Z [info]   ...",
    "2025-11-25T22:41:41.3769672Z [info] + Test testExtra took 0.097s ",
    "2025-11-25T22:41:41.4419552Z 25/11/25 22:41:41 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:41.4432038Z [info] RankingTrainValidationSplitModelSpec:",
    "2025-11-25T22:41:42.0486397Z 25/11/25 22:41:42 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:47.9781127Z 25/11/25 22:41:47 WARN BlockManager: Putting block rdd_3574_0 failed due to exception scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:47.9791392Z 25/11/25 22:41:47 WARN BlockManager: Block rdd_3574_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:47.9805933Z 25/11/25 22:41:47 ERROR Executor: Exception in task 0.0 in stage 2117.0 (TID 2372)",
    "2025-11-25T22:41:47.9810806Z scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:47.9812961Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:47.9814740Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:47.9816467Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:47.9818176Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:47.9819834Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:47.9821731Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:47.9830345Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:47.9830976Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:47.9831480Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:47.9831926Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:47.9832344Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:47.9832770Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:47.9833813Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:47.9834246Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:47.9834672Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:47.9835117Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:47.9835544Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:47.9857147Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:47.9857665Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:47.9858031Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:47.9858534Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:47.9858907Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:47.9859278Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:47.9859645Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:47.9860065Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:47.9860480Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:47.9860868Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:47.9861244Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:47.9861633Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:47.9862043Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:47.9862412Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:47.9863008Z 25/11/25 22:41:47 WARN TaskSetManager: Lost task 0.0 in stage 2117.0 (TID 2372) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:47.9865388Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:47.9868266Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:47.9869450Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:47.9869961Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:47.9870456Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:47.9870971Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:47.9871699Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:47.9872955Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:47.9874562Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:47.9875332Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:47.9875769Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:47.9876248Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:47.9876728Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:47.9877174Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:47.9877643Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:47.9878246Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:47.9878722Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:47.9879197Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:47.9879666Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:47.9880107Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:47.9880572Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:47.9881048Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:47.9881521Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:47.9881991Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:47.9882499Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:47.9883025Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:47.9883509Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:47.9883977Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:47.9884497Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:47.9885022Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:47.9885542Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:47.9885779Z ",
    "2025-11-25T22:41:47.9886163Z 25/11/25 22:41:47 ERROR TaskSetManager: Task 0 in stage 2117.0 failed 1 times; aborting job",
    "2025-11-25T22:41:47.9942987Z 25/11/25 22:41:47 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_161679ae54bb\"}",
    "2025-11-25T22:41:47.9945670Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:41:47.9946281Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:41:47.9948463Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:41:47.9950876Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:47.9956172Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:47.9994128Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:47.9994781Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:47.9995309Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:41:47.9995796Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:41:47.9996300Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:47.9996969Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:41:47.9997438Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:41:47.9997936Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:47.9998609Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:41:47.9999162Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testObjects(RankingTrainValidationSpec.scala:47)",
    "2025-11-25T22:41:47.9999709Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.serializationTestObjects(Fuzzing.scala:614)",
    "2025-11-25T22:41:48.0000198Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.serializationTestObjects$(Fuzzing.scala:614)",
    "2025-11-25T22:41:48.0000746Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.serializationTestObjects(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:41:48.0001329Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization(Fuzzing.scala:506)",
    "2025-11-25T22:41:48.0001836Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization$(Fuzzing.scala:504)",
    "2025-11-25T22:41:48.0002399Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testSerialization(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:41:48.0002944Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$$init$$2(Fuzzing.scala:539)",
    "2025-11-25T22:41:48.0003385Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:41:48.0003745Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:41:48.0004107Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:41:48.0004481Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:41:48.0004841Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:41:48.0005232Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:41:48.0005644Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:41:48.0006014Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:41:48.0006398Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:48.0006842Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:41:48.0007295Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:41:48.0007715Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:41:48.0008170Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:41:48.0008593Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:41:48.0009106Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:41:48.0009710Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:41:48.0010162Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:41:48.0010619Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:41:48.0011055Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:41:48.0011494Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:41:48.0011879Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:48.0012250Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:41:48.0012646Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:41:48.0013089Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:41:48.0013479Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:41:48.0013918Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:41:48.0014322Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:48.0014693Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:41:48.0015020Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:41:48.0015440Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:48.0015929Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:41:48.0016319Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:41:48.0016694Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:41:48.0017108Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:41:48.0017577Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:41:48.0018060Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:41:48.0018540Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:41:48.0018927Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:41:48.0019349Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:41:48.0019787Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:41:48.0020216Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:41:48.0020605Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:41:48.0020979Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:41:48.0021390Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:48.0021848Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:48.0022232Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:48.0022902Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2117.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2117.0 (TID 2372) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:48.0023664Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:48.0024126Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:48.0024523Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:48.0025037Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:48.0025501Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:48.0025975Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:48.0026450Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:48.0026870Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:48.0027301Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:48.0027713Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:48.0028060Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:48.0071452Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0072003Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0072454Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0072934Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0073415Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0076462Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0077022Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0077506Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0077948Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0078641Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:48.0079135Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:48.0098780Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:48.0099436Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:48.0099890Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:48.0100346Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:48.0100756Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:48.0101152Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:48.0101598Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:48.0102042Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:48.0102430Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:48.0102607Z ",
    "2025-11-25T22:41:48.0102834Z Driver stacktrace:",
    "2025-11-25T22:41:48.0103200Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:48.0103589Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:48.0103978Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:48.0104446Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:48.0104860Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:48.0105267Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:48.0105714Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:48.0106191Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:48.0106613Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:48.0106994Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:48.0107638Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:41:48.0114304Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:41:48.0115313Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:41:48.0115856Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:41:48.0116346Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:41:48.0116821Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:41:48.0117293Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:41:48.0117743Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:41:48.0118591Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:48.0119123Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:48.0119592Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:48.0120036Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:41:48.0120510Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:41:48.0121026Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:48.0121546Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:48.0122007Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:48.0122467Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:41:48.0122992Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:41:48.0123495Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:41:48.0148802Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:48.0149420Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:48.0149813Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:48.0150260Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:41:48.0150689Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:41:48.0151159Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:41:48.0151682Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:41:48.0152180Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:41:48.0152694Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:41:48.0153217Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:41:48.0153785Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:41:48.0154279Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:41:48.0154667Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:41:48.0155064Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:41:48.0155463Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:41:48.0155880Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:41:48.0156327Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:41:48.0156752Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:41:48.0157384Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:41:48.0157816Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:41:48.0158619Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:41:48.0159247Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:41:48.0159800Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:48.0160352Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:41:48.0160836Z \t... 61 more",
    "2025-11-25T22:41:48.0161280Z Caused by: scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:48.0162014Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:48.0162538Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:48.0163020Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:48.0163554Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:48.0164082Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:48.0164639Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:48.0165201Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:48.0165704Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:48.0166239Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:48.0166717Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:48.0167146Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:48.0167616Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0168195Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0168704Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0169185Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0169688Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0170137Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0170593Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0171085Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0171526Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0171978Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:48.0172472Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:48.0172929Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:48.0173401Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:48.0173928Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:48.0174445Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:48.0198881Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:48.0199656Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:48.0200021Z \t... 3 more",
    "2025-11-25T22:41:48.0200431Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:41:48.0200755Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:41:48.0201395Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:41:48.0201832Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:41:48.0202333Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:48.0202939Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:48.0203434Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:48.0203933Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:48.0204537Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:41:48.0205038Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:41:48.0205551Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:48.0206062Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:41:48.0206422Z [info]   ...",
    "2025-11-25T22:41:48.0207038Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2117.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2117.0 (TID 2372) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:48.0207824Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:48.0208413Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:48.0208851Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:48.0209302Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:48.0209763Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:48.0210375Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:48.0210813Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:48.0211239Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:48.0211655Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:48.0212043Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:48.0212401Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:48.0212765Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0213149Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0213516Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0213883Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0214294Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0214646Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0215006Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:48.0215402Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:48.0215819Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:48.0216175Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:48.0216571Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:48.0216936Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:48.0217308Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:48.0217733Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:48.0218660Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:48.0219404Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:48.0219996Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:48.0220518Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:48.0221079Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:48.0221574Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:48.0221937Z [info] ",
    "2025-11-25T22:41:48.0222246Z [info] Driver stacktrace:",
    "2025-11-25T22:41:48.0222625Z 25/11/25 22:41:47 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:48.0238808Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:48.0239538Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:48.0240005Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:48.0240532Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:48.0241012Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:48.0241468Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:48.0242167Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:48.0242804Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:48.0243317Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:48.0243837Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:48.0244248Z [info]   ...",
    "2025-11-25T22:41:48.0244705Z [info]   Cause: scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:48.0245299Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:48.0245850Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:48.0246341Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:48.0246866Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:48.0247446Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:48.0248009Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:48.0248709Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:48.0249242Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:48.0249770Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:48.0250321Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:48.0250908Z [info]   ...",
    "2025-11-25T22:41:48.0251253Z [info] + Test Serialization Fuzzing took 6.616s ",
    "2025-11-25T22:41:48.2952742Z 25/11/25 22:41:48 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:48.3040582Z 25/11/25 22:41:48 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:51.8117390Z 25/11/25 22:41:51 WARN BlockManager: Putting block rdd_3877_0 failed due to exception scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:51.8119678Z 25/11/25 22:41:51 WARN BlockManager: Block rdd_3877_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:51.8129081Z 25/11/25 22:41:51 ERROR Executor: Exception in task 0.0 in stage 2271.0 (TID 2627)",
    "2025-11-25T22:41:51.8130502Z scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:51.8131213Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:51.8132592Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:51.8133371Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:51.8134534Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:51.8135499Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:51.8136155Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:51.8136750Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:51.8137263Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:51.8137771Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:51.8138368Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:51.8138831Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:51.8148692Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8149425Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8149886Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8150369Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8150855Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8151295Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8151770Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8152254Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8152703Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8153164Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:51.8153696Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:51.8154179Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:51.8154645Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:51.8155154Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:51.8155685Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:51.8156212Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:51.8156681Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:51.8157203Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:51.8158042Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:51.8169207Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:51.8173349Z 25/11/25 22:41:51 WARN TaskSetManager: Lost task 0.0 in stage 2271.0 (TID 2627) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:51.8174129Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:51.8174588Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:51.8174992Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:51.8175731Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:51.8176189Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:51.8176685Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:51.8177149Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:51.8177582Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:51.8178037Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:51.8178570Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:51.8178939Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:51.8179321Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8179725Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8180104Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8180488Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8180883Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8181260Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8181635Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8182027Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8182405Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8182769Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:51.8183169Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:51.8183560Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:51.8183954Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:51.8184407Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:51.8184839Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:51.8185246Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:51.8185651Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:51.8186079Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:51.8186524Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:51.8186925Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:51.8187083Z ",
    "2025-11-25T22:41:51.8187402Z 25/11/25 22:41:51 ERROR TaskSetManager: Task 0 in stage 2271.0 failed 1 times; aborting job",
    "2025-11-25T22:41:51.8217390Z 25/11/25 22:41:51 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_161679ae54bb\"}",
    "2025-11-25T22:41:51.8226110Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:41:51.8232361Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:41:51.8232909Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:41:51.8242001Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:51.8243700Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:51.8244628Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:51.8269186Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:51.8269820Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:41:51.8270381Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:41:51.8278770Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:51.8279579Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:41:51.8280141Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:41:51.8298541Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:51.8299295Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:41:51.8299939Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testObjects(RankingTrainValidationSpec.scala:47)",
    "2025-11-25T22:41:51.8300563Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.experimentTestObjects(Fuzzing.scala:616)",
    "2025-11-25T22:41:51.8301123Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.experimentTestObjects$(Fuzzing.scala:616)",
    "2025-11-25T22:41:51.8318813Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.experimentTestObjects(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:41:51.8319831Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments(Fuzzing.scala:441)",
    "2025-11-25T22:41:51.8320433Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments$(Fuzzing.scala:440)",
    "2025-11-25T22:41:51.8321080Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testExperiments(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:41:51.8321704Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$$init$$1(Fuzzing.scala:451)",
    "2025-11-25T22:41:51.8322205Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:41:51.8322663Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:41:51.8323103Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:41:51.8323540Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:41:51.8323990Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:41:51.8324460Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:41:51.8324954Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:41:51.8348629Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:41:51.8349160Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:51.8349873Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:41:51.8350330Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:41:51.8350734Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:41:51.8351141Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:41:51.8351563Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:41:51.8352068Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:41:51.8352579Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:41:51.8353119Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:41:51.8353587Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:41:51.8354027Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:41:51.8354465Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:41:51.8354849Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:51.8355223Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:41:51.8355617Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:41:51.8355989Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:41:51.8356384Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:41:51.8356824Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:41:51.8357237Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:51.8357601Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:41:51.8357950Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:41:51.8358489Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:51.8358987Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:41:51.8359381Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:41:51.8359760Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:41:51.8360178Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:41:51.8360645Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:41:51.8361118Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:41:51.8361539Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:41:51.8361930Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:41:51.8362358Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:41:51.8362800Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:41:51.8363233Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:41:51.8363625Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:41:51.8363992Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:41:51.8364418Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:51.8364876Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:51.8365260Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:51.8365933Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2271.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2271.0 (TID 2627) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:51.8366767Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:51.8367225Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:51.8367626Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:51.8368061Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:51.8409383Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:51.8409938Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:51.8410436Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:51.8410859Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:51.8411294Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:51.8411707Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:51.8412057Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:51.8412437Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8412852Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8413216Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8413595Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8414003Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8414368Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8414761Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8415160Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8415520Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8415901Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:51.8416300Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:51.8416678Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:51.8417084Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:51.8417517Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:51.8417957Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:51.8418506Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:51.8418899Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:51.8419337Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:51.8419783Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:51.8420171Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:51.8420345Z ",
    "2025-11-25T22:41:51.8420573Z Driver stacktrace:",
    "2025-11-25T22:41:51.8420937Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:51.8421319Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:51.8421704Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:51.8422180Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:51.8422744Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:51.8423139Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:51.8423604Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:51.8424086Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:51.8424528Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:51.8424912Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:51.8425363Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:41:51.8425914Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:41:51.8426369Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:41:51.8426809Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:41:51.8427203Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:41:51.8427597Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:41:51.8427994Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:41:51.8469236Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:41:51.8469819Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:51.8470361Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:51.8470830Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:51.8471263Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:41:51.8471755Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:41:51.8472276Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:51.8472794Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:51.8473256Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:51.8473724Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:41:51.8474253Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:41:51.8474758Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:41:51.8475251Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:51.8475779Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:51.8476241Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:51.8476715Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:41:51.8477221Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:41:51.8477771Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:41:51.8478517Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:41:51.8479141Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:41:51.8479739Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:41:51.8480367Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:41:51.8498937Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:41:51.8500165Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:41:51.8500662Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:41:51.8501150Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:41:51.8501632Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:41:51.8502130Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:41:51.8502659Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:41:51.8506670Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:41:51.8507411Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:41:51.8508310Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:41:51.8508811Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:41:51.8509351Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:41:51.8509918Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:51.8515210Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:41:51.8515921Z \t... 61 more",
    "2025-11-25T22:41:51.8534037Z Caused by: scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:51.8534847Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:51.8535406Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:51.8535900Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:51.8536587Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:51.8537132Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:51.8537684Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:51.8538353Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:51.8538885Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:51.8539412Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:51.8539882Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:51.8540306Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:51.8540783Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8558633Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8559347Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8559851Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8560335Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8560777Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8561248Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8561721Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8562173Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8571569Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:51.8572396Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:51.8572901Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:51.8573618Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:51.8579063Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:51.8579840Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:51.8580352Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:51.8580828Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:51.8581234Z \t... 3 more",
    "2025-11-25T22:41:51.8581708Z [info] - Experiment Fuzzing *** FAILED ***",
    "2025-11-25T22:41:51.8582123Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:41:51.8582596Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:41:51.8598661Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:41:51.8599452Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:51.8600134Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:51.8600722Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:51.8601168Z 25/11/25 22:41:51 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:51.8601725Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:51.8602326Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:41:51.8602880Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:41:51.8603498Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:51.8604088Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:41:51.8604523Z [info]   ...",
    "2025-11-25T22:41:51.8605243Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2271.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2271.0 (TID 2627) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:51.8606131Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:51.8606667Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:51.8618775Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:51.8628678Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:51.8629430Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:51.8630036Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:51.8630602Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:51.8631121Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:51.8631664Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:51.8632160Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:51.8632624Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:51.8633296Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8633792Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8634267Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8634738Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8635227Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8635695Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8636223Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:51.8636762Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:51.8637233Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:51.8637807Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:51.8648913Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:51.8649657Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:51.8650158Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:51.8650706Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:51.8651231Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:51.8651732Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:51.8663550Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:51.8664348Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:51.8664933Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:51.8665418Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:51.8686576Z [info] ",
    "2025-11-25T22:41:51.8698549Z [info] Driver stacktrace:",
    "2025-11-25T22:41:51.8699072Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:51.8699489Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:51.8699915Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:51.8700391Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:51.8700836Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:51.8701245Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:51.8701716Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:51.8702231Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:51.8702650Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:51.8703049Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:51.8703403Z [info]   ...",
    "2025-11-25T22:41:51.8703762Z [info]   Cause: scala.MatchError: [ArraySeq(8, 7, 3),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:51.8704289Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:51.8704744Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:51.8705159Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:51.8705626Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:51.8706292Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:51.8706793Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:51.8707268Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:51.8707700Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:51.8708277Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:51.8708698Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:51.8708990Z [info]   ...",
    "2025-11-25T22:41:51.8709260Z [info] + Test Experiment Fuzzing took 3.826s ",
    "2025-11-25T22:41:52.1123599Z 25/11/25 22:41:52 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:52.1265249Z 25/11/25 22:41:52 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:55.6008444Z 25/11/25 22:41:55 WARN BlockManager: Putting block rdd_4180_0 failed due to exception scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:41:55.6009998Z 25/11/25 22:41:55 WARN BlockManager: Block rdd_4180_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:41:55.6031804Z 25/11/25 22:41:55 ERROR Executor: Exception in task 0.0 in stage 2425.0 (TID 2882)",
    "2025-11-25T22:41:55.6035460Z scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:55.6058936Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:55.6060171Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:55.6060967Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:55.6062098Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:55.6062917Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:55.6063479Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:55.6063996Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:55.6064484Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:55.6064965Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:55.6065408Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:55.6065839Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:55.6066272Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6066724Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6067159Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6067580Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6068337Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6068850Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6069286Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6069732Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6070153Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6070559Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:55.6071003Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:55.6071439Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:55.6072252Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:55.6072836Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:55.6073336Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:55.6073785Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:55.6074244Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:55.6074718Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:55.6075212Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:55.6075662Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:55.6076409Z 25/11/25 22:41:55 WARN TaskSetManager: Lost task 0.0 in stage 2425.0 (TID 2882) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:55.6077145Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:55.6077631Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:55.6078075Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:55.6078680Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:55.6079172Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:55.6079711Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:55.6080226Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:55.6080697Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:55.6081190Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:55.6081627Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:55.6082035Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:55.6082458Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6082894Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6083325Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6083747Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6084183Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6084621Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6085042Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6085478Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6085897Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6086309Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:55.6086767Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:55.6087188Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:55.6087618Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:55.6088184Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:55.6088678Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:55.6089134Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:55.6089682Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:55.6090228Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:55.6090746Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:55.6091173Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:55.6091368Z ",
    "2025-11-25T22:41:55.6091729Z 25/11/25 22:41:55 ERROR TaskSetManager: Task 0 in stage 2425.0 failed 1 times; aborting job",
    "2025-11-25T22:41:55.6092475Z 25/11/25 22:41:55 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_161679ae54bb\"}",
    "2025-11-25T22:41:55.6093304Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:41:55.6093733Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:41:55.6094207Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:41:55.6094726Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:55.6095341Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:55.6095875Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:55.6096385Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:55.6096951Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:41:55.6097456Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:41:55.6098001Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:55.6098645Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:41:55.6099147Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:41:55.6099703Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:55.6100278Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:41:55.6100865Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testObjects(RankingTrainValidationSpec.scala:47)",
    "2025-11-25T22:41:55.6101456Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.getterSetterTestObject(Fuzzing.scala:618)",
    "2025-11-25T22:41:55.6101986Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.getterSetterTestObject$(Fuzzing.scala:618)",
    "2025-11-25T22:41:55.6102591Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.getterSetterTestObject(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:41:55.6103195Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.GetterSetterFuzzing.testGettersAndSetters(Fuzzing.scala:561)",
    "2025-11-25T22:41:55.6103764Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.GetterSetterFuzzing.testGettersAndSetters$(Fuzzing.scala:560)",
    "2025-11-25T22:41:55.6104365Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testGettersAndSetters(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:41:55.6104959Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.GetterSetterFuzzing.$anonfun$$init$$4(Fuzzing.scala:599)",
    "2025-11-25T22:41:55.6105473Z \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
    "2025-11-25T22:41:55.6105997Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:41:55.6106424Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:41:55.6106830Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:41:55.6107236Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:41:55.6107652Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:41:55.6108162Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:41:55.6108611Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:41:55.6109045Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:41:55.6109474Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:55.6110034Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:41:55.6110546Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:41:55.6110991Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:41:55.6111438Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:41:55.6111905Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:41:55.6112446Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:41:55.6113026Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:41:55.6113514Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:41:55.6114004Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:41:55.6114510Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:41:55.6114979Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:41:55.6115433Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:55.6115852Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:41:55.6116268Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:41:55.6116694Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:41:55.6117130Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:41:55.6117612Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:41:55.6118076Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:55.6118561Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:41:55.6118961Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:41:55.6119432Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:41:55.6119952Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:41:55.6120403Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:41:55.6120825Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:41:55.6121284Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:41:55.6121829Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:41:55.6122361Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:41:55.6122842Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:41:55.6123306Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:41:55.6123765Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:41:55.6124370Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:41:55.6124857Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:41:55.6125284Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:41:55.6125711Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:41:55.6126178Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:55.6126682Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:55.6127110Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:55.6127809Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2425.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2425.0 (TID 2882) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:55.6128783Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:55.6129283Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:55.6129745Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:55.6130222Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:55.6130707Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:55.6131244Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:55.6131751Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:55.6132234Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:55.6132713Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:55.6133152Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:55.6133562Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:55.6133986Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6134441Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6134981Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6135488Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6135955Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6136361Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6136786Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6137312Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6137719Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6138257Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:55.6138718Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:55.6139244Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:55.6139670Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:55.6140111Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:55.6140565Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:55.6140987Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:55.6141388Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:55.6141918Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:55.6142373Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:55.6142950Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:55.6143161Z ",
    "2025-11-25T22:41:55.6143428Z Driver stacktrace:",
    "2025-11-25T22:41:55.6143835Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:55.6144258Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:55.6144693Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:55.6145210Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:55.6145740Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:55.6146174Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:55.6146674Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:55.6147194Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:55.6147654Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:55.6148071Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:55.6148648Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:41:55.6149163Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:41:55.6149672Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:41:55.6150148Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:41:55.6150590Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:41:55.6151022Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:41:55.6151457Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:41:55.6151869Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:41:55.6152310Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:55.6152791Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:55.6153213Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:55.6153602Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:41:55.6154050Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:41:55.6154528Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:55.6155017Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:55.6155451Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:55.6155868Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:41:55.6156447Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:41:55.6156876Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:41:55.6157299Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:41:55.6157746Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:41:55.6158199Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:41:55.6158616Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:41:55.6159073Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:41:55.6159977Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:41:55.6160501Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:41:55.6161001Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:41:55.6161508Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:41:55.6162031Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:41:55.6162600Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:41:55.6163179Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:41:55.6163591Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:41:55.6164021Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:41:55.6164434Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:41:55.6164860Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:41:55.6165314Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:41:55.6165751Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:41:55.6166197Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:41:55.6166641Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:41:55.6167022Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:41:55.6167503Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:41:55.6167981Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:55.6168532Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:41:55.6168959Z \t... 62 more",
    "2025-11-25T22:41:55.6169345Z Caused by: scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:55.6169855Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:55.6170332Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:55.6170742Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:55.6171204Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:55.6171754Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:55.6172180Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:55.6172639Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:55.6173225Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:55.6173684Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:55.6174088Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:55.6174457Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:55.6174861Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6175268Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6175647Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6176132Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6176539Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6176916Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6177319Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6177727Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6178191Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6178581Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:55.6178956Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:55.6179324Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:55.6179688Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:55.6180169Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:55.6180597Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:55.6180980Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:55.6181364Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:55.6181651Z \t... 3 more",
    "2025-11-25T22:41:55.6319516Z Alert Provided - Suite RankingTrainValidationSplitModelSpec took 14.23s",
    "2025-11-25T22:41:55.6341681Z [info] - Getters and Setters work as anticipated *** FAILED ***",
    "2025-11-25T22:41:55.6342517Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:41:55.6343403Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:41:55.6344061Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:41:55.6344597Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:55.6345207Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:55.6345699Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:41:55.6346201Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:41:55.6346724Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:41:55.6347222Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:41:55.6347784Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:41:55.6348433Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:41:55.6348806Z [info]   ...",
    "2025-11-25T22:41:55.6349418Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2425.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2425.0 (TID 2882) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:55.6350239Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:55.6350698Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:55.6351125Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:55.6351581Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:55.6352296Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:55.6352801Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:55.6353273Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:55.6353724Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:55.6354172Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:55.6354584Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:55.6354961Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:41:55.6355360Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6355992Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6356348Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6356710Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6357106Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6357454Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6357817Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:41:55.6358291Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:41:55.6358648Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:41:55.6359002Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:41:55.6359398Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:41:55.6359767Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:41:55.6360158Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:41:55.6360571Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:41:55.6361193Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:41:55.6361730Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:41:55.6362159Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:41:55.6362635Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:41:55.6363096Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:41:55.6363492Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:41:55.6363784Z [info] ",
    "2025-11-25T22:41:55.6364019Z [info] Driver stacktrace:",
    "2025-11-25T22:41:55.6364380Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:55.6364796Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:41:55.6365205Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:41:55.6365795Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:55.6366247Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:41:55.6366656Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:41:55.6367131Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:55.6367628Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:55.6368056Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:41:55.6368649Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:41:55.6368988Z [info]   ...",
    "2025-11-25T22:41:55.6369353Z [info]   Cause: scala.MatchError: [ArraySeq(7, 5, 8),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:41:55.6369877Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:41:55.6370334Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:41:55.6370771Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:41:55.6371224Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:41:55.6371766Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:41:55.6372276Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:41:55.6372796Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:41:55.6373247Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:41:55.6373696Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:41:55.6374113Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:41:55.6374424Z [info]   ...",
    "2025-11-25T22:41:55.6374700Z [info] + Test Getters and Setters work as anticipated took 3.788s ",
    "2025-11-25T22:41:55.6639306Z 25/11/25 22:41:55 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:41:55.6773610Z [info] SARSpec:",
    "2025-11-25T22:42:07.8914008Z [info] - Serialization Fuzzing",
    "2025-11-25T22:42:07.8924476Z [info] + Test Serialization Fuzzing took 12.247s ",
    "2025-11-25T22:42:08.5955385Z [info] - Experiment Fuzzing",
    "2025-11-25T22:42:08.5956277Z [info] + Test Experiment Fuzzing took 0.702s ",
    "2025-11-25T22:42:08.5979005Z Testing parameter activityTimeFormat",
    "2025-11-25T22:42:08.5982726Z Testing parameter alpha",
    "2025-11-25T22:42:08.5988473Z Testing parameter blockSize",
    "2025-11-25T22:42:08.5991601Z Testing parameter checkpointInterval",
    "2025-11-25T22:42:08.5993368Z Testing parameter coldStartStrategy",
    "2025-11-25T22:42:08.5995335Z Testing parameter finalStorageLevel",
    "2025-11-25T22:42:08.5997059Z Testing parameter implicitPrefs",
    "2025-11-25T22:42:08.5999042Z Testing parameter intermediateStorageLevel",
    "2025-11-25T22:42:08.6001530Z Testing parameter itemCol",
    "2025-11-25T22:42:08.6003653Z Testing parameter maxIter",
    "2025-11-25T22:42:08.6004354Z Testing parameter nonnegative",
    "2025-11-25T22:42:08.6004898Z Testing parameter numItemBlocks",
    "2025-11-25T22:42:08.6012922Z Testing parameter numUserBlocks",
    "2025-11-25T22:42:08.6017479Z Testing parameter predictionCol",
    "2025-11-25T22:42:08.6020988Z Testing parameter rank",
    "2025-11-25T22:42:08.6024613Z Testing parameter ratingCol",
    "2025-11-25T22:42:08.6027870Z Testing parameter regParam",
    "2025-11-25T22:42:08.6028753Z Testing parameter seed",
    "2025-11-25T22:42:08.6029553Z Testing parameter similarityFunction",
    "2025-11-25T22:42:08.6030476Z Testing parameter startTime",
    "2025-11-25T22:42:08.6036794Z Could not test parameter startTime",
    "2025-11-25T22:42:08.6037286Z Testing parameter startTimeFormat",
    "2025-11-25T22:42:08.6037614Z Testing parameter supportThreshold",
    "2025-11-25T22:42:08.6037911Z Testing parameter timeCol",
    "2025-11-25T22:42:08.6041223Z Testing parameter timeDecayCoeff",
    "2025-11-25T22:42:08.6043401Z Testing parameter userCol",
    "2025-11-25T22:42:08.6052700Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:42:08.6059539Z [info] + Test Getters and Setters work as anticipated took 0.009s ",
    "2025-11-25T22:42:11.2792440Z 25/11/25 22:42:11 WARN BlockManager: Putting block rdd_4855_0 failed due to exception scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:42:11.2802532Z 25/11/25 22:42:11 WARN BlockManager: Block rdd_4855_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:42:11.2816749Z 25/11/25 22:42:11 ERROR Executor: Exception in task 0.0 in stage 2833.0 (TID 4270)",
    "2025-11-25T22:42:11.2818770Z scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:11.2819495Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:11.2823931Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:11.2824616Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:11.2825485Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:11.2826018Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:11.2826601Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:11.2827153Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:11.2831800Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:11.2837958Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:11.2838918Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:11.2839335Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:11.2839777Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.2840220Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.2840653Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.2841083Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.2841522Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.2841952Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.2842471Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.2842915Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.2843337Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.2843749Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:11.2844227Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:11.2844835Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:11.2845307Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:11.2845840Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:11.2846355Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:11.2846839Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:11.2847323Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:11.2849556Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:11.2855145Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:11.2856783Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:11.2857813Z 25/11/25 22:42:11 WARN TaskSetManager: Lost task 0.0 in stage 2833.0 (TID 4270) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:11.2878828Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:11.2879468Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:11.2879905Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:11.2880345Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:11.2880798Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:11.2881289Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:11.2881758Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:11.2882463Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:11.2882920Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:11.2883324Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:11.2883699Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:11.2884081Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.2884481Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.2884871Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.2885247Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.2885658Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.2886023Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.2886401Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.2886818Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.2887183Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.2887547Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:11.2887959Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:11.2888455Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:11.2888850Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:11.2889303Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:11.2889740Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:11.2890166Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:11.2890560Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:11.2890988Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:11.2891989Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:11.2892485Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:11.2892663Z ",
    "2025-11-25T22:42:11.2892967Z 25/11/25 22:42:11 ERROR TaskSetManager: Task 0 in stage 2833.0 failed 1 times; aborting job",
    "2025-11-25T22:42:11.2898812Z [info] - SAR *** FAILED ***",
    "2025-11-25T22:42:11.8802924Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2833.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2833.0 (TID 4270) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:11.8804598Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:11.8805605Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:11.8806192Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:11.8806774Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:11.8807348Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:11.8807940Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:11.8808651Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:11.8809195Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:11.8809885Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:11.8810412Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:11.8810869Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:11.8811369Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.8811875Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.8812343Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.8812832Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.8813340Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.8813827Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.8814316Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:11.8814857Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:11.8815356Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:11.8815856Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:11.8816391Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:11.8816887Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:11.8817429Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:11.8817984Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:11.8829521Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:11.8830104Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:11.8830640Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:11.8831186Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:11.8831786Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:11.8832286Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:11.8848827Z [info] ",
    "2025-11-25T22:42:11.8849339Z [info] Driver stacktrace:",
    "2025-11-25T22:42:11.8849763Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:11.8850215Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:11.8850684Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:11.8851197Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:11.8851671Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:11.8852150Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:11.8852893Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:11.8853447Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:11.8853904Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:11.8854344Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:11.8854736Z [info]   ...",
    "2025-11-25T22:42:11.8855157Z [info]   Cause: scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:11.8855929Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:11.8856645Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:11.8857192Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:11.8857753Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:11.8869094Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:11.8869822Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:11.8870352Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:11.8870846Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:11.8871339Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:11.8871815Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:11.8872168Z [info]   ...",
    "2025-11-25T22:42:11.8872456Z [info] + Test SAR took 2.681s ",
    "2025-11-25T22:42:13.3101651Z 25/11/25 22:42:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.",
    "2025-11-25T22:42:13.3829932Z 25/11/25 22:42:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:13.3831978Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:13.3834591Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:13.3836411Z Expected: _c0 but found: ",
    "2025-11-25T22:42:13.3836789Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_count1.csv.gz",
    "2025-11-25T22:42:13.9543233Z [info] - tlc test sim count1",
    "2025-11-25T22:42:13.9551937Z [info] + Test tlc test sim count1 took 2.668s ",
    "2025-11-25T22:42:15.0041981Z 25/11/25 22:42:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:15.0044167Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:15.0046954Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:15.0048668Z Expected: _c0 but found: ",
    "2025-11-25T22:42:15.0049275Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_lift1.csv.gz",
    "2025-11-25T22:42:15.5123611Z [info] - tlc test sim lift1",
    "2025-11-25T22:42:15.5133479Z [info] + Test tlc test sim lift1 took 1.556s ",
    "2025-11-25T22:42:16.5453490Z 25/11/25 22:42:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:16.5455723Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:16.5458951Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:16.5460709Z Expected: _c0 but found: ",
    "2025-11-25T22:42:16.5461307Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_jac1.csv.gz",
    "2025-11-25T22:42:17.0403267Z [info] - tlc test sim jac1",
    "2025-11-25T22:42:17.0422353Z [info] + Test tlc test sim jac1 took 1.526s ",
    "2025-11-25T22:42:17.9396602Z 25/11/25 22:42:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:17.9400116Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:17.9402931Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:17.9405051Z Expected: _c0 but found: ",
    "2025-11-25T22:42:17.9406012Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_count3.csv.gz",
    "2025-11-25T22:42:18.4207166Z [info] - tlc test sim count3",
    "2025-11-25T22:42:18.4208262Z [info] + Test tlc test sim count3 took 1.376s ",
    "2025-11-25T22:42:19.3635167Z 25/11/25 22:42:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:19.3638442Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:19.3643918Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:19.3649578Z Expected: _c0 but found: ",
    "2025-11-25T22:42:19.3651615Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_lift3.csv.gz",
    "2025-11-25T22:42:19.8495630Z [info] - tlc test sim lift3",
    "2025-11-25T22:42:19.8499424Z [info] + Test tlc test sim lift3 took 1.43s ",
    "2025-11-25T22:42:20.7477507Z 25/11/25 22:42:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:20.7482855Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:20.7486118Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:20.7487936Z Expected: _c0 but found: ",
    "2025-11-25T22:42:20.7490885Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_jac3.csv.gz",
    "2025-11-25T22:42:21.2297311Z [info] - tlc test sim jac3",
    "2025-11-25T22:42:21.2298791Z [info] + Test tlc test sim jac3 took 1.381s ",
    "2025-11-25T22:42:22.1384959Z 25/11/25 22:42:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:22.1387262Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:22.1390294Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:22.1392374Z Expected: _c0 but found: ",
    "2025-11-25T22:42:22.1393078Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_count3.csv.gz",
    "2025-11-25T22:42:26.8102907Z [info] - tlc test userpred count3 userid only",
    "2025-11-25T22:42:26.8124810Z [info] + Test tlc test userpred count3 userid only took 5.581s ",
    "2025-11-25T22:42:28.0484298Z 25/11/25 22:42:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:28.0491088Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:28.0501895Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:28.0507142Z Expected: _c0 but found: ",
    "2025-11-25T22:42:28.0508549Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_lift3.csv.gz",
    "2025-11-25T22:42:31.9593627Z [info] - tlc test userpred lift3 userid only",
    "2025-11-25T22:42:31.9603061Z [info] + Test tlc test userpred lift3 userid only took 5.148s ",
    "2025-11-25T22:42:33.3151377Z 25/11/25 22:42:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:42:33.3156566Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:33.3164096Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:42:33.3169723Z Expected: _c0 but found: ",
    "2025-11-25T22:42:33.3170866Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_jac3.csv.gz",
    "2025-11-25T22:42:37.1881844Z [info] - tlc test userpred jac3 userid only",
    "2025-11-25T22:42:37.1885391Z [info] + Test tlc test userpred jac3 userid only took 5.227s ",
    "2025-11-25T22:42:37.1891182Z Alert Provided - Suite SARSpec took 41.532s",
    "2025-11-25T22:42:37.2069391Z 25/11/25 22:42:37 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:37.2074900Z [info] RecommendationIndexerSpec:",
    "2025-11-25T22:42:43.6363256Z [info] - Serialization Fuzzing",
    "2025-11-25T22:42:43.6365468Z [info] + Test Serialization Fuzzing took 6.437s ",
    "2025-11-25T22:42:44.3951028Z [info] - Experiment Fuzzing",
    "2025-11-25T22:42:44.3952958Z Testing parameter itemInputCol",
    "2025-11-25T22:42:44.3953471Z Testing parameter itemOutputCol",
    "2025-11-25T22:42:44.3953942Z [info] + Test Experiment Fuzzing took 0.356s ",
    "2025-11-25T22:42:44.3954496Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:42:44.3954975Z [info] + Test Getters and Setters work as anticipated took 0.003s ",
    "2025-11-25T22:42:44.3955456Z Testing parameter ratingCol",
    "2025-11-25T22:42:44.3955890Z Testing parameter userInputCol",
    "2025-11-25T22:42:44.3956312Z Testing parameter userOutputCol",
    "2025-11-25T22:42:46.1924732Z 25/11/25 22:42:46 WARN BlockManager: Putting block rdd_6456_0 failed due to exception scala.MatchError: [ArraySeq(8, 9, 7, 5, 3),ArraySeq(8.0, 9.0, 0.0, 3.0, 2.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:42:46.1934443Z 25/11/25 22:42:46 WARN BlockManager: Block rdd_6456_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:42:46.1946934Z 25/11/25 22:42:46 ERROR Executor: Exception in task 0.0 in stage 3540.0 (TID 5165)",
    "2025-11-25T22:42:46.1950592Z scala.MatchError: [ArraySeq(8, 9, 7, 5, 3),ArraySeq(8.0, 9.0, 0.0, 3.0, 2.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:46.1954082Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:46.1959611Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:46.1960288Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:46.1961974Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:46.1962585Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:46.1963589Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:46.1973047Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:46.1973812Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:46.1974631Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:46.1975130Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:46.1975568Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:46.1976185Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:46.1976686Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:46.1977130Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:46.1977593Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:46.1982652Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:46.1986693Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:46.1988516Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:46.1989274Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:46.1989757Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:46.1990235Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:46.1990743Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:46.1991248Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:46.1991742Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:46.1992203Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:46.1992714Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:46.1993230Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:46.1993689Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:46.1994415Z 25/11/25 22:42:46 WARN TaskSetManager: Lost task 0.0 in stage 3540.0 (TID 5165) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 9, 7, 5, 3),ArraySeq(8.0, 9.0, 0.0, 3.0, 2.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:46.1995179Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:46.1995788Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:46.1996305Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:46.1996826Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:46.1997343Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:46.1997890Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:46.1998661Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:46.2000597Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:46.2002933Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:46.2004453Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:46.2005082Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:46.2005561Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:46.2006033Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:46.2006472Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:46.2006937Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:46.2007415Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:46.2008250Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:46.2008755Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:46.2009247Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:46.2009702Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:46.2010184Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:46.2094270Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:46.2094782Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:46.2095209Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:46.2095682Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:46.2096131Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:46.2096593Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:46.2096997Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:46.2097172Z ",
    "2025-11-25T22:42:46.2097574Z 25/11/25 22:42:46 ERROR TaskSetManager: Task 0 in stage 3540.0 failed 1 times; aborting job",
    "2025-11-25T22:42:46.2097893Z [info] - ALS *** FAILED ***",
    "2025-11-25T22:42:46.2098655Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3540.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3540.0 (TID 5165) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 9, 7, 5, 3),ArraySeq(8.0, 9.0, 0.0, 3.0, 2.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:46.2099452Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:46.2099913Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:46.2100345Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:46.2100804Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:46.2101282Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:46.2101768Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:46.2102238Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:46.2102689Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:46.2103134Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:46.2103546Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:46.2103928Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:46.2104541Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:46.2104970Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:46.2105349Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:46.2105744Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:46.2106169Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:46.2106546Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:46.2106926Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:46.2107356Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:46.2107749Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:46.2108355Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:46.2108830Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:46.2109281Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:46.2109722Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:46.2110128Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:46.2110570Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:46.2111045Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:46.2111438Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:46.2111727Z [info] ",
    "2025-11-25T22:42:46.2111967Z [info] Driver stacktrace:",
    "2025-11-25T22:42:46.2112326Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:46.2112748Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:46.2113152Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:46.2113620Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:46.2114062Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:46.2114467Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:46.2114936Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:46.2115429Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:46.2115850Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:46.2116257Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:46.2116594Z [info]   ...",
    "2025-11-25T22:42:46.2116974Z [info]   Cause: scala.MatchError: [ArraySeq(8, 9, 7, 5, 3),ArraySeq(8.0, 9.0, 0.0, 3.0, 2.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:46.2117514Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:46.2117971Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:46.2118477Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:46.2118927Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:46.2119382Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:46.2119789Z Info Provided - Suite RecommendationIndexerSpec took 9.011s",
    "2025-11-25T22:42:46.2155480Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:46.2156903Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:46.2165846Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:46.2166940Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:46.2167603Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:46.2168258Z [info]   ...",
    "2025-11-25T22:42:46.2168753Z [info] + Test ALS took 2.215s ",
    "2025-11-25T22:42:46.2248964Z [info] RankingTrainValidationSplitSpec:",
    "2025-11-25T22:42:46.2331678Z 25/11/25 22:42:46 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:47.3970628Z 25/11/25 22:42:46 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:51.5034692Z 25/11/25 22:42:51 WARN BlockManager: Putting block rdd_6831_0 failed due to exception scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:42:51.5045981Z 25/11/25 22:42:51 WARN BlockManager: Block rdd_6831_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:42:51.5047189Z 25/11/25 22:42:51 ERROR Executor: Exception in task 0.0 in stage 3731.0 (TID 5572)",
    "2025-11-25T22:42:51.5048006Z scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:51.5057202Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:51.5059690Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:51.5060393Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:51.5060936Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:51.5061486Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:51.5067665Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:51.5068606Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:51.5069179Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:51.5069895Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:51.5071889Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:51.5082940Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:51.5083514Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5083955Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5084335Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5084718Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5085134Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5085498Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5085877Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5086290Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5086651Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5087019Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:51.5087431Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:51.5087812Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:51.5088371Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:51.5089195Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:51.5089634Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:51.5090065Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:51.5090459Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:51.5090887Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:51.5091351Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:51.5091740Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:51.5092431Z 25/11/25 22:42:51 WARN TaskSetManager: Lost task 0.0 in stage 3731.0 (TID 5572) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:51.5093252Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:51.5093699Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:51.5094124Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:51.5094561Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:51.5095015Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:51.5095504Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:51.5095969Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:51.5096396Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:51.5096854Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:51.5097254Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:51.5097625Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:51.5098005Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5129425Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5129905Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5130361Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5130808Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5131238Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5131713Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5132155Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5132595Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5133008Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:51.5133469Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:51.5133906Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:51.5134344Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:51.5134836Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:51.5142042Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:51.5158660Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:51.5171546Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:51.5172163Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:51.5172867Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:51.5173259Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:51.5173435Z ",
    "2025-11-25T22:42:51.5173741Z 25/11/25 22:42:51 ERROR TaskSetManager: Task 0 in stage 3731.0 failed 1 times; aborting job",
    "2025-11-25T22:42:51.5174448Z 25/11/25 22:42:51 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_54f324e9a56e\"}",
    "2025-11-25T22:42:51.5175264Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:42:51.5175657Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:42:51.5176093Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:42:51.5176577Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:51.5177150Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:51.5177643Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:51.5178310Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:51.5178845Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:42:51.5179312Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:42:51.5179811Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:51.5180325Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:42:51.5180858Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:42:51.5181369Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:51.5181895Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:42:51.5182413Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:51.5182944Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerializationHelper(Fuzzing.scala:489)",
    "2025-11-25T22:42:51.5183473Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$testSerialization$1(Fuzzing.scala:510)",
    "2025-11-25T22:42:51.5184033Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$testSerialization$1$adapted(Fuzzing.scala:506)",
    "2025-11-25T22:42:51.5184492Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:51.5184933Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization(Fuzzing.scala:506)",
    "2025-11-25T22:42:51.5185452Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization$(Fuzzing.scala:504)",
    "2025-11-25T22:42:51.5185988Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.testSerialization(RankingTrainValidationSpec.scala:10)",
    "2025-11-25T22:42:51.5186557Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$$init$$2(Fuzzing.scala:539)",
    "2025-11-25T22:42:51.5186994Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:42:51.5187438Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:42:51.5187814Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:42:51.5204871Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:42:51.5205651Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:42:51.5206146Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:42:51.5217853Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:42:51.5227042Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:42:51.5229264Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:51.5231859Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:42:51.5232664Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:42:51.5233171Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:42:51.5233650Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:42:51.5234144Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:42:51.5234731Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:42:51.5235312Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:42:51.5235849Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:42:51.5236372Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:42:51.5236914Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:42:51.5237438Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:42:51.5237901Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:51.5238578Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:42:51.5239087Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:42:51.5239535Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:42:51.5240002Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:42:51.5240515Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:42:51.5240996Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:51.5241449Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:42:51.5241860Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:42:51.5242359Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:51.5242939Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:42:51.5243408Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:42:51.5243863Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:42:51.5244356Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:42:51.5244899Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:42:51.5245464Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:42:51.5245940Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:42:51.5246404Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:42:51.5246901Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:42:51.5247443Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:42:51.5248182Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:42:51.5248688Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:42:51.5249145Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:42:51.5249655Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:51.5250179Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:51.5250644Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:51.5251396Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3731.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3731.0 (TID 5572) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:51.5252329Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:51.5252866Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:51.5253341Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:51.5253866Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:51.5254385Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:51.5254937Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:51.5256396Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:51.5257224Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:51.5258002Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:51.5258654Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:51.5259116Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:51.5259591Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5260064Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5260502Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5260965Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5261432Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5261870Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5262334Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5262809Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5263246Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5263699Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:51.5264171Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:51.5264635Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:51.5265095Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:51.5265600Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:51.5266124Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:51.5266604Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:51.5267065Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:51.5267578Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:51.5268377Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:51.5268884Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:51.5269116Z ",
    "2025-11-25T22:42:51.5269446Z Driver stacktrace:",
    "2025-11-25T22:42:51.5269892Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:51.5270357Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:51.5270815Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:51.5271359Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:51.5271849Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:51.5272335Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:51.5272967Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:51.5273527Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:51.5274022Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:51.5274474Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:51.5275000Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:42:51.5275551Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:42:51.5276079Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:42:51.5276587Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:42:51.5277052Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:42:51.5277520Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:42:51.5277992Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:42:51.5278550Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:42:51.5279031Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:51.5279546Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:51.5280026Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:51.5280468Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:42:51.5280940Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:42:51.5281453Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:51.5281968Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:51.5282432Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:51.5282898Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:42:51.5283421Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:42:51.5283920Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:42:51.5284426Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:51.5284924Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:51.5285378Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:51.5285846Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:42:51.5286343Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:42:51.5286891Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:42:51.5287487Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:42:51.5288257Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:42:51.5288882Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:42:51.5289485Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:42:51.5290126Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:42:51.5290731Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:42:51.5291208Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:42:51.5291788Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:42:51.5292268Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:42:51.5292760Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:42:51.5293285Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:42:51.5293787Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:42:51.5294319Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:42:51.5294817Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:42:51.5295265Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:42:51.5295813Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:42:51.5296357Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:51.5296905Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:42:51.5297389Z \t... 62 more",
    "2025-11-25T22:42:51.5297830Z Caused by: scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:51.5298629Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:51.5299193Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:51.5299673Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:51.5300203Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:51.5300719Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:51.5301316Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:51.5301863Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:51.5302362Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:51.5302883Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:51.5303356Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:51.5303777Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:51.5304580Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5305144Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5305633Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5306106Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5306580Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5307155Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5307604Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5308072Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5308636Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5309083Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:51.5309556Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:51.5310028Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:51.5310496Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:51.5311010Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:51.5311645Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:51.5312174Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:51.5312656Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:51.5313040Z \t... 3 more",
    "2025-11-25T22:42:51.5313509Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:42:51.5313910Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:42:51.5314379Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:42:51.5314895Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:42:51.5315463Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:51.5316139Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:51.5316710Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:51.5317270Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:51.5317881Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:42:51.5318551Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:42:51.5319179Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:51.5319770Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:42:51.5320187Z [info]   ...",
    "2025-11-25T22:42:51.5320892Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3731.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3731.0 (TID 5572) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:51.5321739Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:51.5322328Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:51.5322826Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:51.5323376Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:51.5323915Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:51.5324484Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:51.5325181Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:51.5325695Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:51.5326236Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:51.5326730Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:51.5327169Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:51.5327653Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5328219Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5328702Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5329186Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5329773Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5330229Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5330713Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:51.5331196Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:51.5331665Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:51.5332119Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:51.5332631Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:51.5333125Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:51.5333610Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:51.5334135Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:51.5334678Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:51.5335185Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:51.5335683Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:51.5336150Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:51.5336616Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:51.5337036Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:51.5337314Z [info] ",
    "2025-11-25T22:42:51.5337552Z [info] Driver stacktrace:",
    "2025-11-25T22:42:51.5337934Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:51.5338431Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:51.5338858Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:51.5339332Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:51.5339760Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:51.5340186Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:51.5340644Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:51.5341139Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:51.5341577Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:51.5341976Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:51.5342335Z [info]   ...",
    "2025-11-25T22:42:51.5342699Z [info]   Cause: scala.MatchError: [ArraySeq(9, 7, 3),ArraySeq(2.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:51.5343330Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:51.5343810Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:51.5344226Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:51.5344692Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:51.5345154Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:51.5345644Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:51.5346252Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:51.5346691Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:51.5347158Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:51.5347571Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:51.5347866Z [info]   ...",
    "2025-11-25T22:42:51.5353420Z [info] + Test Serialization Fuzzing took 5.291s ",
    "2025-11-25T22:42:51.5354227Z 25/11/25 22:42:51 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:51.7299335Z 25/11/25 22:42:51 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:51.7344886Z 25/11/25 22:42:51 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:54.6993472Z 25/11/25 22:42:54 WARN BlockManager: Putting block rdd_7134_0 failed due to exception scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:42:54.7001568Z 25/11/25 22:42:54 WARN BlockManager: Block rdd_7134_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:42:54.7009010Z 25/11/25 22:42:54 ERROR Executor: Exception in task 0.0 in stage 3885.0 (TID 5827)",
    "2025-11-25T22:42:54.7009691Z scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:54.7030590Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:54.7031251Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:54.7031667Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:54.7032125Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:54.7032575Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:54.7033078Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:54.7033549Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:54.7033973Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:54.7034420Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:54.7034816Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:54.7035179Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:54.7035561Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7035957Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7036333Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7036714Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7037107Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7037848Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7038378Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7038782Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7039157Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7039523Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:54.7039941Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:54.7040321Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:54.7040708Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:54.7041155Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:54.7041711Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:54.7042126Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:54.7042532Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:54.7042954Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:54.7043413Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:54.7043797Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:54.7059839Z 25/11/25 22:42:54 WARN TaskSetManager: Lost task 0.0 in stage 3885.0 (TID 5827) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:54.7060972Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:54.7061481Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:54.7061956Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:54.7062433Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:54.7075580Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:54.7080287Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:54.7080960Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:54.7081501Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:54.7082017Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:54.7082500Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:54.7083039Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:54.7083461Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7083916Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7084327Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7084750Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7085205Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7085614Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7116048Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7116769Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7117144Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7117492Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:54.7118315Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:54.7118682Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:54.7119062Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:54.7119473Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:54.7119876Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:54.7120275Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:54.7120641Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:54.7121038Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:54.7121567Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:54.7122124Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:54.7122300Z ",
    "2025-11-25T22:42:54.7122602Z 25/11/25 22:42:54 ERROR TaskSetManager: Task 0 in stage 3885.0 failed 1 times; aborting job",
    "2025-11-25T22:42:54.7123419Z 25/11/25 22:42:54 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_54f324e9a56e\"}",
    "2025-11-25T22:42:54.7124116Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:42:54.7124501Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:42:54.7124918Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:42:54.7125418Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:54.7125998Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:54.7126495Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:54.7126970Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:54.7127580Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:42:54.7128027Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:42:54.7128573Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:54.7129060Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:42:54.7129493Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:42:54.7129959Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:54.7130468Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:42:54.7130972Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:54.7131454Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.runExperiment(Fuzzing.scala:435)",
    "2025-11-25T22:42:54.7131910Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.runExperiment$(Fuzzing.scala:430)",
    "2025-11-25T22:42:54.7132416Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.runExperiment(RankingTrainValidationSpec.scala:10)",
    "2025-11-25T22:42:54.7133006Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$testExperiments$1(Fuzzing.scala:442)",
    "2025-11-25T22:42:54.7133495Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$testExperiments$1$adapted(Fuzzing.scala:441)",
    "2025-11-25T22:42:54.7133923Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:54.7134317Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments(Fuzzing.scala:441)",
    "2025-11-25T22:42:54.7134781Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments$(Fuzzing.scala:440)",
    "2025-11-25T22:42:54.7135266Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.testExperiments(RankingTrainValidationSpec.scala:10)",
    "2025-11-25T22:42:54.7135753Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$$init$$1(Fuzzing.scala:451)",
    "2025-11-25T22:42:54.7136228Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:42:54.7136565Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:42:54.7136896Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:42:54.7137242Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:42:54.7137569Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:42:54.7138207Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:42:54.7138608Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:42:54.7138970Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:42:54.7139367Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:54.7139791Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:42:54.7140238Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:42:54.7140660Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:42:54.7141044Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:42:54.7141454Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:42:54.7141960Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:42:54.7142463Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:42:54.7142924Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:42:54.7143366Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:42:54.7143806Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:42:54.7144246Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:42:54.7144631Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:54.7145026Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:42:54.7145405Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:42:54.7145770Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:42:54.7146175Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:42:54.7146593Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:42:54.7146997Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:54.7147371Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:42:54.7147702Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:42:54.7148194Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:54.7148687Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:42:54.7149159Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:42:54.7149551Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:42:54.7149949Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:42:54.7150414Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:42:54.7150902Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:42:54.7151301Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:42:54.7151686Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:42:54.7152111Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:42:54.7152711Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:42:54.7153447Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:42:54.7153799Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:42:54.7154139Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:42:54.7154728Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:54.7155172Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:54.7155576Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:54.7156240Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3885.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3885.0 (TID 5827) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:54.7157014Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:54.7157459Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:54.7157854Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:54.7158372Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:54.7158822Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:54.7159301Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:54.7159801Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:54.7160229Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:54.7160684Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:54.7161082Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:54.7161432Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:54.7161830Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7162229Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7162595Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7162987Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7163383Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7163766Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7164145Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7164538Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7164998Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7165362Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:54.7165763Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:54.7166158Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:54.7166549Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:54.7166984Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:54.7167436Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:54.7167843Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:54.7168324Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:54.7168822Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:54.7169276Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:54.7169676Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:54.7169831Z ",
    "2025-11-25T22:42:54.7170073Z Driver stacktrace:",
    "2025-11-25T22:42:54.7170427Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:54.7170809Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:54.7171213Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:54.7171669Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:54.7172083Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:54.7172498Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:54.7172943Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:54.7173443Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:54.7173843Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:54.7174219Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:54.7174695Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:42:54.7175154Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:42:54.7175609Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:42:54.7176040Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:42:54.7176433Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:42:54.7176837Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:42:54.7177215Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:42:54.7177586Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:42:54.7178001Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:54.7178501Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:54.7178883Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:54.7179241Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:42:54.7179633Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:42:54.7180080Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:54.7180507Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:54.7180886Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:54.7181360Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:42:54.7181791Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:42:54.7182211Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:42:54.7182638Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:54.7183057Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:54.7183452Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:54.7183831Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:42:54.7184253Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:42:54.7184803Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:42:54.7185310Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:42:54.7185803Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:42:54.7186308Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:42:54.7186828Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:42:54.7187404Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:42:54.7187883Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:42:54.7188332Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:42:54.7188738Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:42:54.7189153Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:42:54.7189584Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:42:54.7190012Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:42:54.7190437Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:42:54.7190884Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:42:54.7191302Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:42:54.7191669Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:42:54.7192135Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:42:54.7192609Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:54.7193101Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:42:54.7193486Z \t... 64 more",
    "2025-11-25T22:42:54.7193844Z Caused by: scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:54.7194359Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:54.7194801Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:54.7195220Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:54.7195654Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:54.7196099Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:54.7196594Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:54.7197134Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:54.7197553Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:54.7198003Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:54.7198470Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:54.7198835Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:54.7199217Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7199615Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7199997Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7200448Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7200844Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7201231Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7201647Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7202042Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7202426Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7202792Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:54.7203211Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:54.7203591Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:54.7203998Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:54.7204445Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:54.7204883Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:54.7205296Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:54.7205702Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:54.7206016Z \t... 3 more",
    "2025-11-25T22:42:54.7379043Z Testing parameter alpha",
    "2025-11-25T22:42:54.7380001Z Testing parameter blockSize",
    "2025-11-25T22:42:54.7380372Z Testing parameter checkpointInterval",
    "2025-11-25T22:42:54.7380753Z Testing parameter coldStartStrategy",
    "2025-11-25T22:42:54.7381090Z Testing parameter estimator",
    "2025-11-25T22:42:54.7381483Z Testing parameter estimatorParamMaps",
    "2025-11-25T22:42:54.7381859Z Could not test parameter estimatorParamMaps",
    "2025-11-25T22:42:54.7382206Z Testing parameter evaluator",
    "2025-11-25T22:42:54.7382539Z Testing parameter finalStorageLevel",
    "2025-11-25T22:42:54.7382901Z Testing parameter implicitPrefs",
    "2025-11-25T22:42:54.7383271Z Testing parameter intermediateStorageLevel",
    "2025-11-25T22:42:54.7383616Z Testing parameter itemCol",
    "2025-11-25T22:42:54.7383990Z Testing parameter maxIter",
    "2025-11-25T22:42:54.7384321Z Testing parameter minRatingsI",
    "2025-11-25T22:42:54.7384650Z Testing parameter minRatingsU",
    "2025-11-25T22:42:54.7384995Z Testing parameter nonnegative",
    "2025-11-25T22:42:54.7385323Z Testing parameter numItemBlocks",
    "2025-11-25T22:42:54.7385654Z Testing parameter numUserBlocks",
    "2025-11-25T22:42:54.7385997Z Testing parameter parallelism",
    "2025-11-25T22:42:54.7386326Z Testing parameter predictionCol",
    "2025-11-25T22:42:54.7386650Z Testing parameter rank",
    "2025-11-25T22:42:54.7387009Z Testing parameter ratingCol",
    "2025-11-25T22:42:54.7387332Z Testing parameter regParam",
    "2025-11-25T22:42:54.7387651Z Testing parameter seed",
    "2025-11-25T22:42:54.7387989Z Testing parameter trainRatio",
    "2025-11-25T22:42:54.7388443Z Testing parameter userCol",
    "2025-11-25T22:42:54.7388846Z 25/11/25 22:42:54 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:54.7389262Z [info] - Experiment Fuzzing *** FAILED ***",
    "2025-11-25T22:42:54.7389648Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:42:54.7390492Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:42:54.7391015Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:42:54.7391622Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:54.7392302Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:54.7392868Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:54.7393419Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:54.7394153Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:42:54.7394704Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:42:54.7395306Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:54.7395889Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:42:54.7396301Z [info]   ...",
    "2025-11-25T22:42:54.7396997Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3885.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3885.0 (TID 5827) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:54.7397841Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:54.7398521Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:54.7399013Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:54.7399548Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:54.7400079Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:54.7400647Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:54.7401209Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:54.7401787Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:54.7402348Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:54.7402833Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:54.7403267Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:54.7403746Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7404227Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7404678Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7405157Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7405637Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7406100Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7406559Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:54.7407042Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:54.7407649Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:54.7408180Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:54.7408695Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:54.7409186Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:54.7409662Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:54.7410196Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:54.7410718Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:54.7411220Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:54.7411813Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:54.7412351Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:54.7412883Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:54.7413365Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:54.7413711Z [info] ",
    "2025-11-25T22:42:54.7414032Z [info] Driver stacktrace:",
    "2025-11-25T22:42:54.7414467Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:54.7414939Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:54.7415429Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:54.7415970Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:54.7416477Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:54.7416972Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:54.7417506Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:54.7418161Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:54.7418694Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:54.7419165Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:54.7419592Z [info]   ...",
    "2025-11-25T22:42:54.7420029Z [info]   Cause: scala.MatchError: [ArraySeq(7, 9, 5),ArraySeq(0.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:54.7420612Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:54.7421161Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:54.7421660Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:54.7422220Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:54.7422755Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:54.7423315Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:54.7423881Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:54.7424388Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:54.7424922Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:54.7425409Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:54.7425775Z [info]   ...",
    "2025-11-25T22:42:54.7426221Z [info] + Test Experiment Fuzzing took 3.197s ",
    "2025-11-25T22:42:54.7426588Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:42:54.7426972Z [info] + Test Getters and Setters work as anticipated took 0.008s ",
    "2025-11-25T22:42:54.9749644Z 25/11/25 22:42:54 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:54.9806549Z 25/11/25 22:42:54 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:58.2290170Z 25/11/25 22:42:58 WARN BlockManager: Putting block rdd_7437_0 failed due to exception scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:42:58.2298733Z 25/11/25 22:42:58 WARN BlockManager: Block rdd_7437_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:42:58.2299885Z 25/11/25 22:42:58 ERROR Executor: Exception in task 0.0 in stage 4039.0 (TID 6082)",
    "2025-11-25T22:42:58.2300990Z scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:58.2301822Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:58.2302487Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:58.2303112Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:58.2303802Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:58.2304459Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:58.2305158Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:58.2305827Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:58.2312555Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:58.2318987Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:58.2320233Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:58.2320742Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:58.2321202Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2321869Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2322516Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2323145Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2324256Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2324728Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2339916Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2340510Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2340904Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2341295Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:58.2341704Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:58.2342081Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:58.2342487Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:58.2342921Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:58.2343355Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:58.2343777Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:58.2344173Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:58.2344608Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:58.2345331Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:58.2345715Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:58.2346304Z 25/11/25 22:42:58 WARN TaskSetManager: Lost task 0.0 in stage 4039.0 (TID 6082) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:58.2346975Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:58.2347434Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:58.2347836Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:58.2348542Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:58.2349015Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:58.2349490Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:58.2349970Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:58.2350390Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:58.2350824Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:58.2351239Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:58.2351588Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:58.2351966Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2352383Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2352753Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2353145Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2353543Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2353908Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2354300Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2354697Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2355062Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2355443Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:58.2355843Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:58.2356224Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:58.2356629Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:58.2357062Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:58.2357512Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:58.2357921Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:58.2360336Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:58.2360788Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:58.2361232Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:58.2361620Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:58.2361793Z ",
    "2025-11-25T22:42:58.2362094Z 25/11/25 22:42:58 ERROR TaskSetManager: Task 0 in stage 4039.0 failed 1 times; aborting job",
    "2025-11-25T22:42:58.2362915Z 25/11/25 22:42:58 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_9e2c1468c992\"}",
    "2025-11-25T22:42:58.2363791Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:42:58.2364149Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:42:58.2364550Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:42:58.2365011Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:58.2365556Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:58.2366131Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:58.2366572Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:58.2367064Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:42:58.2367499Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:42:58.2367981Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:58.2368546Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:42:58.2369038Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:42:58.2369569Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:58.2370106Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:42:58.2370656Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.$anonfun$new$1(RankingTrainValidationSpec.scala:23)",
    "2025-11-25T22:42:58.2371084Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:42:58.2371421Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:42:58.2371772Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:42:58.2372107Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:42:58.2372435Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:42:58.2372815Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:42:58.2373190Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:42:58.2373545Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:42:58.2373909Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:58.2374493Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:42:58.2374954Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:42:58.2375384Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:42:58.2375770Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:42:58.2376199Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:42:58.2376693Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:42:58.2377213Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:42:58.2377765Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:42:58.2378319Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:42:58.2378918Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:42:58.2379344Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:42:58.2379725Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:58.2380107Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:42:58.2380481Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:42:58.2380860Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:42:58.2381247Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:42:58.2381741Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:42:58.2382163Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:58.2382631Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:42:58.2382941Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:42:58.2383347Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:42:58.2383783Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:42:58.2384145Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:42:58.2384511Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:42:58.2384880Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:42:58.2385334Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:42:58.2385778Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:42:58.2386161Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:42:58.2386533Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:42:58.2386906Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:42:58.2387314Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:42:58.2387726Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:42:58.2388076Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:42:58.2388510Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:42:58.2388939Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:58.2389348Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:58.2389727Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:58.2390339Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4039.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4039.0 (TID 6082) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:58.2391074Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:58.2391474Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:58.2391799Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:58.2392153Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:58.2392538Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:58.2392995Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:58.2393389Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:58.2393732Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:58.2394087Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:58.2394425Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:58.2394710Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:58.2395020Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2395360Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2395722Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2396030Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2396376Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2396673Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2396995Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2397320Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2397618Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2397933Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:58.2398510Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:58.2398867Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:58.2399248Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:58.2399653Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:58.2400079Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:58.2400462Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:58.2400827Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:58.2401237Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:58.2401661Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:58.2402021Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:58.2402185Z ",
    "2025-11-25T22:42:58.2402399Z Driver stacktrace:",
    "2025-11-25T22:42:58.2402743Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:58.2403102Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:58.2403464Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:58.2403905Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:58.2404326Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:58.2404687Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:58.2405115Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:58.2405560Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:58.2405951Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:58.2406306Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:58.2406723Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:42:58.2407164Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:42:58.2407868Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:42:58.2408408Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:42:58.2408805Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:42:58.2409253Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:42:58.2409683Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:42:58.2410187Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:42:58.2410592Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:58.2411034Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:58.2411426Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:58.2411864Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:42:58.2412284Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:42:58.2412723Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:58.2413165Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:58.2413558Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:58.2413952Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:42:58.2414455Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:42:58.2414887Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:42:58.2415307Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:42:58.2415752Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:42:58.2416143Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:42:58.2416551Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:42:58.2416979Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:42:58.2417450Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:42:58.2417962Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:42:58.2418528Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:42:58.2419037Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:42:58.2419559Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:42:58.2420121Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:42:58.2420620Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:42:58.2421018Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:42:58.2421425Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:42:58.2421834Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:42:58.2422261Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:42:58.2422712Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:42:58.2423144Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:42:58.2423585Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:42:58.2424028Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:42:58.2424498Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:42:58.2424971Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:42:58.2425439Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:58.2425910Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:42:58.2426322Z \t... 54 more",
    "2025-11-25T22:42:58.2426695Z Caused by: scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:58.2427196Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:58.2427909Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:58.2428454Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:58.2428953Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:58.2429439Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:58.2429951Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:58.2430465Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:58.2430925Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:58.2431413Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:58.2431849Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:58.2432241Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:58.2432678Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2433118Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2433523Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2433959Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2434393Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2434795Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2435232Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2435669Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2436094Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2436501Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:58.2436947Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:58.2437384Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:58.2437816Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:58.2438347Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:58.2438849Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:58.2439397Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:58.2439801Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:58.2440178Z \t... 3 more",
    "2025-11-25T22:42:58.2487392Z [info] - testALS *** FAILED ***",
    "2025-11-25T22:42:58.2489211Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:42:58.2489751Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:42:58.2490239Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:42:58.2490972Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:58.2491592Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:58.2492161Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:42:58.2492687Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:42:58.2493294Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:42:58.2493808Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:42:58.2494465Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:42:58.2495039Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:42:58.2495423Z [info]   ...",
    "2025-11-25T22:42:58.2496076Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4039.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4039.0 (TID 6082) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:58.2496876Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:58.2497380Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:58.2497841Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:58.2498442Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:58.2498959Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:58.2499490Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:58.2500021Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:58.2500498Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:58.2501087Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:58.2501523Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:58.2501900Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:42:58.2502299Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2502735Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2503221Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2503586Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2503951Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2504287Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2504649Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:42:58.2505014Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:42:58.2505352Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:42:58.2505708Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:42:58.2506079Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:42:58.2506515Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:42:58.2506889Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:42:58.2507288Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:42:58.2507698Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:42:58.2508166Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:42:58.2508541Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:42:58.2508944Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:42:58.2509344Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:42:58.2509782Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:42:58.2510045Z [info] ",
    "2025-11-25T22:42:58.2510270Z [info] Driver stacktrace:",
    "2025-11-25T22:42:58.2510610Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:58.2510969Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:42:58.2511326Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:42:58.2511755Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:58.2512136Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:42:58.2512497Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:42:58.2512917Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:58.2513314Z Alert Provided - Suite RankingTrainValidationSplitSpec took 12.018s",
    "2025-11-25T22:42:58.2579462Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:58.2593875Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:42:58.2594541Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:42:58.2594917Z [info]   ...",
    "2025-11-25T22:42:58.2595314Z [info]   Cause: scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(9.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:42:58.2595870Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:42:58.2596354Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:42:58.2596817Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:42:58.2597304Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:42:58.2597823Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:42:58.2598509Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:42:58.2599036Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:42:58.2599517Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:42:58.2600028Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:42:58.2600486Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:42:58.2600829Z [info]   ...",
    "2025-11-25T22:42:58.2602948Z [info] + Test testALS took 3.522s ",
    "2025-11-25T22:42:58.2832523Z 25/11/25 22:42:58 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:42:58.2899135Z [info] RecommendationIndexerModelSpec:",
    "2025-11-25T22:43:01.0868553Z [info] - Serialization Fuzzing",
    "2025-11-25T22:43:01.0901151Z [info] + Test Serialization Fuzzing took 2.826s ",
    "2025-11-25T22:43:01.4403664Z [info] - Experiment Fuzzing",
    "2025-11-25T22:43:01.4411845Z [info] + Test Experiment Fuzzing took 0.352s ",
    "2025-11-25T22:43:01.7799679Z Testing parameter itemIndexModel",
    "2025-11-25T22:43:01.7818694Z Testing parameter itemInputCol",
    "2025-11-25T22:43:01.7820200Z Testing parameter itemOutputCol",
    "2025-11-25T22:43:01.7820750Z Testing parameter ratingCol",
    "2025-11-25T22:43:01.7821593Z Testing parameter userIndexModel",
    "2025-11-25T22:43:01.7822193Z Testing parameter userInputCol",
    "2025-11-25T22:43:01.7822482Z Testing parameter userOutputCol",
    "2025-11-25T22:43:01.7822780Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:43:01.7823116Z [info] + Test Getters and Setters work as anticipated took 0.341s ",
    "2025-11-25T22:43:01.7830878Z Info Provided - Suite RecommendationIndexerModelSpec took 3.519s",
    "2025-11-25T22:43:02.2212227Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:43:02.2232245Z [info] No tests to run for cognitive / Test / testOnly",
    "2025-11-25T22:43:02.2234062Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:43:02.2234668Z [info] No tests to run for lightgbm / Test / testOnly",
    "2025-11-25T22:43:02.2235107Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:43:02.2235557Z [info] No tests to run for vw / Test / testOnly",
    "2025-11-25T22:43:02.2243714Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:43:02.2244784Z [info] No tests to run for deepLearning / Test / testOnly",
    "2025-11-25T22:43:02.2255740Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:43:02.2278962Z [info] No tests to run for Test / testOnly",
    "2025-11-25T22:43:02.2279671Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:43:02.2280153Z [info] No tests to run for opencv / Test / testOnly",
    "2025-11-25T22:43:02.2321026Z [info] Run completed in 2 minutes, 21 seconds.",
    "2025-11-25T22:43:02.2321739Z [info] Total number of tests run: 40",
    "2025-11-25T22:43:02.2322169Z [info] Suites: completed 9, aborted 0",
    "2025-11-25T22:43:02.2322620Z [info] Tests: succeeded 28, failed 12, canceled 0, ignored 0, pending 0",
    "2025-11-25T22:43:02.2323049Z [info] *** 12 TESTS FAILED ***",
    "2025-11-25T22:43:02.2345384Z [error] Failed tests:",
    "2025-11-25T22:43:02.2349177Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RankingEvaluatorSpec",
    "2025-11-25T22:43:02.2352123Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec",
    "2025-11-25T22:43:02.2354453Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.SARSpec",
    "2025-11-25T22:43:02.2372420Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RecommendationIndexerSpec",
    "2025-11-25T22:43:02.2373898Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec",
    "2025-11-25T22:43:02.2885110Z [error] (core / Test / testOnly) sbt.TestsFailedException: Tests unsuccessful",
    "2025-11-25T22:43:02.2963461Z [error] Total time: 150 s (0:02:30.0), completed Nov 25, 2025, 10:43:02 PM",
    "2025-11-25T22:43:02.6856973Z ",
    "2025-11-25T22:43:02.6884553Z ##[error]Script failed with exit code: 1",
    "2025-11-25T22:43:02.6893655Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account clear",
    "2025-11-25T22:43:03.3394296Z ##[warning]RetryHelper encountered task failure, will retry (attempt #: 1 out of 1) after 1000 ms",
    "2025-11-25T22:43:04.6151420Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az version",
    "2025-11-25T22:43:04.9850888Z {",
    "2025-11-25T22:43:04.9851986Z   \"azure-cli\": \"2.60.0\",",
    "2025-11-25T22:43:04.9852466Z   \"azure-cli-core\": \"2.60.0\",",
    "2025-11-25T22:43:04.9856553Z   \"azure-cli-telemetry\": \"1.1.0\",",
    "2025-11-25T22:43:04.9858384Z   \"extensions\": {",
    "2025-11-25T22:43:04.9859156Z     \"azure-devops\": \"1.0.2\"",
    "2025-11-25T22:43:04.9860667Z   }",
    "2025-11-25T22:43:04.9861347Z }",
    "2025-11-25T22:43:04.9891089Z Setting AZURE_CONFIG_DIR env variable to: /home/vsts/work/_temp/.azclitask",
    "2025-11-25T22:43:04.9904464Z Setting active cloud to: AzureCloud",
    "2025-11-25T22:43:04.9911870Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az cloud set -n AzureCloud",
    "2025-11-25T22:43:05.7473049Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az login --service-principal -u *** --tenant 72f988bf-86f1-41af-91ab-2d7cd011db47 --allow-no-subscriptions --federated-token ***",
    "2025-11-25T22:43:06.9310398Z [",
    "2025-11-25T22:43:06.9311076Z   {",
    "2025-11-25T22:43:06.9311410Z     \"cloudName\": \"AzureCloud\",",
    "2025-11-25T22:43:06.9311738Z     \"homeTenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:43:06.9312052Z     \"id\": \"e342c2c0-f844-4b18-9208-52c8c234c30e\",",
    "2025-11-25T22:43:06.9312348Z     \"isDefault\": true,",
    "2025-11-25T22:43:06.9312597Z     \"managedByTenants\": [",
    "2025-11-25T22:43:06.9312821Z       {",
    "2025-11-25T22:43:06.9313093Z         \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"",
    "2025-11-25T22:43:06.9313679Z       }",
    "2025-11-25T22:43:06.9313880Z     ],",
    "2025-11-25T22:43:06.9314138Z     \"name\": \"Synapse_OSS_ML_DevTest_001\",",
    "2025-11-25T22:43:06.9314408Z     \"state\": \"Enabled\",",
    "2025-11-25T22:43:06.9314681Z     \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",",
    "2025-11-25T22:43:06.9314961Z     \"user\": {",
    "2025-11-25T22:43:06.9315349Z       \"name\": \"***\",",
    "2025-11-25T22:43:06.9315596Z       \"type\": \"servicePrincipal\"",
    "2025-11-25T22:43:06.9315846Z     }",
    "2025-11-25T22:43:06.9316045Z   }",
    "2025-11-25T22:43:06.9316247Z ]",
    "2025-11-25T22:43:06.9339111Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account set --subscription e342c2c0-f844-4b18-9208-52c8c234c30e",
    "2025-11-25T22:43:07.5341666Z [command]/usr/bin/bash /home/vsts/work/_temp/azureclitaskscript1764110584610.sh",
    "2025-11-25T22:43:10.0776175Z [info] welcome to sbt 1.10.11 (Eclipse Adoptium Java 17.0.17)",
    "2025-11-25T22:43:11.3805864Z [info] loading settings for project s-build from assembly.sbt, build.sbt, plugins.sbt...",
    "2025-11-25T22:43:12.5479575Z [info] loading project definition from /home/vsts/work/1/s/project",
    "2025-11-25T22:43:15.2284516Z [info] loading settings for project root from build.sbt, sonatype.sbt...",
    "2025-11-25T22:43:16.2050025Z [warn] Secret pgp-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:43:16.2091013Z [warn] Secret pgp-private not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:43:16.2091951Z [warn] Secret pgp-public not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:43:17.1761801Z [info] set current project to synapseml (in build file:/home/vsts/work/1/s/)",
    "2025-11-25T22:43:17.6131574Z [warn] Secret ado-feed-token not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:43:17.6135340Z [warn] Secret nexus-un not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:43:17.6141313Z [warn] Secret nexus-pw not downloaded. Set SYNAPSEML_ENABLE_PUBLISH=true to enable publishing.",
    "2025-11-25T22:43:27.9274251Z [info] RankingAdapterModelSpec:",
    "2025-11-25T22:43:28.4402285Z Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties",
    "2025-11-25T22:43:28.4641807Z 25/11/25 22:43:28 INFO RecommendationIndexer: {\"protocolVersion\":\"0.0.1\",\"method\":\"constructor\",\"libraryName\":\"SynapseML\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RecommendationIndexer\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RecommendationIndexer_3c87d9b606d4\"}",
    "2025-11-25T22:43:29.9719721Z 25/11/25 22:43:29 INFO SparkContext: Running Spark version 4.0.1",
    "2025-11-25T22:43:29.9740293Z 25/11/25 22:43:29 INFO SparkContext: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:43:29.9749663Z 25/11/25 22:43:29 INFO SparkContext: Java version 17.0.17",
    "2025-11-25T22:43:30.2111419Z 25/11/25 22:43:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable",
    "2025-11-25T22:43:30.2868391Z 25/11/25 22:43:30 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:43:30.2887100Z 25/11/25 22:43:30 INFO ResourceUtils: No custom resources configured for spark.driver.",
    "2025-11-25T22:43:30.2890842Z 25/11/25 22:43:30 INFO ResourceUtils: ==============================================================",
    "2025-11-25T22:43:30.2912851Z 25/11/25 22:43:30 INFO SparkContext: Submitted application: com.microsoft.azure.synapse.ml.core.test.base.TestBase$@16806222",
    "2025-11-25T22:43:30.2988325Z 25/11/25 22:43:30 INFO SparkContext: Spark configuration:",
    "2025-11-25T22:43:30.2990281Z spark.app.name=com.microsoft.azure.synapse.ml.core.test.base.TestBase$@16806222",
    "2025-11-25T22:43:30.2991084Z spark.app.startTime=1764110609964",
    "2025-11-25T22:43:30.2992611Z spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:43:30.2994872Z spark.driver.maxResultSize=6g",
    "2025-11-25T22:43:30.2996601Z spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true",
    "2025-11-25T22:43:30.2998416Z spark.hadoop.fs.s3a.vectored.read.max.merged.size=2M",
    "2025-11-25T22:43:30.2999185Z spark.hadoop.fs.s3a.vectored.read.min.seek.size=128K",
    "2025-11-25T22:43:30.2999866Z spark.logConf=true",
    "2025-11-25T22:43:30.3000500Z spark.master=local[*]",
    "2025-11-25T22:43:30.3001161Z spark.sql.crossJoin.enabled=true",
    "2025-11-25T22:43:30.3001829Z spark.sql.shuffle.partitions=20",
    "2025-11-25T22:43:30.3002509Z spark.sql.warehouse.dir=file:/home/vsts/work/1/s/core/spark-warehouse",
    "2025-11-25T22:43:30.3309805Z 25/11/25 22:43:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)",
    "2025-11-25T22:43:30.3332432Z 25/11/25 22:43:30 INFO ResourceProfile: Limiting resource is cpu",
    "2025-11-25T22:43:30.3351479Z 25/11/25 22:43:30 INFO ResourceProfileManager: Added ResourceProfile id: 0",
    "2025-11-25T22:43:30.3903313Z 25/11/25 22:43:30 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:43:30.3922090Z 25/11/25 22:43:30 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:43:30.3928310Z 25/11/25 22:43:30 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:43:30.3937073Z 25/11/25 22:43:30 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:43:30.3970971Z 25/11/25 22:43:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:43:30.6686604Z 25/11/25 22:43:30 INFO Utils: Successfully started service 'sparkDriver' on port 45169.",
    "2025-11-25T22:43:30.6960551Z 25/11/25 22:43:30 INFO SparkEnv: Registering MapOutputTracker",
    "2025-11-25T22:43:30.7097399Z 25/11/25 22:43:30 INFO SparkEnv: Registering BlockManagerMaster",
    "2025-11-25T22:43:30.7282775Z 25/11/25 22:43:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information",
    "2025-11-25T22:43:30.7284267Z 25/11/25 22:43:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up",
    "2025-11-25T22:43:30.7315136Z 25/11/25 22:43:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat",
    "2025-11-25T22:43:30.7536343Z 25/11/25 22:43:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-902d891c-a703-4ddf-8765-93cdf612106d",
    "2025-11-25T22:43:30.7969493Z 25/11/25 22:43:30 INFO SparkEnv: Registering OutputCommitCoordinator",
    "2025-11-25T22:43:30.9223086Z 25/11/25 22:43:30 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI",
    "2025-11-25T22:43:30.9985998Z 25/11/25 22:43:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.",
    "2025-11-25T22:43:31.0762782Z 25/11/25 22:43:31 INFO SecurityManager: Changing view acls to: vsts",
    "2025-11-25T22:43:31.0763788Z 25/11/25 22:43:31 INFO SecurityManager: Changing modify acls to: vsts",
    "2025-11-25T22:43:31.0764257Z 25/11/25 22:43:31 INFO SecurityManager: Changing view acls groups to: vsts",
    "2025-11-25T22:43:31.0764722Z 25/11/25 22:43:31 INFO SecurityManager: Changing modify acls groups to: vsts",
    "2025-11-25T22:43:31.0765357Z 25/11/25 22:43:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vsts groups with view permissions: EMPTY; users with modify permissions: vsts; groups with modify permissions: EMPTY; RPC SSL disabled",
    "2025-11-25T22:43:31.2393975Z 25/11/25 22:43:31 INFO Executor: Starting executor ID driver on host runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net",
    "2025-11-25T22:43:31.2401678Z 25/11/25 22:43:31 INFO Executor: OS info Linux, 6.8.0-1041-azure, amd64",
    "2025-11-25T22:43:31.2402677Z 25/11/25 22:43:31 INFO Executor: Java version 17.0.17",
    "2025-11-25T22:43:31.2557507Z 25/11/25 22:43:31 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''",
    "2025-11-25T22:43:31.2574006Z 25/11/25 22:43:31 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@33e1bd6a for default.",
    "2025-11-25T22:43:31.2902931Z 25/11/25 22:43:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38393.",
    "2025-11-25T22:43:31.3039077Z 25/11/25 22:43:31 INFO NettyBlockTransferService: Server created on runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net:38393",
    "2025-11-25T22:43:31.3066852Z 25/11/25 22:43:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy",
    "2025-11-25T22:43:31.3246667Z 25/11/25 22:43:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 38393, None)",
    "2025-11-25T22:43:31.3363435Z 25/11/25 22:43:31 INFO BlockManagerMasterEndpoint: Registering block manager runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net:38393 with 861.6 MiB RAM, BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 38393, None)",
    "2025-11-25T22:43:31.3399936Z 25/11/25 22:43:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 38393, None)",
    "2025-11-25T22:43:31.3418525Z 25/11/25 22:43:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net, 38393, None)",
    "2025-11-25T22:43:42.7750891Z 25/11/25 22:43:42 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS",
    "2025-11-25T22:43:53.3202704Z [info] - Serialization Fuzzing",
    "2025-11-25T22:43:53.3336239Z [info] + Test Serialization Fuzzing took 25.462s ",
    "2025-11-25T22:43:55.1869312Z [info] - Experiment Fuzzing",
    "2025-11-25T22:43:55.1903964Z [info] + Test Experiment Fuzzing took 1.852s ",
    "2025-11-25T22:43:56.4793022Z Testing parameter itemCol",
    "2025-11-25T22:43:56.4794522Z Testing parameter k",
    "2025-11-25T22:43:56.4803622Z Testing parameter labelCol",
    "2025-11-25T22:43:56.4814091Z Testing parameter minRatingsPerItem",
    "2025-11-25T22:43:56.4822372Z Testing parameter minRatingsPerUser",
    "2025-11-25T22:43:56.4830594Z Testing parameter mode",
    "2025-11-25T22:43:56.4838802Z Testing parameter ratingCol",
    "2025-11-25T22:43:56.4846424Z Testing parameter recommender",
    "2025-11-25T22:43:56.4922833Z Could not test parameter recommender",
    "2025-11-25T22:43:56.4959119Z Testing parameter recommenderModel",
    "2025-11-25T22:43:56.4959660Z Testing parameter userCol",
    "2025-11-25T22:43:56.4960045Z 25/11/25 22:43:56 WARN DefaultParamInfo: unsupported type RankingAdapterModel_457fa9fc980e__recommender",
    "2025-11-25T22:43:56.4960425Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:43:56.4977761Z [info] + Test Getters and Setters work as anticipated took 1.309s ",
    "2025-11-25T22:43:56.5003266Z Alert Provided - Suite RankingAdapterModelSpec took 28.623s",
    "2025-11-25T22:43:56.5569452Z 25/11/25 22:43:56 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:43:56.6177454Z [info] RankingAdapterSpec:",
    "2025-11-25T22:44:14.0151285Z [info] - Serialization Fuzzing",
    "2025-11-25T22:44:14.0152672Z [info] + Test Serialization Fuzzing took 17.495s ",
    "2025-11-25T22:44:15.2703851Z [info] - Experiment Fuzzing",
    "2025-11-25T22:44:15.2723138Z [info] + Test Experiment Fuzzing took 1.255s ",
    "2025-11-25T22:44:15.2739637Z Testing parameter itemCol",
    "2025-11-25T22:44:15.2744924Z Testing parameter k",
    "2025-11-25T22:44:15.2749125Z Testing parameter labelCol",
    "2025-11-25T22:44:15.2752737Z Testing parameter minRatingsPerItem",
    "2025-11-25T22:44:15.2756254Z Testing parameter minRatingsPerUser",
    "2025-11-25T22:44:15.2788827Z Testing parameter mode",
    "2025-11-25T22:44:15.2798761Z Testing parameter ratingCol",
    "2025-11-25T22:44:15.2801528Z Testing parameter recommender",
    "2025-11-25T22:44:15.2804351Z Could not test parameter recommender",
    "2025-11-25T22:44:15.2804702Z Testing parameter userCol",
    "2025-11-25T22:44:15.2805742Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:44:15.2806374Z [info] + Test Getters and Setters work as anticipated took 0.005s ",
    "2025-11-25T22:44:15.2806790Z Alert Provided - Suite RankingAdapterSpec took 18.755s",
    "2025-11-25T22:44:15.2956778Z [info] SARModelSpec:",
    "2025-11-25T22:44:15.3123026Z 25/11/25 22:44:15 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:23.8789611Z [info] - Serialization Fuzzing",
    "2025-11-25T22:44:23.8804976Z [info] + Test Serialization Fuzzing took 8.587s ",
    "2025-11-25T22:44:24.6992721Z [info] - Experiment Fuzzing",
    "2025-11-25T22:44:24.6993682Z [info] + Test Experiment Fuzzing took 0.813s ",
    "2025-11-25T22:44:25.6249354Z Testing parameter activityTimeFormat",
    "2025-11-25T22:44:25.6250824Z Could not test parameter activityTimeFormat",
    "2025-11-25T22:44:25.6251427Z Testing parameter alpha",
    "2025-11-25T22:44:25.6252036Z Testing parameter blockSize",
    "2025-11-25T22:44:25.6278968Z Testing parameter checkpointInterval",
    "2025-11-25T22:44:25.6281508Z Testing parameter coldStartStrategy",
    "2025-11-25T22:44:25.6282315Z Testing parameter finalStorageLevel",
    "2025-11-25T22:44:25.6282895Z Testing parameter implicitPrefs",
    "2025-11-25T22:44:25.6283433Z Testing parameter intermediateStorageLevel",
    "2025-11-25T22:44:25.6283941Z Testing parameter itemCol",
    "2025-11-25T22:44:25.6284435Z Testing parameter itemDataFrame",
    "2025-11-25T22:44:25.6284939Z Testing parameter maxIter",
    "2025-11-25T22:44:25.6289744Z Testing parameter nonnegative",
    "2025-11-25T22:44:25.6290603Z Testing parameter numItemBlocks",
    "2025-11-25T22:44:25.6291219Z Testing parameter numUserBlocks",
    "2025-11-25T22:44:25.6320586Z Testing parameter predictionCol",
    "2025-11-25T22:44:25.6321463Z Testing parameter rank",
    "2025-11-25T22:44:25.6322026Z Testing parameter ratingCol",
    "2025-11-25T22:44:25.6322632Z Testing parameter regParam",
    "2025-11-25T22:44:25.6323162Z Testing parameter seed",
    "2025-11-25T22:44:25.6323659Z Testing parameter similarityFunction",
    "2025-11-25T22:44:25.6324178Z Could not test parameter similarityFunction",
    "2025-11-25T22:44:25.6324699Z Testing parameter startTime",
    "2025-11-25T22:44:25.6325193Z Could not test parameter startTime",
    "2025-11-25T22:44:25.6349012Z Testing parameter startTimeFormat",
    "2025-11-25T22:44:25.6349962Z Could not test parameter startTimeFormat",
    "2025-11-25T22:44:25.6350549Z Testing parameter supportThreshold",
    "2025-11-25T22:44:25.6351156Z Could not test parameter supportThreshold",
    "2025-11-25T22:44:25.6351670Z Testing parameter timeCol",
    "2025-11-25T22:44:25.6352474Z Could not test parameter timeCol",
    "2025-11-25T22:44:25.6352992Z Testing parameter timeDecayCoeff",
    "2025-11-25T22:44:25.6353497Z Could not test parameter timeDecayCoeff",
    "2025-11-25T22:44:25.6353989Z Testing parameter userCol",
    "2025-11-25T22:44:25.6354552Z Testing parameter userDataFrame",
    "2025-11-25T22:44:25.6355088Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:44:25.6355645Z [info] + Test Getters and Setters work as anticipated took 0.942s ",
    "2025-11-25T22:44:25.6363912Z Alert Provided - Suite SARModelSpec took 10.342s",
    "2025-11-25T22:44:25.6549458Z [info] RankingEvaluatorSpec:",
    "2025-11-25T22:44:25.7481654Z 25/11/25 22:44:25 WARN BlockManager: Putting block rdd_3194_0 failed due to exception scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:25.7494180Z 25/11/25 22:44:25 WARN BlockManager: Block rdd_3194_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:25.7497263Z 25/11/25 22:44:25 ERROR Executor: Exception in task 0.0 in stage 1796.0 (TID 1969)",
    "2025-11-25T22:44:25.7497859Z scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.7498695Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.7499216Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.7499676Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.7500149Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.7500634Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.7501133Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.7501632Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.7502114Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.7502580Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.7503029Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.7503433Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.7503926Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7504367Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7504778Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7505211Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7505647Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7506072Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7506494Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7507261Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7507692Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7508226Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.7508794Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.7509092Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.7509370Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.7509680Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.7510001Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.7510289Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.7510698Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.7511000Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.7511313Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.7511604Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.7692874Z 25/11/25 22:44:25 WARN TaskSetManager: Lost task 0.0 in stage 1796.0 (TID 1969) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.7694476Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.7695219Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.7695712Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.7696222Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.7696735Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.7697264Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.7697795Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.7698383Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.7698901Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.7699355Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.7699786Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.7700228Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7700707Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7701141Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7701578Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7702241Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7702780Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7703263Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7703750Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7704204Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7704672Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.7705161Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.7705646Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.7706239Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.7707043Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.7707531Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.7707996Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.7708545Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.7709313Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.7709828Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.7710269Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.7710513Z ",
    "2025-11-25T22:44:25.7739967Z 25/11/25 22:44:25 ERROR TaskSetManager: Task 0 in stage 1796.0 failed 1 times; aborting job",
    "2025-11-25T22:44:25.7907645Z [info] - testAllTrue *** FAILED ***",
    "2025-11-25T22:44:25.7930839Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1796.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1796.0 (TID 1969) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.7932505Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.7933179Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.7936295Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.7937033Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.7937524Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.7938051Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.7938783Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.7939227Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.7939693Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.7940107Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.7940485Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.7940880Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7941291Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7941687Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7942090Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7942500Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7942891Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7943284Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.7943706Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.7944077Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.7944455Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.7944880Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.7945272Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.7945679Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.7946326Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.7946773Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.7947211Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.7947617Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.7948053Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.7948627Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.7949024Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.7949299Z [info] ",
    "2025-11-25T22:44:25.7949648Z [info] Driver stacktrace:",
    "2025-11-25T22:44:25.7950009Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:25.7950416Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:25.7950836Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:25.7951305Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:25.7951747Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:25.7952170Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:25.7952629Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:25.7953136Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:25.7953558Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:25.7953970Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:25.7954325Z [info]   ...",
    "2025-11-25T22:44:25.7954688Z [info]   Cause: scala.MatchError: [ArraySeq(1, 2, 3),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.7955318Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.7955745Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.7956128Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.7956557Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.7956980Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.7957451Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.7957900Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.7989032Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.7989635Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.7990056Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.7990368Z [info]   ...",
    "2025-11-25T22:44:25.8104739Z [info] + Test testAllTrue took 0.165s ",
    "2025-11-25T22:44:25.8886724Z 25/11/25 22:44:25 WARN BlockManager: Putting block rdd_3203_0 failed due to exception scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:25.8888051Z 25/11/25 22:44:25 WARN BlockManager: Block rdd_3203_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:25.8889316Z 25/11/25 22:44:25 ERROR Executor: Exception in task 0.0 in stage 1797.0 (TID 1970)",
    "2025-11-25T22:44:25.8890523Z scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.8891020Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.8891447Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.8891837Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.8892242Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.8892663Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.8893129Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.8893891Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.8894341Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.8894779Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.8895182Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.8895551Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.8895932Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.8896342Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.8896726Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.8897111Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.8897509Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.8897894Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.8898394Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.8898821Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.8899294Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.8899636Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.8900027Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.8900380Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.8900746Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.8901164Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.8901569Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.8901951Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.8902330Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.8902724Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.8903151Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.8903514Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.8904044Z 25/11/25 22:44:25 WARN TaskSetManager: Lost task 0.0 in stage 1797.0 (TID 1970) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.8904706Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.8905123Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.8905593Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.8906030Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.8906388Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.8906791Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.8907169Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.8907530Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.8907885Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.8908301Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.8908732Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.8909047Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.8909389Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.8909690Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.8909997Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.8910336Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.8910642Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.8910950Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.8911282Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.8911579Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.8911877Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.8912220Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.8912527Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.8912856Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.8913203Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.8913554Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.8913903Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.8914220Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.8914562Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.8914934Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.8915251Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.8915389Z ",
    "2025-11-25T22:44:25.8960306Z 25/11/25 22:44:25 ERROR TaskSetManager: Task 0 in stage 1797.0 failed 1 times; aborting job",
    "2025-11-25T22:44:25.8984923Z [info] - testAllMiss *** FAILED ***",
    "2025-11-25T22:44:25.9008350Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1797.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1797.0 (TID 1970) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.9009477Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.9010049Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.9010578Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.9011136Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.9011927Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.9012527Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.9013094Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.9013635Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.9014103Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.9015003Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.9015514Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.9016005Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9016663Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9017135Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9017629Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9018236Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9018733Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9019218Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9019756Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9020236Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9020708Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.9021231Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.9021711Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.9022228Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.9022766Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.9023306Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.9023833Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.9024332Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.9024878Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.9025428Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.9025937Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.9026303Z [info] ",
    "2025-11-25T22:44:25.9026564Z [info] Driver stacktrace:",
    "2025-11-25T22:44:25.9027036Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:25.9027526Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:25.9028057Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:25.9028711Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:25.9029256Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:25.9029755Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:25.9080286Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:25.9086828Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:25.9087624Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:25.9088057Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:25.9088540Z [info]   ...",
    "2025-11-25T22:44:25.9088907Z [info]   Cause: scala.MatchError: [ArraySeq(4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.9089436Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.9089896Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.9090331Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.9090791Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.9091367Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.9091877Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.9092563Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.9093115Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.9093655Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.9094194Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.9094590Z [info]   ...",
    "2025-11-25T22:44:25.9094951Z [info] + Test testAllMiss took 0.091s ",
    "2025-11-25T22:44:25.9840639Z 25/11/25 22:44:25 WARN BlockManager: Putting block rdd_3212_0 failed due to exception scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:25.9884054Z 25/11/25 22:44:25 WARN BlockManager: Block rdd_3212_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:25.9885424Z 25/11/25 22:44:25 ERROR Executor: Exception in task 0.0 in stage 1798.0 (TID 1971)",
    "2025-11-25T22:44:25.9888725Z scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.9890151Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.9893883Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.9894541Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.9895074Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.9895626Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.9896192Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.9897067Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.9902821Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.9903650Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.9904140Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.9904590Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.9905048Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9905541Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9905988Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9906876Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9907442Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9908921Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9914717Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9915591Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9920463Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9921064Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.9922192Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.9922751Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.9923244Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.9923759Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.9924497Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.9925012Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.9925483Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.9925987Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.9926534Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.9926998Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.9927721Z 25/11/25 22:44:25 WARN TaskSetManager: Lost task 0.0 in stage 1798.0 (TID 1971) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.9928656Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:25.9929205Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:25.9929685Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:25.9930208Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:25.9930780Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:25.9931335Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:25.9931889Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:25.9932391Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:25.9932906Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:25.9933397Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:25.9933825Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:25.9934279Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9935032Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9935553Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9936018Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9936490Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9936926Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9937389Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:25.9937858Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:25.9938411Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:25.9938899Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:25.9939535Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:25.9939987Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:25.9940469Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:25.9940986Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:25.9941538Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:25.9942023Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:25.9942489Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:25.9968741Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:25.9969787Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:25.9970273Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:25.9970537Z ",
    "2025-11-25T22:44:25.9970926Z 25/11/25 22:44:25 ERROR TaskSetManager: Task 0 in stage 1798.0 failed 1 times; aborting job",
    "2025-11-25T22:44:25.9993811Z [info] - testOrder *** FAILED ***",
    "2025-11-25T22:44:25.9995852Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1798.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1798.0 (TID 1971) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:25.9997025Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:26.0000725Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:26.0001666Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:26.0005766Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:26.0008356Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:26.0026231Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:26.0027547Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:26.0032509Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:26.0034836Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:26.0070289Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:26.0070897Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:26.0071305Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.0071731Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.0072131Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.0072523Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.0072936Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.0073326Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.0073717Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.0074145Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.0074520Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.0074907Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:26.0075336Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:26.0075955Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:26.0076360Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:26.0076825Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:26.0077275Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:26.0077716Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:26.0078286Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:26.0078737Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:26.0079336Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:26.0079736Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:26.0080035Z [info] ",
    "2025-11-25T22:44:26.0080274Z [info] Driver stacktrace:",
    "2025-11-25T22:44:26.0080642Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:26.0081063Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:26.0081468Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:26.0081944Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:26.0082393Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:26.0082800Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:26.0083260Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:26.0083777Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:26.0084202Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:26.0084618Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:26.0085000Z [info]   ...",
    "2025-11-25T22:44:26.0085362Z [info]   Cause: scala.MatchError: [ArraySeq(3, 2, 1),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:26.0085909Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:26.0086367Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:26.0086796Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:26.0087249Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:26.0087717Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:26.0103312Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:26.0109207Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:26.0128964Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:26.0129774Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:26.0130282Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:26.0130678Z [info]   ...",
    "2025-11-25T22:44:26.0131009Z [info] + Test testOrder took 0.097s ",
    "2025-11-25T22:44:26.1091622Z 25/11/25 22:44:26 WARN BlockManager: Putting block rdd_3221_0 failed due to exception scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:26.1093825Z 25/11/25 22:44:26 WARN BlockManager: Block rdd_3221_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:26.1094576Z 25/11/25 22:44:26 ERROR Executor: Exception in task 0.0 in stage 1799.0 (TID 1972)",
    "2025-11-25T22:44:26.1099241Z scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:26.1100216Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:26.1101061Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:26.1101837Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:26.1102870Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:26.1103695Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:26.1104562Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:26.1105410Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:26.1107591Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:26.1109097Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:26.1109617Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:26.1110062Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:26.1110516Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1110991Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1111453Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1111909Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1112394Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1112834Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1113287Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1113772Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1114209Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1199035Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:26.1199855Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:26.1200251Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:26.1200653Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:26.1201160Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:26.1201667Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:26.1202134Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:26.1202572Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:26.1203041Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:26.1203543Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:26.1203974Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:26.1204752Z 25/11/25 22:44:26 WARN TaskSetManager: Lost task 0.0 in stage 1799.0 (TID 1972) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:26.1205671Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:26.1206179Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:26.1206626Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:26.1207120Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:26.1207609Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:26.1208344Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:26.1208889Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:26.1209357Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:26.1209955Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:26.1210509Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:26.1210875Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:26.1211284Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1211692Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1212069Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1212476Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1212880Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1213258Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1213664Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1214275Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1214680Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1215109Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:26.1215546Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:26.1215982Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:26.1216414Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:26.1216890Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:26.1217384Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:26.1217837Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:26.1254317Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:26.1255249Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:26.1255749Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:26.1256162Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:26.1256322Z ",
    "2025-11-25T22:44:26.1256634Z 25/11/25 22:44:26 ERROR TaskSetManager: Task 0 in stage 1799.0 failed 1 times; aborting job",
    "2025-11-25T22:44:26.1256975Z [info] - testExtra *** FAILED ***",
    "2025-11-25T22:44:26.1257267Z Info Provided - Suite RankingEvaluatorSpec took 0.471s",
    "2025-11-25T22:44:26.1258327Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1799.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1799.0 (TID 1972) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:26.1259142Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:26.1259840Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:26.1260256Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:26.1260709Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:26.1261216Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:26.1261736Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:26.1262262Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:26.1262725Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:26.1263310Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:26.1263772Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:26.1264173Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:26.1264591Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1265078Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1265503Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1265952Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1266404Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1266822Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1267275Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:26.1267728Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:26.1268233Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:26.1268682Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:26.1269141Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:26.1269583Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:26.1270027Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:26.1270511Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:26.1271020Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:26.1271486Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:26.1271933Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:26.1272425Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:26.1272921Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:26.1273367Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:26.1273683Z [info] ",
    "2025-11-25T22:44:26.1273959Z [info] Driver stacktrace:",
    "2025-11-25T22:44:26.1274372Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:26.1274809Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:26.1275250Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:26.1275773Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:26.1276244Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:26.1276687Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:26.1277293Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:26.1277832Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:26.1390510Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:26.1391278Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:26.1391672Z [info]   ...",
    "2025-11-25T22:44:26.1392058Z [info]   Cause: scala.MatchError: [ArraySeq(1, 2, 3, 4, 5, 6),ArraySeq(1, 2, 3)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:26.1392572Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:26.1393343Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:26.1393764Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:26.1394315Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:26.1394798Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:26.1395284Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:26.1395776Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:26.1396242Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:26.1396737Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:26.1397207Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:26.1397543Z [info]   ...",
    "2025-11-25T22:44:26.1397834Z [info] + Test testExtra took 0.118s ",
    "2025-11-25T22:44:26.1949877Z 25/11/25 22:44:26 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:26.2146533Z [info] RankingTrainValidationSplitModelSpec:",
    "2025-11-25T22:44:26.8823539Z 25/11/25 22:44:26 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:32.7485047Z 25/11/25 22:44:32 WARN BlockManager: Putting block rdd_3577_0 failed due to exception scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:32.7490008Z 25/11/25 22:44:32 WARN BlockManager: Block rdd_3577_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:32.7502082Z 25/11/25 22:44:32 ERROR Executor: Exception in task 0.0 in stage 1983.0 (TID 2372)",
    "2025-11-25T22:44:32.7505742Z scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:32.7506372Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:32.7506874Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:32.7507330Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:32.7507808Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:32.7508501Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:32.7509030Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:32.7509534Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:32.7510011Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:32.7510488Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:32.7511322Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:32.7511715Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:32.7512136Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7512591Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7512995Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7513407Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7515791Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7516173Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7516551Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7517214Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7517577Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7517958Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:32.7518528Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:32.7518908Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:32.7519313Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:32.7519748Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:32.7520182Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:32.7520605Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:32.7520996Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:32.7521421Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:32.7521883Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:32.7522268Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:32.7536390Z 25/11/25 22:44:32 WARN TaskSetManager: Lost task 0.0 in stage 1983.0 (TID 2372) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:32.7537346Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:32.7537871Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:32.7539406Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:32.7539895Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:32.7540353Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:32.7540847Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:32.7541332Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:32.7541766Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:32.7542206Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:32.7542630Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:32.7542992Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:32.7543395Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7543803Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7544184Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7544813Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7545220Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7545598Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7546005Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7546405Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7546786Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7547178Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:32.7547584Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:32.7548074Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:32.7548523Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:32.7549000Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:32.7549411Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:32.7549778Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:32.7550128Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:32.7550514Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:32.7550945Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:32.7551493Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:32.7551690Z ",
    "2025-11-25T22:44:32.7552018Z 25/11/25 22:44:32 ERROR TaskSetManager: Task 0 in stage 1983.0 failed 1 times; aborting job",
    "2025-11-25T22:44:32.7585071Z 25/11/25 22:44:32 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_6163de7eb418\"}",
    "2025-11-25T22:44:32.7589641Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:44:32.7602767Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:44:32.7603269Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:44:32.7603824Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:32.7604443Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:32.7604974Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:32.7627043Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:32.7627800Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:44:32.7628502Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:44:32.7629021Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:32.7629524Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:44:32.7630006Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:44:32.7630510Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:32.7631062Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:44:32.7631851Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testObjects(RankingTrainValidationSpec.scala:47)",
    "2025-11-25T22:44:32.7632381Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.serializationTestObjects(Fuzzing.scala:614)",
    "2025-11-25T22:44:32.7632883Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.serializationTestObjects$(Fuzzing.scala:614)",
    "2025-11-25T22:44:32.7633435Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.serializationTestObjects(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:44:32.7634010Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization(Fuzzing.scala:506)",
    "2025-11-25T22:44:32.7634518Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization$(Fuzzing.scala:504)",
    "2025-11-25T22:44:32.7635175Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testSerialization(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:44:32.7635728Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$$init$$2(Fuzzing.scala:539)",
    "2025-11-25T22:44:32.7636157Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:44:32.7636536Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:44:32.7636900Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:44:32.7637258Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:44:32.7637737Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:44:32.7638244Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:44:32.7638659Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:44:32.7639066Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:44:32.7639476Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:32.7639907Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:44:32.7640370Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:44:32.7640779Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:44:32.7641169Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:44:32.7641600Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:44:32.7642091Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:44:32.7642595Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:44:32.7643054Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:44:32.7643501Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:44:32.7643950Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:44:32.7644374Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:44:32.7644757Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:32.7645138Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:44:32.7645515Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:44:32.7645883Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:44:32.7646286Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:44:32.7646708Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:44:32.7647131Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:32.7647569Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:44:32.7647901Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:44:32.7696806Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:32.7697746Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:44:32.7698322Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:44:32.7698740Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:44:32.7699146Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:44:32.7699632Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:44:32.7700105Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:44:32.7700716Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:44:32.7701132Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:44:32.7719955Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:44:32.7720435Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:44:32.7720891Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:44:32.7721299Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:44:32.7721684Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:44:32.7722099Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:32.7722542Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:32.7722951Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:32.7723612Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1983.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1983.0 (TID 2372) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:32.7724383Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:32.7724829Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:32.7725230Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:32.7725681Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:32.7726124Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:32.7726617Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:32.7727083Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:32.7727508Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:32.7727957Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:32.7728486Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:32.7728857Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:32.7729239Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7729641Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7730023Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7730406Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7730806Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7731428Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7731806Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7732203Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7732585Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7732951Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:32.7733372Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:32.7733753Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:32.7734143Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:32.7734594Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:32.7735119Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:32.7735534Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:32.7735968Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:32.7736391Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:32.7736841Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:32.7737244Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:32.7737400Z ",
    "2025-11-25T22:44:32.7737645Z Driver stacktrace:",
    "2025-11-25T22:44:32.7737996Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:32.7776699Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:32.7777193Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:32.7777720Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:32.7778339Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:32.7778792Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:32.7779290Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:32.7779831Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:32.7780284Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:32.7780711Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:32.7781227Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:44:32.7781727Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:44:32.7782251Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:44:32.7782713Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:44:32.7783149Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:44:32.7783590Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:44:32.7783970Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:44:32.7784380Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:44:32.7784842Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:32.7785309Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:32.7785752Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:32.7786139Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:44:32.7786586Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:44:32.7787259Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:32.7787733Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:32.7788255Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:32.7788704Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:44:32.7789176Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:44:32.7789658Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:44:32.7790112Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:32.7790571Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:32.7791110Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:32.7818774Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:44:32.7819396Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:44:32.7819893Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:44:32.7820394Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:44:32.7820901Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:44:32.7821394Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:44:32.7821942Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:44:32.7822585Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:44:32.7823108Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:44:32.7823551Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:44:32.7823974Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:44:32.7824412Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:44:32.7824883Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:44:32.7825350Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:44:32.7825828Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:44:32.7826299Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:44:32.7826761Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:44:32.7827184Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:44:32.7827680Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:44:32.7828283Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:32.7828824Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:44:32.7829251Z \t... 61 more",
    "2025-11-25T22:44:32.7829673Z Caused by: scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:32.7830218Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:32.7830700Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:32.7831154Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:32.7831880Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:32.7832370Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:32.7832906Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:32.7833406Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:32.7833886Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:32.7834453Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:32.7834888Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:32.7835296Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:32.7835806Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7836251Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7836674Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7837090Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7837544Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7837949Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7868290Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7868808Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7869493Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7869929Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:32.7870387Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:32.7870821Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:32.7871262Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:32.7871750Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:32.7872229Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:32.7872689Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:32.7873126Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:32.7873458Z \t... 3 more",
    "2025-11-25T22:44:32.7873815Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:44:32.7874136Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:44:32.7874542Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:44:32.7874976Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:44:32.7875507Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:32.7876152Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:32.7876682Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:32.7877217Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:32.7877778Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:44:32.7878396Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:44:32.7878955Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:32.7879689Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:44:32.7880088Z [info]   ...",
    "2025-11-25T22:44:32.7880737Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1983.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1983.0 (TID 2372) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:32.7881546Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:32.7882043Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:32.7882514Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:32.7883103Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:32.7883609Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:32.7884152Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:32.7884661Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:32.7885135Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:32.7885700Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:32.7886153Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:32.7886569Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:32.7886993Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7887403Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7887800Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7908564Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7909212Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7909616Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7910014Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:32.7910439Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:32.7910816Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:32.7911201Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:32.7911641Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:32.7912033Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:32.7912443Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:32.7912905Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:32.7913354Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:32.7913792Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:32.7914198Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:32.7914634Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:32.7915106Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:32.7915505Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:32.7915783Z [info] ",
    "2025-11-25T22:44:32.7916205Z [info] Driver stacktrace:",
    "2025-11-25T22:44:32.7916568Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:32.7916986Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:32.7917388Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:32.7917864Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:32.7918450Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:32.7918898Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:32.7919356Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:32.7919959Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:32.7920384Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:32.7920799Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:32.7921202Z 25/11/25 22:44:32 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:32.7921485Z [info]   ...",
    "2025-11-25T22:44:32.7921863Z [info]   Cause: scala.MatchError: [ArraySeq(8, 7, 5),ArraySeq(8.0, 1.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:32.7922375Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:32.7922846Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:32.7923281Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:32.7923735Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:32.7924212Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:32.7924697Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:32.7925175Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:32.7925621Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:32.7926061Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:32.7926485Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:32.7926782Z [info]   ...",
    "2025-11-25T22:44:32.7927045Z [info] + Test Serialization Fuzzing took 6.627s ",
    "2025-11-25T22:44:33.0985633Z 25/11/25 22:44:33 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:33.1107782Z 25/11/25 22:44:33 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:36.6011316Z 25/11/25 22:44:36 WARN BlockManager: Putting block rdd_3880_0 failed due to exception scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:36.6020891Z 25/11/25 22:44:36 WARN BlockManager: Block rdd_3880_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:36.6033370Z 25/11/25 22:44:36 ERROR Executor: Exception in task 0.0 in stage 2137.0 (TID 2627)",
    "2025-11-25T22:44:36.6034267Z scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:36.6034972Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:36.6035715Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:36.6036274Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:36.6037189Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:36.6037811Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:36.6038582Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:36.6039219Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:36.6039791Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:36.6040388Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:36.6040938Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:36.6041630Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:36.6042178Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6042915Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6043486Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6044049Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6044647Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6045285Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6045809Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6046368Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6046882Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6047408Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:36.6047967Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:36.6048595Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:36.6049161Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:36.6049935Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:36.6050596Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:36.6051254Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:36.6051850Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:36.6052466Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:36.6053108Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:36.6053727Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:36.6076689Z 25/11/25 22:44:36 WARN TaskSetManager: Lost task 0.0 in stage 2137.0 (TID 2627) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:36.6077916Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:36.6078771Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:36.6079973Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:36.6080710Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:36.6081344Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:36.6084909Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:36.6086504Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:36.6087182Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:36.6087642Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:36.6088046Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:36.6088522Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:36.6088926Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6089331Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6089703Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6090108Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6090507Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6091013Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6091414Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6091815Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6092198Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6092568Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:36.6092970Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:36.6093371Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:36.6093767Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:36.6094200Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:36.6094655Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:36.6095075Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:36.6095466Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:36.6095910Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:36.6096373Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:36.6096805Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:36.6096967Z ",
    "2025-11-25T22:44:36.6097286Z 25/11/25 22:44:36 ERROR TaskSetManager: Task 0 in stage 2137.0 failed 1 times; aborting job",
    "2025-11-25T22:44:36.6143649Z 25/11/25 22:44:36 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_6163de7eb418\"}",
    "2025-11-25T22:44:36.6169212Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:44:36.6209087Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:44:36.6209804Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:44:36.6210359Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:36.6210996Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:36.6211519Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:36.6212032Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:36.6212612Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:44:36.6213118Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:44:36.6213978Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:36.6214525Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:44:36.6215023Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:44:36.6215582Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:36.6216156Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:44:36.6216767Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testObjects(RankingTrainValidationSpec.scala:47)",
    "2025-11-25T22:44:36.6217637Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.experimentTestObjects(Fuzzing.scala:616)",
    "2025-11-25T22:44:36.6218435Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.experimentTestObjects$(Fuzzing.scala:616)",
    "2025-11-25T22:44:36.6219119Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.experimentTestObjects(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:44:36.6219871Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments(Fuzzing.scala:441)",
    "2025-11-25T22:44:36.6220487Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments$(Fuzzing.scala:440)",
    "2025-11-25T22:44:36.6221160Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testExperiments(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:44:36.6221824Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$$init$$1(Fuzzing.scala:451)",
    "2025-11-25T22:44:36.6222377Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:44:36.6222868Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:44:36.6223322Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:44:36.6223828Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:44:36.6224308Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:44:36.6224827Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:44:36.6225344Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:44:36.6225800Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:44:36.6226289Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:36.6226806Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:44:36.6227355Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:44:36.6227842Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:44:36.6236387Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:44:36.6236925Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:44:36.6237432Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:44:36.6237940Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:44:36.6238955Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:44:36.6239411Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:44:36.6239853Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:44:36.6240298Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:44:36.6240861Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:36.6241232Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:44:36.6241626Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:44:36.6241994Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:44:36.6242395Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:44:36.6242816Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:44:36.6243221Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:36.6243592Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:44:36.6243925Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:44:36.6244348Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:36.6244917Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:44:36.6245310Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:44:36.6245688Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:44:36.6246101Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:44:36.6246565Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:44:36.6247049Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:44:36.6247449Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:44:36.6247837Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:44:36.6248364Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:44:36.6248817Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:44:36.6249266Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:44:36.6249668Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:44:36.6250042Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:44:36.6250469Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:36.6250914Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:36.6251297Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:36.6251968Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2137.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2137.0 (TID 2627) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:36.6253063Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:36.6253530Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:36.6253930Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:36.6254378Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:36.6254823Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:36.6255299Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:36.6255778Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:36.6256203Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:36.6256751Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:36.6257146Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:36.6257497Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:36.6257895Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6258386Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6258758Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6259152Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6259547Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6259908Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6260302Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6260776Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6261161Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6261527Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:36.6261928Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:36.6262322Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:36.6262715Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:36.6263148Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:36.6263601Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:36.6264008Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:36.6264417Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:36.6264863Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:36.6265312Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:36.6265715Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:36.6265872Z ",
    "2025-11-25T22:44:36.6266102Z Driver stacktrace:",
    "2025-11-25T22:44:36.6266468Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:36.6266850Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:36.6267257Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:36.6267714Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:36.6268208Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:36.6268627Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:36.6269080Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:36.6269564Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:36.6269986Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:36.6270368Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:36.6270838Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:44:36.6271297Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:44:36.6271752Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:44:36.6272184Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:44:36.6272585Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:44:36.6272976Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:44:36.6273451Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:44:36.6273824Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:44:36.6274248Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:36.6274674Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:36.6275056Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:36.6275419Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:44:36.6275815Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:44:36.6276251Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:36.6276692Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:36.6277147Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:36.6277549Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:44:36.6277982Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:44:36.6278483Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:44:36.6278913Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:36.6279351Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:36.6279730Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:36.6280122Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:44:36.6280544Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:44:36.6281028Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:44:36.6281533Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:44:36.6282022Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:44:36.6282528Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:44:36.6283049Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:44:36.6283625Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:44:36.6284106Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:44:36.6284496Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:44:36.6284902Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:44:36.6285304Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:44:36.6285720Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:44:36.6286159Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:44:36.6286587Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:44:36.6287034Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:44:36.6287453Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:44:36.6287819Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:44:36.6288357Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:44:36.6288833Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:36.6289381Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:44:36.6289782Z \t... 61 more",
    "2025-11-25T22:44:36.6290146Z Caused by: scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:36.6295455Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:36.6295923Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:36.6296332Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:36.6296788Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:36.6297238Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:36.6297915Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:36.6298541Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:36.6320445Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:36.6321081Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:36.6321492Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:36.6321841Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:36.6322237Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6322639Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6323003Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6323399Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6323795Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6324160Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6324551Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6324945Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6325324Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6325692Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:36.6326086Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:36.6326476Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:36.6326867Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:36.6327299Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:36.6327753Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:36.6328287Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:36.6328693Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:36.6329063Z \t... 3 more",
    "2025-11-25T22:44:36.6329324Z [info] - Experiment Fuzzing *** FAILED ***",
    "2025-11-25T22:44:36.6329662Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:44:36.6330056Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:44:36.6330485Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:44:36.6331002Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:36.6331894Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:36.6332653Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:36.6333139Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:36.6333667Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:44:36.6334163Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:44:36.6334679Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:36.6335208Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:44:36.6335569Z [info]   ...",
    "2025-11-25T22:44:36.6335939Z 25/11/25 22:44:36 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:36.6336680Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2137.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2137.0 (TID 2627) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:36.6339774Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:36.6340265Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:36.6340683Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:36.6341155Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:36.6341623Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:36.6342209Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:36.6342892Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:36.6343330Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:36.6343787Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:36.6344201Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:36.6344565Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:36.6345082Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6345466Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6345833Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6346399Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6346810Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6347203Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6347698Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:36.6348080Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:36.6348553Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:36.6348970Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:36.6349392Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:36.6349812Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:36.6350235Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:36.6350701Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:36.6351468Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:36.6351934Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:36.6352393Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:36.6352863Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:36.6353367Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:36.6353800Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:36.6354214Z [info] ",
    "2025-11-25T22:44:36.6354487Z [info] Driver stacktrace:",
    "2025-11-25T22:44:36.6355163Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:36.6355607Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:36.6356070Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:36.6356598Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:36.6357074Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:36.6357532Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:36.6358033Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:36.6399210Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:36.6399723Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:36.6400188Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:36.6400591Z [info]   ...",
    "2025-11-25T22:44:36.6400997Z [info]   Cause: scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(9.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:36.6401567Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:36.6402053Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:36.6402473Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:36.6402977Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:36.6403476Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:36.6404006Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:36.6404588Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:36.6405160Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:36.6405630Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:36.6406053Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:36.6406369Z [info]   ...",
    "2025-11-25T22:44:36.6406663Z [info] + Test Experiment Fuzzing took 3.853s ",
    "2025-11-25T22:44:36.8772216Z 25/11/25 22:44:36 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:36.8879467Z 25/11/25 22:44:36 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:40.2829926Z 25/11/25 22:44:40 WARN BlockManager: Putting block rdd_4183_0 failed due to exception scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:40.2840278Z 25/11/25 22:44:40 WARN BlockManager: Block rdd_4183_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:40.2857608Z 25/11/25 22:44:40 ERROR Executor: Exception in task 0.0 in stage 2291.0 (TID 2882)",
    "2025-11-25T22:44:40.2858663Z scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:40.2859487Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:40.2860126Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:40.2861178Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:40.2861956Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:40.2862710Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:40.2863196Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:40.2863693Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:40.2864125Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:40.2864583Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:40.2864983Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:40.2865334Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:40.2865727Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.2866131Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.2866495Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.2866893Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.2867290Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.2867673Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.2868052Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.2868582Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.2868967Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.2869338Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:40.2869735Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:40.2870133Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:40.2870524Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:40.2870963Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:40.2871418Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:40.2871843Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:40.2872248Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:40.2872754Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:40.2873202Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:40.2873602Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:40.2895332Z 25/11/25 22:44:40 WARN TaskSetManager: Lost task 0.0 in stage 2291.0 (TID 2882) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:40.2903673Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:40.2918759Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:40.2919457Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:40.2919992Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:40.2920543Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:40.2921138Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:40.2921698Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:40.2922197Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:40.2922710Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:40.2923408Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:40.2923844Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:40.2924301Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.2924795Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.2925235Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.2925701Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.2926174Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.2926614Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.2927079Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.2927549Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.2927992Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.2928608Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:40.2929092Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:40.2929546Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:40.2930030Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:40.2930538Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:40.2931066Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:40.2931568Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:40.2932039Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:40.2932547Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:40.2948686Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:40.2949404Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:40.2949595Z ",
    "2025-11-25T22:44:40.2949906Z 25/11/25 22:44:40 ERROR TaskSetManager: Task 0 in stage 2291.0 failed 1 times; aborting job",
    "2025-11-25T22:44:40.2950626Z 25/11/25 22:44:40 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_6163de7eb418\"}",
    "2025-11-25T22:44:40.2951299Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:44:40.2951700Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:44:40.2952121Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:44:40.2952619Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:40.2953352Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:40.2953827Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:40.2954314Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:40.2954823Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:44:40.2955298Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:44:40.2955799Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:40.2956376Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:44:40.2956853Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:44:40.2957351Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:40.2957894Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:44:40.2958575Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testObjects(RankingTrainValidationSpec.scala:47)",
    "2025-11-25T22:44:40.2959100Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.getterSetterTestObject(Fuzzing.scala:618)",
    "2025-11-25T22:44:40.2959593Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.Fuzzing.getterSetterTestObject$(Fuzzing.scala:618)",
    "2025-11-25T22:44:40.2960201Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.getterSetterTestObject(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:44:40.2960784Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.GetterSetterFuzzing.testGettersAndSetters(Fuzzing.scala:561)",
    "2025-11-25T22:44:40.2961296Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.GetterSetterFuzzing.testGettersAndSetters$(Fuzzing.scala:560)",
    "2025-11-25T22:44:40.2961859Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec.testGettersAndSetters(RankingTrainValidationSpec.scala:44)",
    "2025-11-25T22:44:40.2962406Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.GetterSetterFuzzing.$anonfun$$init$$4(Fuzzing.scala:599)",
    "2025-11-25T22:44:40.2962857Z \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
    "2025-11-25T22:44:40.2963250Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:44:40.2963634Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:44:40.2963996Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:44:40.2964371Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:44:40.2964727Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:44:40.2965134Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:44:40.2965530Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:44:40.2965893Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:44:40.2966294Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:40.2966719Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:44:40.2967164Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:44:40.2967581Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:44:40.2967970Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:44:40.2988898Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:44:40.2989655Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:44:40.2990181Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:44:40.2990654Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:44:40.2991103Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:44:40.2991543Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:44:40.2991983Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:44:40.2992366Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:40.2992835Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:44:40.2993219Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:44:40.2993585Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:44:40.2993991Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:44:40.2994410Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:44:40.2994813Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:40.2995186Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:44:40.2995519Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:44:40.2995941Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:44:40.2996430Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:44:40.2996830Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:44:40.2997220Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:44:40.2997622Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:44:40.2998207Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:44:40.2998708Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:44:40.2999109Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:44:40.2999500Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:44:40.2999920Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:44:40.3000363Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:44:40.3000819Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:44:40.3001204Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:44:40.3001574Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:44:40.3002002Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:40.3002446Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:40.3002845Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:40.3003505Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2291.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2291.0 (TID 2882) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:40.3004281Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:40.3004807Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:40.3005204Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:40.3005659Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:40.3006105Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:40.3006581Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:40.3007057Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:40.3007479Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:40.3007925Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:40.3029126Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:40.3029614Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:40.3030098Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3030583Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3031026Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3031501Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3031974Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3032428Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3032881Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3033355Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3033839Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3034288Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:40.3034768Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:40.3035231Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:40.3035694Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:40.3036204Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:40.3036732Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:40.3037841Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:40.3038477Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:40.3039030Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:40.3039557Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:40.3040032Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:40.3040323Z ",
    "2025-11-25T22:44:40.3040642Z Driver stacktrace:",
    "2025-11-25T22:44:40.3041070Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:40.3041528Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:40.3042004Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:40.3058641Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:40.3059350Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:40.3059861Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:40.3060387Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:40.3060974Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:40.3061726Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:40.3062192Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:40.3062738Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:44:40.3063271Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:44:40.3065714Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:44:40.3066404Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:44:40.3066886Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:44:40.3067373Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:44:40.3068016Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:44:40.3068678Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:44:40.3069180Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:40.3069687Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:40.3070158Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:40.3070599Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:44:40.3071071Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:44:40.3071598Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:40.3072100Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:40.3072559Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:40.3073034Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:44:40.3073550Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:44:40.3074056Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:44:40.3074597Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:44:40.3075101Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:44:40.3075575Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:44:40.3076036Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:44:40.3098558Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:44:40.3099574Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:44:40.3100191Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:44:40.3100779Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:44:40.3101369Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:44:40.3101976Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:44:40.3118688Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:44:40.3119318Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:44:40.3119720Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:44:40.3120128Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:44:40.3120531Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:44:40.3120972Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:44:40.3121594Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:44:40.3122025Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:44:40.3122481Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:44:40.3122902Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:44:40.3123275Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:44:40.3123749Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:44:40.3124240Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:40.3124714Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:44:40.3125204Z \t... 62 more",
    "2025-11-25T22:44:40.3125574Z Caused by: scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:40.3126075Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:40.3126539Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:40.3126940Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:40.3127395Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:40.3127841Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:40.3128436Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:40.3128933Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:40.3129366Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:40.3129802Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:40.3130219Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:40.3130573Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:40.3130971Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3131372Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3131737Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3132137Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3132535Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3132909Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3133303Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3133698Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3134075Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3134461Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:40.3134864Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:40.3135257Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:40.3135649Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:40.3136082Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:40.3136534Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:40.3136946Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:40.3137341Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:40.3137744Z \t... 3 more",
    "2025-11-25T22:44:40.3178431Z Alert Provided - Suite RankingTrainValidationSplitModelSpec took 14.156s",
    "2025-11-25T22:44:40.3179313Z [info] - Getters and Setters work as anticipated *** FAILED ***",
    "2025-11-25T22:44:40.3179758Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:44:40.3180270Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:44:40.3180784Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:44:40.3181359Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:40.3182075Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:40.3182848Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:44:40.3183431Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:44:40.3184031Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:44:40.3184586Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:44:40.3185194Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:44:40.3185790Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:44:40.3186293Z [info]   ...",
    "2025-11-25T22:44:40.3189039Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2291.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2291.0 (TID 2882) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:40.3208916Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:40.3209554Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:40.3209986Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:40.3210455Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:40.3210915Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:40.3211419Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:40.3211903Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:40.3212338Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:40.3212798Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:40.3213212Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:40.3213576Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:40.3213980Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3214390Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3214779Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3215170Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3215581Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3216161Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3216555Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:40.3216962Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:40.3217351Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:40.3217732Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:40.3238492Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:40.3239169Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:40.3239592Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:40.3240059Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:40.3240742Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:40.3241173Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:40.3241595Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:40.3242035Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:40.3242506Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:40.3242903Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:40.3243177Z [info] ",
    "2025-11-25T22:44:40.3243426Z [info] Driver stacktrace:",
    "2025-11-25T22:44:40.3243787Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:40.3244188Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:40.3244609Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:40.3245086Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:40.3245531Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:40.3245937Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:40.3246397Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:40.3246906Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:40.3247327Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:40.3247724Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:40.3248074Z [info]   ...",
    "2025-11-25T22:44:40.3248570Z [info]   Cause: scala.MatchError: [ArraySeq(8, 9, 7),ArraySeq(2.0, 4.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:40.3249103Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:40.3249560Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:40.3249977Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:40.3250449Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:40.3250911Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:40.3251422Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:40.3251897Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:40.3252334Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:40.3252897Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:40.3253309Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:40.3253618Z [info]   ...",
    "2025-11-25T22:44:40.3253914Z [info] + Test Getters and Setters work as anticipated took 3.676s ",
    "2025-11-25T22:44:40.3394033Z 25/11/25 22:44:40 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:44:40.3556024Z [info] SARSpec:",
    "2025-11-25T22:44:52.5258063Z [info] - Serialization Fuzzing",
    "2025-11-25T22:44:52.5259323Z [info] + Test Serialization Fuzzing took 12.203s ",
    "2025-11-25T22:44:53.2207821Z [info] - Experiment Fuzzing",
    "2025-11-25T22:44:53.2218881Z [info] + Test Experiment Fuzzing took 0.696s ",
    "2025-11-25T22:44:53.2246430Z Testing parameter activityTimeFormat",
    "2025-11-25T22:44:53.2262024Z Testing parameter alpha",
    "2025-11-25T22:44:53.2264314Z Testing parameter blockSize",
    "2025-11-25T22:44:53.2264992Z Testing parameter checkpointInterval",
    "2025-11-25T22:44:53.2265744Z Testing parameter coldStartStrategy",
    "2025-11-25T22:44:53.2268930Z Testing parameter finalStorageLevel",
    "2025-11-25T22:44:53.2269399Z Testing parameter implicitPrefs",
    "2025-11-25T22:44:53.2269666Z Testing parameter intermediateStorageLevel",
    "2025-11-25T22:44:53.2271241Z Testing parameter itemCol",
    "2025-11-25T22:44:53.2271677Z Testing parameter maxIter",
    "2025-11-25T22:44:53.2271921Z Testing parameter nonnegative",
    "2025-11-25T22:44:53.2272171Z Testing parameter numItemBlocks",
    "2025-11-25T22:44:53.2272425Z Testing parameter numUserBlocks",
    "2025-11-25T22:44:53.2272823Z Testing parameter predictionCol",
    "2025-11-25T22:44:53.2273104Z Testing parameter rank",
    "2025-11-25T22:44:53.2273426Z Testing parameter ratingCol",
    "2025-11-25T22:44:53.2273668Z Testing parameter regParam",
    "2025-11-25T22:44:53.2273898Z Testing parameter seed",
    "2025-11-25T22:44:53.2274340Z Testing parameter similarityFunction",
    "2025-11-25T22:44:53.2274625Z Testing parameter startTime",
    "2025-11-25T22:44:53.2416079Z Could not test parameter startTime",
    "2025-11-25T22:44:53.2419588Z Testing parameter startTimeFormat",
    "2025-11-25T22:44:53.2444468Z Testing parameter supportThreshold",
    "2025-11-25T22:44:53.2446367Z Testing parameter timeCol",
    "2025-11-25T22:44:53.2446782Z Testing parameter timeDecayCoeff",
    "2025-11-25T22:44:53.2462317Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:44:53.2484667Z [info] + Test Getters and Setters work as anticipated took 0.024s ",
    "2025-11-25T22:44:53.2486355Z Testing parameter userCol",
    "2025-11-25T22:44:55.9086462Z 25/11/25 22:44:55 WARN BlockManager: Putting block rdd_4858_0 failed due to exception scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:44:55.9090553Z 25/11/25 22:44:55 WARN BlockManager: Block rdd_4858_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:44:55.9118922Z 25/11/25 22:44:55 ERROR Executor: Exception in task 0.0 in stage 2697.0 (TID 4270)",
    "2025-11-25T22:44:55.9119886Z scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:55.9120709Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:55.9121238Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:55.9124898Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:55.9125582Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:55.9126146Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:55.9126730Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:55.9127324Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:55.9128401Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:55.9128979Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:55.9129465Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:55.9129919Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:55.9130388Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9130881Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9131351Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9135057Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9141047Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9141781Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9142221Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9142634Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9142999Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9143384Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:55.9143787Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:55.9144167Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:55.9144575Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:55.9145011Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:55.9145506Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:55.9145918Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:55.9146312Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:55.9146753Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:55.9147198Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:55.9147587Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:55.9148303Z 25/11/25 22:44:55 WARN TaskSetManager: Lost task 0.0 in stage 2697.0 (TID 4270) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:55.9149005Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:55.9149477Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:55.9149936Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:55.9150430Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:55.9150875Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:55.9151359Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:55.9151837Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:55.9152260Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:55.9152695Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:55.9153106Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:55.9153456Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:55.9153848Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9154379Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9154742Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9155131Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9155529Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9155891Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9156280Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9156675Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9157036Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9157411Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:55.9157883Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:55.9158367Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:55.9158764Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:55.9159196Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:55.9159647Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:55.9160112Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:55.9160552Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:55.9161016Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:55.9161467Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:55.9161866Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:55.9162031Z ",
    "2025-11-25T22:44:55.9162333Z 25/11/25 22:44:55 ERROR TaskSetManager: Task 0 in stage 2697.0 failed 1 times; aborting job",
    "2025-11-25T22:44:55.9191418Z [info] - SAR *** FAILED ***",
    "2025-11-25T22:44:55.9603218Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2697.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2697.0 (TID 4270) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:55.9605068Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:55.9605836Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:55.9606431Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:55.9607074Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:55.9607693Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:55.9608490Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:55.9609200Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:55.9609938Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:55.9610554Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:55.9611121Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:55.9611641Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:44:55.9612254Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9612863Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9613762Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9614332Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9614961Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9615747Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9616323Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:44:55.9616945Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:44:55.9617747Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:44:55.9618397Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:44:55.9618975Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:44:55.9619759Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:44:55.9620372Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:44:55.9621015Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:44:55.9621681Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:44:55.9622675Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:44:55.9623464Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:44:55.9624129Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:44:55.9624814Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:44:55.9640644Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:44:55.9641824Z [info] ",
    "2025-11-25T22:44:55.9642674Z [info] Driver stacktrace:",
    "2025-11-25T22:44:55.9643429Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:55.9643856Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:44:55.9644297Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:44:55.9644767Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:55.9645206Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:44:55.9645633Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:44:55.9646094Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:55.9646611Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:55.9647046Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:44:55.9647458Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:44:55.9647819Z [info]   ...",
    "2025-11-25T22:44:55.9648415Z [info]   Cause: scala.MatchError: [ArraySeq(0, 1, 2, 3, 4),ArraySeq(4.0, 8.0, 3.0, 2.0, 9.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:44:55.9649029Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:44:55.9649494Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:44:55.9649914Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:44:55.9650386Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:44:55.9686897Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:44:55.9687964Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:44:55.9689689Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:44:55.9690280Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:44:55.9690771Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:44:55.9691193Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:44:55.9691508Z [info]   ...",
    "2025-11-25T22:44:55.9691754Z [info] + Test SAR took 2.671s ",
    "2025-11-25T22:44:58.1142553Z 25/11/25 22:44:58 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.",
    "2025-11-25T22:44:58.1862750Z 25/11/25 22:44:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:44:58.1864810Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:44:58.1867367Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:44:58.1868942Z Expected: _c0 but found: ",
    "2025-11-25T22:44:58.1869362Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_count1.csv.gz",
    "2025-11-25T22:44:58.8158537Z [info] - tlc test sim count1",
    "2025-11-25T22:44:58.8199661Z [info] + Test tlc test sim count1 took 2.897s ",
    "2025-11-25T22:44:59.9206018Z 25/11/25 22:44:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:44:59.9208721Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:44:59.9212073Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:44:59.9213971Z Expected: _c0 but found: ",
    "2025-11-25T22:44:59.9214603Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_lift1.csv.gz",
    "2025-11-25T22:45:00.4193042Z [info] - tlc test sim lift1",
    "2025-11-25T22:45:00.4220396Z [info] + Test tlc test sim lift1 took 1.602s ",
    "2025-11-25T22:45:01.3176782Z 25/11/25 22:45:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:01.3179025Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:01.3181621Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:01.3183443Z Expected: _c0 but found: ",
    "2025-11-25T22:45:01.3183873Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_jac1.csv.gz",
    "2025-11-25T22:45:01.8090894Z [info] - tlc test sim jac1",
    "2025-11-25T22:45:01.8097144Z [info] + Test tlc test sim jac1 took 1.39s ",
    "2025-11-25T22:45:02.7709007Z 25/11/25 22:45:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:02.7713306Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:02.7740887Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:02.7743663Z Expected: _c0 but found: ",
    "2025-11-25T22:45:02.7744369Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_count3.csv.gz",
    "2025-11-25T22:45:03.2733941Z [info] - tlc test sim count3",
    "2025-11-25T22:45:03.2735630Z [info] + Test tlc test sim count3 took 1.458s ",
    "2025-11-25T22:45:04.2639340Z 25/11/25 22:45:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:04.2644661Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:04.2648021Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:04.2650205Z Expected: _c0 but found: ",
    "2025-11-25T22:45:04.2651209Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_lift3.csv.gz",
    "2025-11-25T22:45:04.7594724Z [info] - tlc test sim lift3",
    "2025-11-25T22:45:04.7602245Z [info] + Test tlc test sim lift3 took 1.492s ",
    "2025-11-25T22:45:05.6411300Z 25/11/25 22:45:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:05.6416323Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:05.6434156Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:05.6436011Z Expected: _c0 but found: ",
    "2025-11-25T22:45:05.6436378Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_jac3.csv.gz",
    "2025-11-25T22:45:06.1292615Z [info] - tlc test sim jac3",
    "2025-11-25T22:45:06.1301097Z [info] + Test tlc test sim jac3 took 1.37s ",
    "2025-11-25T22:45:06.9535825Z 25/11/25 22:45:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:06.9540998Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:06.9544572Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:06.9547920Z Expected: _c0 but found: ",
    "2025-11-25T22:45:06.9548382Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_count3.csv.gz",
    "2025-11-25T22:45:11.7929541Z [info] - tlc test userpred count3 userid only",
    "2025-11-25T22:45:11.7930913Z [info] + Test tlc test userpred count3 userid only took 5.661s ",
    "2025-11-25T22:45:13.2279920Z 25/11/25 22:45:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:13.2281987Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:13.2284883Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:13.2286520Z Expected: _c0 but found: ",
    "2025-11-25T22:45:13.2287346Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_lift3.csv.gz",
    "2025-11-25T22:45:17.0923056Z [info] - tlc test userpred lift3 userid only",
    "2025-11-25T22:45:17.0953631Z [info] + Test tlc test userpred lift3 userid only took 5.301s ",
    "2025-11-25T22:45:18.4628069Z 25/11/25 22:45:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.",
    "2025-11-25T22:45:18.4630327Z  Header: , DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:18.4632725Z  Schema: _c0, DAF-00255, DAF-00280, DAF-00281, DAF-00283, DAF-00284, DAF-00288, DAF-00349, DAF-00350, DAF-00351, DAF-00367, DAF-00375, DAF-00385, DAF-00396, DAF-00399, DAF-00416, DAF-00419, DAF-00420, DAF-00437, DAF-00442, DAF-00443, DAF-00444, DAF-00448, DAF-00449, DAF-00450, DAF-00451, DAF-00460, DAF-00462, DAF-00464, DAF-00465, DAF-00482, DAF-00488, DAF-00491, DAF-00498, DAF-00499, DAF-00502, DAF-00503, DAF-00504, DAF-00512, DAF-00516, DAF-00517, DAF-00518, DC2-00001, DCF-00085, DCF-00086, DCF-00087, DCF-00104, DCF-00173, DCF-00197, DCF-00198, DCF-00199, DCF-00203, DCF-00204, DCF-00205, DCF-00206, DCF-00252, DCF-00253, DCF-00254, DDF-00078, DDF-00122, DHF-00533, DHF-00826, DHF-00847, DHF-00881, DHF-00890, DHF-00894, DHF-00904, DHF-00905, DHF-00907, DHF-00927, DHF-01029, DHF-01030, DHF-01031, DHF-01037, DHF-01038, DHF-01055, DHF-01056, DHF-01080, DHF-01159, DHF-01242, DHF-01331, DHF-01332, DHF-01333, DHF-01334, DHF-01406, DHF-01436, DHF-01437, DHF-01438, DHF-01439, DHF-01440, DHF-01441, DHF-01444, DHF-01512, DHF-01528, DHF-01529, DHF-01530, DHF-01540, DHF-01550, DQF-00248, DQF-00358, DQF-00362, DR5-00001",
    "2025-11-25T22:45:18.4634398Z Expected: _c0 but found: ",
    "2025-11-25T22:45:18.4634794Z CSV file: file:///home/vsts/work/1/s/core/target/scala-2.13/test-classes/sim_jac3.csv.gz",
    "2025-11-25T22:45:22.3052728Z [info] - tlc test userpred jac3 userid only",
    "2025-11-25T22:45:22.3074229Z [info] + Test tlc test userpred jac3 userid only took 5.213s ",
    "2025-11-25T22:45:22.3092001Z Alert Provided - Suite SARSpec took 41.978s",
    "2025-11-25T22:45:22.3307189Z [info] RecommendationIndexerSpec:",
    "2025-11-25T22:45:22.3351343Z 25/11/25 22:45:22 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:28.4399935Z [info] - Serialization Fuzzing",
    "2025-11-25T22:45:28.4401433Z [info] + Test Serialization Fuzzing took 6.124s ",
    "2025-11-25T22:45:28.7925453Z [info] - Experiment Fuzzing",
    "2025-11-25T22:45:28.7926784Z [info] + Test Experiment Fuzzing took 0.353s ",
    "2025-11-25T22:45:28.7946982Z Testing parameter itemInputCol",
    "2025-11-25T22:45:28.7947934Z Testing parameter itemOutputCol",
    "2025-11-25T22:45:28.7948615Z Testing parameter ratingCol",
    "2025-11-25T22:45:28.7950352Z Testing parameter userInputCol",
    "2025-11-25T22:45:28.7950829Z Testing parameter userOutputCol",
    "2025-11-25T22:45:28.7952731Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:45:28.7976878Z [info] + Test Getters and Setters work as anticipated took 0.003s ",
    "2025-11-25T22:45:30.7467195Z 25/11/25 22:45:30 WARN BlockManager: Putting block rdd_6458_0 failed due to exception scala.MatchError: [ArraySeq(7, 5, 0, 9, 8),ArraySeq(5.0, 7.0, 0.0, 2.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:45:30.7474033Z 25/11/25 22:45:30 WARN BlockManager: Block rdd_6458_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:45:30.7480967Z 25/11/25 22:45:30 ERROR Executor: Exception in task 0.0 in stage 3404.0 (TID 5165)",
    "2025-11-25T22:45:30.7493654Z scala.MatchError: [ArraySeq(7, 5, 0, 9, 8),ArraySeq(5.0, 7.0, 0.0, 2.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:30.7501918Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:30.7507203Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:30.7509116Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:30.7509959Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:30.7510512Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:30.7511066Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:30.7511624Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:30.7512125Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:30.7512647Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:30.7513125Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:30.7513551Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:30.7514026Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:30.7514507Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:30.7525472Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:30.7526118Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:30.7535793Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:30.7536526Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:30.7536992Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:30.7546161Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:30.7549667Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:30.7550514Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:30.7561311Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:30.7562555Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:30.7571281Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:30.7571835Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:30.7572286Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:30.7572734Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:30.7573140Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:30.7573805Z 25/11/25 22:45:30 WARN TaskSetManager: Lost task 0.0 in stage 3404.0 (TID 5165) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 5, 0, 9, 8),ArraySeq(5.0, 7.0, 0.0, 2.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:30.7574501Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:30.7574957Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:30.7575384Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:30.7575821Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:30.7576268Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:30.7576759Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:30.7577217Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:30.7577654Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:30.7578213Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:30.7578621Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:30.7578984Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:30.7579369Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:30.7579763Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:30.7580143Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:30.7580521Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:30.7580930Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:30.7581293Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:30.7581658Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:30.7582069Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:30.7582445Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:30.7582837Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:30.7583495Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:30.7583931Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:30.7584341Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:30.7584744Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:30.7585165Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:30.7585622Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:30.7586004Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:30.7586191Z ",
    "2025-11-25T22:45:30.7586491Z 25/11/25 22:45:30 ERROR TaskSetManager: Task 0 in stage 3404.0 failed 1 times; aborting job",
    "2025-11-25T22:45:30.7586904Z [info] - ALS *** FAILED ***",
    "2025-11-25T22:45:30.7587553Z [info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3404.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3404.0 (TID 5165) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 5, 0, 9, 8),ArraySeq(5.0, 7.0, 0.0, 2.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:30.7588403Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:30.7589007Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:30.7589392Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:30.7589811Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:30.7590256Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:30.7590789Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:30.7591192Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:30.7591544Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:30.7591908Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:30.7592261Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:30.7592558Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:30.7592892Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:30.7593227Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:30.7593532Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:30.7593865Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:30.7594200Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:30.7594502Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:30.7594824Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:30.7595162Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:30.7595479Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:30.7595821Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:30.7596183Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:30.7596560Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:30.7596906Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:30.7597314Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:30.7597681Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:30.7598055Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:30.7598466Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:30.7598704Z [info] ",
    "2025-11-25T22:45:30.7598897Z [info] Driver stacktrace:",
    "2025-11-25T22:45:30.7599208Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:30.7599530Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:30.7599854Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:30.7600322Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:30.7600671Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:30.7601003Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:30.7601420Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:30.7601822Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:30.7602179Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:30.7602505Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:30.7602779Z [info]   ...",
    "2025-11-25T22:45:30.7603104Z [info]   Cause: scala.MatchError: [ArraySeq(7, 5, 0, 9, 8),ArraySeq(5.0, 7.0, 0.0, 2.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:30.7603734Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:30.7604176Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:30.7604557Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:30.7604975Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:30.7605456Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:30.7605907Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:30.7606361Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:30.7606710Z Info Provided - Suite RecommendationIndexerSpec took 8.437s",
    "2025-11-25T22:45:30.7607061Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:30.7607494Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:30.7607876Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:30.7608339Z [info]   ...",
    "2025-11-25T22:45:30.7608538Z [info] + Test ALS took 1.957s ",
    "2025-11-25T22:45:30.7669607Z [info] RankingTrainValidationSplitSpec:",
    "2025-11-25T22:45:30.7748375Z 25/11/25 22:45:30 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:31.5432390Z 25/11/25 22:45:31 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:35.9521210Z 25/11/25 22:45:35 WARN BlockManager: Putting block rdd_6833_0 failed due to exception scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:45:35.9525583Z 25/11/25 22:45:35 WARN BlockManager: Block rdd_6833_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:45:35.9534297Z 25/11/25 22:45:35 ERROR Executor: Exception in task 0.0 in stage 3595.0 (TID 5572)",
    "2025-11-25T22:45:35.9535005Z scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:35.9535739Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:35.9536323Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:35.9536870Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:35.9537440Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:35.9538038Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:35.9538787Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:35.9539645Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:35.9540192Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:35.9540722Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:35.9541224Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:35.9541675Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:35.9542166Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9542692Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9543155Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9546716Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9571303Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9572134Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9572680Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9573258Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9574054Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9574655Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:35.9575088Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:35.9575477Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:35.9575966Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:35.9576405Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:35.9576861Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:35.9577287Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:35.9577687Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:35.9578241Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:35.9578699Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:35.9579103Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:35.9579683Z 25/11/25 22:45:35 WARN TaskSetManager: Lost task 0.0 in stage 3595.0 (TID 5572) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:35.9580381Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:35.9580832Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:35.9581447Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:35.9581905Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:35.9582353Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:35.9582856Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:35.9583322Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:35.9583743Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:35.9584191Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:35.9584586Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:35.9585042Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:35.9585422Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9585824Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9586201Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9586579Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9586999Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9587378Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9598523Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9599262Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9599699Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9600122Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:35.9600575Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:35.9601015Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:35.9601447Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:35.9601934Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:35.9602404Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:35.9602854Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:35.9603304Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:35.9603766Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:35.9604252Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:35.9604697Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:35.9604892Z ",
    "2025-11-25T22:45:35.9605248Z 25/11/25 22:45:35 ERROR TaskSetManager: Task 0 in stage 3595.0 failed 1 times; aborting job",
    "2025-11-25T22:45:35.9605995Z 25/11/25 22:45:35 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_d2a4d48d8a42\"}",
    "2025-11-25T22:45:35.9606719Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:45:35.9607142Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:45:35.9607607Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:45:35.9608220Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:35.9609026Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:35.9609517Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:35.9609987Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:35.9610508Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:45:35.9610970Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:45:35.9611469Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:35.9611981Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:45:35.9612523Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:45:35.9613038Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:35.9613569Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:45:35.9614100Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:35.9614641Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerializationHelper(Fuzzing.scala:489)",
    "2025-11-25T22:45:35.9615167Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$testSerialization$1(Fuzzing.scala:510)",
    "2025-11-25T22:45:35.9615727Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$testSerialization$1$adapted(Fuzzing.scala:506)",
    "2025-11-25T22:45:35.9616191Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:35.9616631Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization(Fuzzing.scala:506)",
    "2025-11-25T22:45:35.9729177Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.testSerialization$(Fuzzing.scala:504)",
    "2025-11-25T22:45:35.9730438Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.testSerialization(RankingTrainValidationSpec.scala:10)",
    "2025-11-25T22:45:35.9731052Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.SerializationFuzzing.$anonfun$$init$$2(Fuzzing.scala:539)",
    "2025-11-25T22:45:35.9731517Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:45:35.9731909Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:45:35.9732318Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:45:35.9732728Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:45:35.9733131Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:45:35.9733560Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:45:35.9734038Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:45:35.9734467Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:45:35.9734899Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:35.9735372Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:45:35.9735877Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:45:35.9736320Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:45:35.9736750Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:45:35.9737229Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:45:35.9737774Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:45:35.9738743Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:45:35.9739239Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:45:35.9739727Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:45:35.9740229Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:45:35.9740681Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:45:35.9741084Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:35.9741501Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:45:35.9741924Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:45:35.9742465Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:45:35.9742908Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:45:35.9743369Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:45:35.9743832Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:35.9744235Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:45:35.9744608Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:45:35.9745088Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:35.9745602Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:45:35.9746058Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:45:35.9746482Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:45:35.9746930Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:45:35.9747457Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:45:35.9747975Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:45:35.9748508Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:45:35.9748958Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:45:35.9749408Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:45:35.9749907Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:45:35.9750382Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:45:35.9750803Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:45:35.9751229Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:45:35.9751682Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:35.9752167Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:35.9752612Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:35.9753312Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3595.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3595.0 (TID 5572) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:35.9754116Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:35.9754605Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:35.9755057Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:35.9755678Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:35.9756171Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:35.9756696Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:35.9757198Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:35.9757674Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:35.9758217Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:35.9758660Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:35.9759065Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:35.9759573Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9760016Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9760433Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9760846Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9761297Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9761702Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9762118Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9762702Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9763129Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9763552Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:35.9763992Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:35.9764422Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:35.9764854Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:35.9765329Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:35.9765816Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:35.9766264Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:35.9766694Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:35.9767173Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:35.9767661Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:35.9768171Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:35.9768381Z ",
    "2025-11-25T22:45:35.9768658Z Driver stacktrace:",
    "2025-11-25T22:45:35.9769067Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:35.9769496Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:35.9769937Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:35.9770434Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:35.9770890Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:35.9771339Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:35.9771822Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:35.9772359Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:35.9772818Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:35.9773235Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:35.9773846Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:45:35.9774354Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:45:35.9774853Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:45:35.9775333Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:45:35.9879545Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:45:35.9880069Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:45:35.9880512Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:45:35.9880924Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:45:35.9881660Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:35.9882134Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:35.9882568Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:35.9883025Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:45:35.9883457Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:45:35.9883931Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:35.9884412Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:35.9884833Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:35.9885275Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:45:35.9885744Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:45:35.9886212Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:45:35.9886682Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:35.9887144Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:35.9887564Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:35.9888002Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:45:35.9888609Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:45:35.9889148Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:45:35.9889684Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:45:35.9890218Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:45:35.9890768Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:45:35.9891330Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:45:35.9891952Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:45:35.9892467Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:45:35.9892895Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:45:35.9893336Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:45:35.9893774Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:45:35.9894345Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:45:35.9894838Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:45:35.9895433Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:45:35.9927345Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:45:35.9928394Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:45:35.9928801Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:45:35.9929287Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:45:35.9929763Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:35.9930256Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:45:35.9930646Z \t... 62 more",
    "2025-11-25T22:45:35.9931007Z Caused by: scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:35.9931815Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:35.9932263Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:35.9932665Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:35.9933115Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:35.9933564Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:35.9934058Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:35.9934564Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:35.9934985Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:35.9935439Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:35.9935839Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:35.9936204Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:35.9936583Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9936980Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9937357Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9937734Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9938225Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9938614Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9938988Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9939384Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9939760Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9940135Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:35.9940534Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:35.9940926Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:35.9941313Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:35.9941761Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:35.9942197Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:35.9942607Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:35.9943012Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:35.9943349Z \t... 3 more",
    "2025-11-25T22:45:35.9943608Z [info] - Serialization Fuzzing *** FAILED ***",
    "2025-11-25T22:45:35.9944071Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:45:35.9944463Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:45:35.9944890Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:45:35.9945400Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:35.9945986Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:35.9946495Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:35.9946978Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:35.9947591Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:45:35.9948072Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:45:35.9969656Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:35.9970337Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:45:35.9970776Z [info]   ...",
    "2025-11-25T22:45:35.9971476Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3595.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3595.0 (TID 5572) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:35.9972352Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:35.9972923Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:35.9973528Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:35.9974059Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:35.9974620Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:35.9979116Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:35.9979946Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:35.9980479Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:35.9981018Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:35.9981542Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:35.9981985Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:35.9985714Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9986418Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9986888Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9987378Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9987866Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9988513Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9989035Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:35.9989529Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:35.9990216Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:35.9990694Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:35.9991186Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:35.9991654Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:35.9992182Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:35.9992710Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:35.9993252Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:35.9993763Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:35.9994353Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:35.9994890Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:35.9995426Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:35.9995913Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:35.9996264Z [info] ",
    "2025-11-25T22:45:35.9996575Z [info] Driver stacktrace:",
    "2025-11-25T22:45:35.9996974Z 25/11/25 22:45:35 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:35.9997556Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:35.9998037Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:35.9998673Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:35.9999338Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:35.9999869Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:36.0000359Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:36.0000902Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:36.0001495Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:36.0002930Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:36.0003534Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:36.0003963Z [info]   ...",
    "2025-11-25T22:45:36.0004415Z [info]   Cause: scala.MatchError: [ArraySeq(9, 8, 5),ArraySeq(3.0, 0.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:36.0005026Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:36.0005562Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:36.0006049Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:36.0006592Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:36.0007126Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:36.0007700Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:36.0008363Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:36.0008898Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:36.0009436Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:36.0010095Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:36.0010475Z [info]   ...",
    "2025-11-25T22:45:36.0010818Z [info] + Test Serialization Fuzzing took 5.199s ",
    "2025-11-25T22:45:36.1878567Z 25/11/25 22:45:36 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:36.2019749Z 25/11/25 22:45:36 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:39.3266845Z 25/11/25 22:45:39 WARN BlockManager: Putting block rdd_7136_0 failed due to exception scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:45:39.3272191Z 25/11/25 22:45:39 WARN BlockManager: Block rdd_7136_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:45:39.3282299Z 25/11/25 22:45:39 ERROR Executor: Exception in task 0.0 in stage 3749.0 (TID 5827)",
    "2025-11-25T22:45:39.3283367Z scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:39.3283955Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:39.3284650Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:39.3285338Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:39.3285917Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:39.3286497Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:39.3287735Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:39.3288409Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:39.3288895Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:39.3289333Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:39.3289735Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:39.3290099Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:39.3290479Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3290892Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3291260Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3291660Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3292071Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3292437Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3292813Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3293268Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3293674Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3294078Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:39.3294531Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:39.3294946Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:39.3295391Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:39.3295847Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:39.3296284Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:39.3296708Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:39.3297097Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:39.3297548Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:39.3298281Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:39.3298676Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:39.3301390Z 25/11/25 22:45:39 WARN TaskSetManager: Lost task 0.0 in stage 3749.0 (TID 5827) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:39.3305987Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:39.3306625Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:39.3307035Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:39.3307691Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:39.3308317Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:39.3312046Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:39.3312591Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:39.3313133Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:39.3313610Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:39.3314068Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:39.3314461Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:39.3314900Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3315349Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3315757Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3316197Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3316637Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3317041Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3317478Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3317912Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3318452Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3318879Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:39.3319321Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:39.3319764Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:39.3320199Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:39.3320675Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:39.3321170Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:39.3321659Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:39.3322088Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:39.3322568Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:39.3323054Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:39.3323495Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:39.3323687Z ",
    "2025-11-25T22:45:39.3324036Z 25/11/25 22:45:39 ERROR TaskSetManager: Task 0 in stage 3749.0 failed 1 times; aborting job",
    "2025-11-25T22:45:39.3327083Z 25/11/25 22:45:39 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_d2a4d48d8a42\"}",
    "2025-11-25T22:45:39.3332286Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:45:39.3332723Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:45:39.3333184Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:45:39.3333675Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:39.3334264Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:39.3334943Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:39.3335427Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:39.3335957Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:45:39.3336421Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:45:39.3336936Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:39.3337433Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:45:39.3337891Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:45:39.3338545Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:39.3339076Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:45:39.3339618Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:39.3340159Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.runExperiment(Fuzzing.scala:435)",
    "2025-11-25T22:45:39.3340657Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.runExperiment$(Fuzzing.scala:430)",
    "2025-11-25T22:45:39.3341178Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.runExperiment(RankingTrainValidationSpec.scala:10)",
    "2025-11-25T22:45:39.3341717Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$testExperiments$1(Fuzzing.scala:442)",
    "2025-11-25T22:45:39.3342252Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$testExperiments$1$adapted(Fuzzing.scala:441)",
    "2025-11-25T22:45:39.3342704Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:39.3343151Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments(Fuzzing.scala:441)",
    "2025-11-25T22:45:39.3343637Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.testExperiments$(Fuzzing.scala:440)",
    "2025-11-25T22:45:39.3344165Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.testExperiments(RankingTrainValidationSpec.scala:10)",
    "2025-11-25T22:45:39.3344712Z \tat com.microsoft.azure.synapse.ml.core.test.fuzzing.ExperimentFuzzing.$anonfun$$init$$1(Fuzzing.scala:451)",
    "2025-11-25T22:45:39.3345133Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:45:39.3345508Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:45:39.3345869Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:45:39.3346231Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:45:39.3346600Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:45:39.3347112Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:45:39.3347509Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:45:39.3347890Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:45:39.3348352Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:39.3348783Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:45:39.3349254Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:45:39.3349652Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:45:39.3350054Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:45:39.3350546Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:45:39.3351037Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:45:39.3351556Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:45:39.3352000Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:45:39.3352441Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:45:39.3352891Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:45:39.3353313Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:45:39.3353712Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:39.3354084Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:45:39.3354471Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:45:39.3354858Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:45:39.3355251Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:45:39.3355668Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:45:39.3356088Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:39.3356485Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:45:39.3356837Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:45:39.3357262Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:39.3357775Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:45:39.3358327Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:45:39.3358765Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:45:39.3359206Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:45:39.3359733Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:45:39.3378433Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:45:39.3379222Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:45:39.3379629Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:45:39.3380050Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:45:39.3380513Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:45:39.3380954Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:45:39.3381337Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:45:39.3381733Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:45:39.3382339Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:39.3382804Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:39.3383191Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:39.3383849Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3749.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3749.0 (TID 5827) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:39.3384616Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:39.3385138Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:39.3385561Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:39.3386002Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:39.3386449Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:39.3386941Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:39.3387407Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:39.3387847Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:39.3388407Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:39.3388812Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:39.3389183Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:39.3389569Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3389972Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3390355Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3390733Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3391148Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3391511Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3391891Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3392305Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3392672Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3393040Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:39.3393460Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:39.3393853Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:39.3394244Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:39.3394691Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:39.3395121Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:39.3427812Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:39.3448687Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:39.3449276Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:39.3449744Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:39.3450141Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:39.3450315Z ",
    "2025-11-25T22:45:39.3450542Z Driver stacktrace:",
    "2025-11-25T22:45:39.3451089Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:39.3451486Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:39.3451870Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:39.3452329Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:39.3452759Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:39.3453148Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:39.3453609Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:39.3454089Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:39.3454612Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:39.3455009Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:39.3455466Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:45:39.3455925Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:45:39.3456392Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:45:39.3456807Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:45:39.3457218Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:45:39.3457607Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:45:39.3457983Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:45:39.3519049Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:45:39.3519484Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:39.3519898Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:39.3520273Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:39.3520595Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:45:39.3520977Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:45:39.3521382Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:39.3521781Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:39.3522151Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:39.3522508Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:45:39.3522913Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:45:39.3523321Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:45:39.3523709Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:39.3524116Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:39.3524468Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:39.3524822Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:45:39.3525234Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:45:39.3525670Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:45:39.3526136Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:45:39.3526610Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:45:39.3527071Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:45:39.3527788Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:45:39.3548320Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:45:39.3549284Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:45:39.3549778Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:45:39.3562813Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:45:39.3563572Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:45:39.3588732Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:45:39.3589546Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:45:39.3589985Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:45:39.3590396Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:45:39.3590807Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:45:39.3591156Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:45:39.3591581Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:45:39.3592034Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:39.3592474Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:45:39.3592836Z \t... 64 more",
    "2025-11-25T22:45:39.3593194Z Caused by: scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:39.3593665Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:39.3594093Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:39.3594470Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:39.3594876Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:39.3595304Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:39.3595745Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:39.3611773Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:39.3628819Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:39.3629432Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:39.3629841Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:39.3630168Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:39.3630525Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3631088Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3631454Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3631847Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3632243Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3632604Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3632998Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3633399Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3633997Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3634383Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:39.3634780Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:39.3635159Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:39.3635568Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:39.3636001Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:39.3636454Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:39.3636868Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:39.3638079Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:39.3645160Z \t... 3 more",
    "2025-11-25T22:45:39.3650082Z Testing parameter alpha",
    "2025-11-25T22:45:39.3650584Z Testing parameter blockSize",
    "2025-11-25T22:45:39.3650917Z Testing parameter checkpointInterval",
    "2025-11-25T22:45:39.3678881Z [info] - Experiment Fuzzing *** FAILED ***",
    "2025-11-25T22:45:39.3679392Z Testing parameter coldStartStrategy",
    "2025-11-25T22:45:39.3679674Z Testing parameter estimator",
    "2025-11-25T22:45:39.3679945Z Testing parameter estimatorParamMaps",
    "2025-11-25T22:45:39.3680247Z Could not test parameter estimatorParamMaps",
    "2025-11-25T22:45:39.3680521Z Testing parameter evaluator",
    "2025-11-25T22:45:39.3680787Z Testing parameter finalStorageLevel",
    "2025-11-25T22:45:39.3681077Z Testing parameter implicitPrefs",
    "2025-11-25T22:45:39.3681357Z Testing parameter intermediateStorageLevel",
    "2025-11-25T22:45:39.3681630Z Testing parameter itemCol",
    "2025-11-25T22:45:39.3681901Z Testing parameter maxIter",
    "2025-11-25T22:45:39.3682156Z Testing parameter minRatingsI",
    "2025-11-25T22:45:39.3682427Z Testing parameter minRatingsU",
    "2025-11-25T22:45:39.3682703Z Testing parameter nonnegative",
    "2025-11-25T22:45:39.3682963Z Testing parameter numItemBlocks",
    "2025-11-25T22:45:39.3683231Z Testing parameter numUserBlocks",
    "2025-11-25T22:45:39.3683504Z Testing parameter parallelism",
    "2025-11-25T22:45:39.3683764Z Testing parameter predictionCol",
    "2025-11-25T22:45:39.3684021Z Testing parameter rank",
    "2025-11-25T22:45:39.3684288Z Testing parameter ratingCol",
    "2025-11-25T22:45:39.3684541Z Testing parameter regParam",
    "2025-11-25T22:45:39.3684795Z Testing parameter seed",
    "2025-11-25T22:45:39.3685063Z Testing parameter trainRatio",
    "2025-11-25T22:45:39.3685315Z Testing parameter userCol",
    "2025-11-25T22:45:39.3685617Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:45:39.3686045Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:45:39.3686476Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:45:39.3686979Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:39.3687581Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:39.3688073Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:39.3688688Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:39.3689212Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:45:39.3689686Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:45:39.3690214Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:39.3690732Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:45:39.3691296Z [info]   ...",
    "2025-11-25T22:45:39.3691908Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3749.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3749.0 (TID 5827) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:39.3692688Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:39.3693147Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:39.3693561Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:39.3694045Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:39.3694592Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:39.3695101Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:39.3695575Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:39.3696012Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:39.3696475Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:39.3696887Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:39.3697269Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:39.3697662Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3698075Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3739107Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3739549Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3739966Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3740364Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3740757Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:39.3741186Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:39.3741564Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:39.3741941Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:39.3742367Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:39.3742764Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:39.3743170Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:39.3743637Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:39.3744082Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:39.3744520Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:39.3744924Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:39.3745360Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:39.3745833Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:39.3746227Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:39.3746503Z [info] ",
    "2025-11-25T22:45:39.3746849Z [info] Driver stacktrace:",
    "2025-11-25T22:45:39.3747183Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:39.3747742Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:39.3748424Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:39.3748901Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:39.3749385Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:39.3749893Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:39.3750430Z 25/11/25 22:45:39 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:39.3750862Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:39.3751455Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:39.3751893Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:39.3752291Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:39.3752629Z [info]   ...",
    "2025-11-25T22:45:39.3753006Z [info]   Cause: scala.MatchError: [ArraySeq(8, 7, 9),ArraySeq(8.0, 3.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:39.3753517Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:39.3753972Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:39.3754413Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:39.3754863Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:39.3755345Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:39.3755838Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:39.3756313Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:39.3756763Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:39.3757214Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:39.3757641Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:39.3757938Z [info]   ...",
    "2025-11-25T22:45:39.3781175Z [info] + Test Experiment Fuzzing took 3.373s ",
    "2025-11-25T22:45:39.3781916Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:45:39.3782330Z [info] + Test Getters and Setters work as anticipated took 0.004s ",
    "2025-11-25T22:45:39.5845503Z 25/11/25 22:45:39 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:39.5911846Z 25/11/25 22:45:39 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:42.6698024Z 25/11/25 22:45:42 WARN BlockManager: Putting block rdd_7439_0 failed due to exception scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema).",
    "2025-11-25T22:45:42.6699667Z 25/11/25 22:45:42 WARN BlockManager: Block rdd_7439_0 could not be removed as it was not found on disk or in memory",
    "2025-11-25T22:45:42.6705805Z 25/11/25 22:45:42 ERROR Executor: Exception in task 0.0 in stage 3902.0 (TID 6082)",
    "2025-11-25T22:45:42.6706548Z scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:42.6707415Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:42.6708077Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:42.6710024Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:42.6710741Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:42.6711369Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:42.6712035Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:42.6712694Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:42.6713286Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:42.6713915Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:42.6714472Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:42.6715192Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:42.6715740Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6716297Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6716802Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6717342Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6717955Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6718614Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6719141Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6719705Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6720206Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6720712Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:42.6721287Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:42.6722160Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:42.6722856Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:42.6723572Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:42.6724302Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:42.6724982Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:42.6725630Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:42.6726351Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:42.6727079Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:42.6727742Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:42.6728745Z 25/11/25 22:45:42 WARN TaskSetManager: Lost task 0.0 in stage 3902.0 (TID 6082) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:42.6792122Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:42.6792724Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:42.6793179Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:42.6793649Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:42.6794159Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:42.6794700Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:42.6795203Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:42.6795925Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:42.6796402Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:42.6796837Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:42.6797239Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:42.6797664Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6798233Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6798649Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6802642Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6803584Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6804004Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6804431Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6804883Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6805285Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6805696Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:42.6806147Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:42.6806562Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:42.6807008Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:42.6807481Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:42.6807953Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:42.6808551Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:42.6808990Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:42.6809456Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:42.6809956Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:42.6810382Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:42.6810590Z ",
    "2025-11-25T22:45:42.6810935Z 25/11/25 22:45:42 ERROR TaskSetManager: Task 0 in stage 3902.0 failed 1 times; aborting job",
    "2025-11-25T22:45:42.6811681Z 25/11/25 22:45:42 ERROR RankingTrainValidationSplit: {\"protocolVersion\":\"0.0.1\",\"method\":\"fit\",\"libraryName\":\"SynapseML\",\"errorMessage\":\"org.apache.spark.SparkException\",\"errorType\":\"org.apache.spark.SparkException\",\"className\":\"class com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit\",\"libraryVersion\":\"1.1.0-27-0d303b21-SNAPSHOT\",\"modelUid\":\"RankingTrainValidationSplit_72941f23463c\"}",
    "2025-11-25T22:45:42.6812424Z org.apache.spark.SparkException: Exception thrown in awaitResult: ",
    "2025-11-25T22:45:42.6812864Z \tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:45:42.6813320Z \tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:45:42.6813835Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:42.6814459Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:42.6814974Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:42.6815486Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:42.6816048Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:45:42.6816685Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:45:42.6817238Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:42.6817774Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:45:42.6818370Z \tat com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit$(SynapseMLLogging.scala:152)",
    "2025-11-25T22:45:42.6818941Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logFit(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:42.6819510Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.fit(RankingTrainValidationSplit.scala:145)",
    "2025-11-25T22:45:42.6820120Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec.$anonfun$new$1(RankingTrainValidationSpec.scala:23)",
    "2025-11-25T22:45:42.6820750Z \tat org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)",
    "2025-11-25T22:45:42.6821173Z \tat org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)",
    "2025-11-25T22:45:42.6821574Z \tat org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)",
    "2025-11-25T22:45:42.6821972Z \tat org.scalatest.Transformer.apply(Transformer.scala:22)",
    "2025-11-25T22:45:42.6822379Z \tat org.scalatest.Transformer.apply(Transformer.scala:20)",
    "2025-11-25T22:45:42.6822810Z \tat org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)",
    "2025-11-25T22:45:42.6823245Z \tat org.scalatest.TestSuite.withFixture(TestSuite.scala:196)",
    "2025-11-25T22:45:42.6823665Z \tat org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)",
    "2025-11-25T22:45:42.6824089Z \tat org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:42.6824552Z \tat org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)",
    "2025-11-25T22:45:42.6825053Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:45:42.6825527Z \tat org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)",
    "2025-11-25T22:45:42.6825972Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)",
    "2025-11-25T22:45:42.6826426Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)",
    "2025-11-25T22:45:42.6826959Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterEachTestData$$super$runTest(TestBase.scala:150)",
    "2025-11-25T22:45:42.6827520Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest(BeforeAndAfterEachTestData.scala:213)",
    "2025-11-25T22:45:42.6828003Z \tat org.scalatest.BeforeAndAfterEachTestData.runTest$(BeforeAndAfterEachTestData.scala:206)",
    "2025-11-25T22:45:42.6828564Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.runTest(TestBase.scala:150)",
    "2025-11-25T22:45:42.6829064Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:45:42.6829526Z \tat org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)",
    "2025-11-25T22:45:42.6829965Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:42.6830372Z \tat org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)",
    "2025-11-25T22:45:42.6830789Z \tat org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)",
    "2025-11-25T22:45:42.6831216Z \tat org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)",
    "2025-11-25T22:45:42.6831641Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)",
    "2025-11-25T22:45:42.6832099Z \tat org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)",
    "2025-11-25T22:45:42.6832563Z \tat org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:42.6832957Z \tat org.scalatest.Suite.run(Suite.scala:1114)",
    "2025-11-25T22:45:42.6833347Z \tat org.scalatest.Suite.run$(Suite.scala:1096)",
    "2025-11-25T22:45:42.6833814Z \tat org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)",
    "2025-11-25T22:45:42.6834423Z \tat org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:45:42.6834874Z \tat org.scalatest.SuperEngine.runImpl(Engine.scala:535)",
    "2025-11-25T22:45:42.6835292Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)",
    "2025-11-25T22:45:42.6835730Z \tat org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)",
    "2025-11-25T22:45:42.6836250Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.org$scalatest$BeforeAndAfterAll$$super$run(TestBase.scala:150)",
    "2025-11-25T22:45:42.6836764Z \tat org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)",
    "2025-11-25T22:45:42.6837219Z \tat org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)",
    "2025-11-25T22:45:42.6837641Z \tat org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)",
    "2025-11-25T22:45:42.6838230Z \tat com.microsoft.azure.synapse.ml.core.test.base.TestBase.run(TestBase.scala:150)",
    "2025-11-25T22:45:42.6838736Z \tat org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)",
    "2025-11-25T22:45:42.6839213Z \tat org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)",
    "2025-11-25T22:45:42.6839629Z \tat sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)",
    "2025-11-25T22:45:42.6840051Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
    "2025-11-25T22:45:42.6840503Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:42.6841000Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:42.6841429Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:42.6842129Z Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3902.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3902.0 (TID 6082) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:42.6842935Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:42.6843417Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:42.6843870Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:42.6844342Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:42.6844832Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:42.6845355Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:42.6845855Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:42.6846333Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:42.6846807Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:42.6847247Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:42.6847647Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:42.6848067Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6848575Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6848994Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6849408Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6849856Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6909559Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6910719Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6911652Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6912252Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6912766Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:42.6913363Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:42.6914396Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:42.6929148Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:42.6929780Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:42.6930338Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:42.6930736Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:42.6931326Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:42.6932067Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:42.6932491Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:42.6932947Z \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:42.6933094Z ",
    "2025-11-25T22:45:42.6933319Z Driver stacktrace:",
    "2025-11-25T22:45:42.6933646Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:42.6934001Z \tat scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:42.6934693Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:42.6935117Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:42.6935516Z \tat scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:42.6935883Z \tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:42.6936298Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:42.6936759Z \tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:42.6937133Z \tat scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:42.6937484Z \tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:42.6937916Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)",
    "2025-11-25T22:45:42.6938468Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)",
    "2025-11-25T22:45:42.6938917Z \tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)",
    "2025-11-25T22:45:42.6939307Z \tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)",
    "2025-11-25T22:45:42.6939677Z \tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)",
    "2025-11-25T22:45:42.6940066Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)",
    "2025-11-25T22:45:42.6940417Z \tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2579)",
    "2025-11-25T22:45:42.6940761Z \tat org.apache.spark.rdd.RDD.$anonfun$reduce$1(RDD.scala:1148)",
    "2025-11-25T22:45:42.6941162Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:42.6941560Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:42.6941935Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:42.6942255Z \tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1130)",
    "2025-11-25T22:45:42.6942623Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$stats$1(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:45:42.6943045Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:42.6943440Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:42.6943916Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:42.6944289Z \tat org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:44)",
    "2025-11-25T22:45:42.6944712Z \tat org.apache.spark.rdd.DoubleRDDFunctions.$anonfun$mean$1(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:45:42.6945121Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:45:42.6945508Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
    "2025-11-25T22:45:42.6945904Z \tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
    "2025-11-25T22:45:42.6946274Z \tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)",
    "2025-11-25T22:45:42.6946626Z \tat org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:49)",
    "2025-11-25T22:45:42.6947020Z \tat org.apache.spark.mllib.evaluation.RankingMetrics.ndcgAt(RankingMetrics.scala:161)",
    "2025-11-25T22:45:42.6947559Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg$lzycompute(RankingEvaluator.scala:26)",
    "2025-11-25T22:45:42.6948042Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.ndcg(RankingEvaluator.scala:26)",
    "2025-11-25T22:45:42.6948589Z \tat com.microsoft.azure.synapse.ml.recommendation.AdvancedRankingMetrics.matchMetric(RankingEvaluator.scala:78)",
    "2025-11-25T22:45:42.6949268Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.evaluate(RankingEvaluator.scala:147)",
    "2025-11-25T22:45:42.6949794Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.calculateMetrics$1(RankingTrainValidationSplit.scala:122)",
    "2025-11-25T22:45:42.6950361Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$3(RankingTrainValidationSplit.scala:128)",
    "2025-11-25T22:45:42.6950858Z \tat scala.runtime.java8.JFunction0$mcD$sp.apply(JFunction0$mcD$sp.scala:17)",
    "2025-11-25T22:45:42.6951252Z \tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)",
    "2025-11-25T22:45:42.6951657Z \tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)",
    "2025-11-25T22:45:42.6952060Z \tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)",
    "2025-11-25T22:45:42.6952477Z \tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)",
    "2025-11-25T22:45:42.6952922Z \tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)",
    "2025-11-25T22:45:42.6953349Z \tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)",
    "2025-11-25T22:45:42.6953802Z \tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)",
    "2025-11-25T22:45:42.6954224Z \tat scala.concurrent.impl.Promise$DefaultPromise.map(Promise.scala:182)",
    "2025-11-25T22:45:42.6954591Z \tat scala.concurrent.Future$.apply(Future.scala:687)",
    "2025-11-25T22:45:42.6955059Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$2(RankingTrainValidationSplit.scala:129)",
    "2025-11-25T22:45:42.6955535Z \tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:42.6956005Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:125)",
    "2025-11-25T22:45:42.6956406Z \t... 54 more",
    "2025-11-25T22:45:42.6956769Z Caused by: scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:42.6957287Z \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:42.6957727Z \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:42.6958202Z \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:42.6958668Z \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:42.6959135Z \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:42.6959687Z \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:42.6960171Z \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:42.6960592Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:42.6961047Z \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:42.6961444Z \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:42.6961797Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:42.6962193Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6962591Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6962956Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6963419Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6963817Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6964204Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6964582Z \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6964977Z \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6965356Z \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6965726Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:42.6966124Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:42.6966517Z \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:42.6966910Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:42.6967341Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:42.6967787Z \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:42.6968270Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:42.6968681Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:42.6968990Z \t... 3 more",
    "2025-11-25T22:45:42.6969274Z Alert Provided - Suite RankingTrainValidationSplitSpec took 11.912s",
    "2025-11-25T22:45:42.6969581Z [info] - testALS *** FAILED ***",
    "2025-11-25T22:45:42.6969883Z [info]   org.apache.spark.SparkException: Exception thrown in awaitResult:",
    "2025-11-25T22:45:42.6970276Z [info]   at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)",
    "2025-11-25T22:45:42.6970713Z [info]   at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)",
    "2025-11-25T22:45:42.6971204Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:42.6971806Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$4$adapted(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:42.6972299Z [info]   at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:936)",
    "2025-11-25T22:45:42.6972776Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.$anonfun$fit$1(RankingTrainValidationSplit.scala:132)",
    "2025-11-25T22:45:42.6973313Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb(SynapseMLLogging.scala:163)",
    "2025-11-25T22:45:42.6973803Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logVerb$(SynapseMLLogging.scala:160)",
    "2025-11-25T22:45:42.6974329Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplit.logVerb(RankingTrainValidationSplit.scala:25)",
    "2025-11-25T22:45:42.6974837Z [info]   at com.microsoft.azure.synapse.ml.logging.SynapseMLLogging.logFit(SynapseMLLogging.scala:153)",
    "2025-11-25T22:45:42.6975180Z [info]   ...",
    "2025-11-25T22:45:42.6975879Z [info]   Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3902.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3902.0 (TID 6082) (runnervmr8kkp.iwupiss0sklupkzur0jfr53ugb.dx.internal.cloudapp.net executor driver): scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:42.6976663Z [info] \tat com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:42.6977115Z [info] \tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:42.6977528Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:42.6977995Z [info] \tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:42.6978614Z [info] \tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:42.6979104Z [info] \tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:42.6979590Z [info] \tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:42.6980021Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:42.6980483Z [info] \tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:42.6980895Z [info] \tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:42.6981256Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:336)",
    "2025-11-25T22:45:42.6981660Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6982072Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6982465Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6982869Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6983282Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6983673Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6984062Z [info] \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
    "2025-11-25T22:45:42.6984470Z [info] \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)",
    "2025-11-25T22:45:42.6984859Z [info] \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)",
    "2025-11-25T22:45:42.6985240Z [info] \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)",
    "2025-11-25T22:45:42.6985654Z [info] \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)",
    "2025-11-25T22:45:42.6986059Z [info] \tat org.apache.spark.scheduler.Task.run(Task.scala:147)",
    "2025-11-25T22:45:42.6986469Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)",
    "2025-11-25T22:45:42.6986929Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)",
    "2025-11-25T22:45:42.6987380Z [info] \tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)",
    "2025-11-25T22:45:42.6987820Z [info] \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)",
    "2025-11-25T22:45:42.6988312Z [info] \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)",
    "2025-11-25T22:45:42.6988756Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)",
    "2025-11-25T22:45:42.6989229Z [info] \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)",
    "2025-11-25T22:45:42.6989622Z [info] \tat java.base/java.lang.Thread.run(Thread.java:840)",
    "2025-11-25T22:45:42.6989894Z [info] ",
    "2025-11-25T22:45:42.6990148Z [info] Driver stacktrace:",
    "2025-11-25T22:45:42.6990508Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:42.6990994Z [info]   at scala.Option.getOrElse(Option.scala:201)",
    "2025-11-25T22:45:42.6991492Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)",
    "2025-11-25T22:45:42.7011488Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:42.7012116Z [info]   at scala.collection.immutable.List.foreach(List.scala:334)",
    "2025-11-25T22:45:42.7012561Z [info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)",
    "2025-11-25T22:45:42.7013030Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:42.7013548Z [info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:42.7014171Z [info]   at scala.Option.foreach(Option.scala:437)",
    "2025-11-25T22:45:42.7014578Z [info]   at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)",
    "2025-11-25T22:45:42.7016218Z [info]   ...",
    "2025-11-25T22:45:42.7016601Z [info]   Cause: scala.MatchError: [ArraySeq(7, 8, 3),ArraySeq(8.0, 6.0)] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)",
    "2025-11-25T22:45:42.7017138Z [info]   at com.microsoft.azure.synapse.ml.recommendation.RankingEvaluator.$anonfun$getMetrics$1(RankingEvaluator.scala:136)",
    "2025-11-25T22:45:42.7017600Z [info]   at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)",
    "2025-11-25T22:45:42.7018018Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:234)",
    "2025-11-25T22:45:42.7018677Z [info]   at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:319)",
    "2025-11-25T22:45:42.7019144Z [info]   at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1634)",
    "2025-11-25T22:45:42.7019644Z [info]   at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1560)",
    "2025-11-25T22:45:42.7020145Z [info]   at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1625)",
    "2025-11-25T22:45:42.7020586Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1424)",
    "2025-11-25T22:45:42.7021050Z [info]   at org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1378)",
    "2025-11-25T22:45:42.7021462Z [info]   at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:386)",
    "2025-11-25T22:45:42.7021757Z [info]   ...",
    "2025-11-25T22:45:42.7022023Z [info] + Test testALS took 3.336s ",
    "2025-11-25T22:45:42.7085328Z 25/11/25 22:45:42 WARN CacheManager: Asked to cache already cached data.",
    "2025-11-25T22:45:42.7341576Z [info] RecommendationIndexerModelSpec:",
    "2025-11-25T22:45:45.4548445Z [info] - Serialization Fuzzing",
    "2025-11-25T22:45:45.4549728Z [info] + Test Serialization Fuzzing took 2.758s ",
    "2025-11-25T22:45:45.7861356Z [info] - Experiment Fuzzing",
    "2025-11-25T22:45:45.7866915Z [info] + Test Experiment Fuzzing took 0.329s ",
    "2025-11-25T22:45:46.1274942Z Testing parameter itemIndexModel",
    "2025-11-25T22:45:46.1275989Z Testing parameter itemInputCol",
    "2025-11-25T22:45:46.1276391Z Testing parameter itemOutputCol",
    "2025-11-25T22:45:46.1276756Z Testing parameter ratingCol",
    "2025-11-25T22:45:46.1280897Z Testing parameter userIndexModel",
    "2025-11-25T22:45:46.1283701Z Testing parameter userInputCol",
    "2025-11-25T22:45:46.1297862Z Testing parameter userOutputCol",
    "2025-11-25T22:45:46.1300829Z [info] - Getters and Setters work as anticipated",
    "2025-11-25T22:45:46.1310593Z [info] + Test Getters and Setters work as anticipated took 0.346s ",
    "2025-11-25T22:45:46.1355808Z Info Provided - Suite RecommendationIndexerModelSpec took 3.433s",
    "2025-11-25T22:45:46.4770105Z [info] Run completed in 2 minutes, 20 seconds.",
    "2025-11-25T22:45:46.4791396Z [info] Total number of tests run: 40",
    "2025-11-25T22:45:46.4792642Z [info] Suites: completed 9, aborted 0",
    "2025-11-25T22:45:46.4793270Z [info] Tests: succeeded 28, failed 12, canceled 0, ignored 0, pending 0",
    "2025-11-25T22:45:46.4793600Z [info] *** 12 TESTS FAILED ***",
    "2025-11-25T22:45:46.4807983Z [error] Failed tests:",
    "2025-11-25T22:45:46.4820677Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RankingEvaluatorSpec",
    "2025-11-25T22:45:46.4821353Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitModelSpec",
    "2025-11-25T22:45:46.4821830Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.SARSpec",
    "2025-11-25T22:45:46.4822294Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RecommendationIndexerSpec",
    "2025-11-25T22:45:46.4822762Z [error] \tcom.microsoft.azure.synapse.ml.recommendation.RankingTrainValidationSplitSpec",
    "2025-11-25T22:45:46.4853705Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:45:46.4854313Z [info] No tests to run for opencv / Test / testOnly",
    "2025-11-25T22:45:46.4854733Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:45:46.4855387Z [info] No tests to run for cognitive / Test / testOnly",
    "2025-11-25T22:45:46.4858865Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:45:46.4859252Z [info] No tests to run for vw / Test / testOnly",
    "2025-11-25T22:45:46.4859552Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:45:46.4859974Z [info] No tests to run for deepLearning / Test / testOnly",
    "2025-11-25T22:45:46.4876175Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:45:46.4876814Z [info] No tests to run for Test / testOnly",
    "2025-11-25T22:45:46.4877222Z [info] Passed: Total 0, Failed 0, Errors 0, Passed 0",
    "2025-11-25T22:45:46.4877613Z [info] No tests to run for lightgbm / Test / testOnly",
    "2025-11-25T22:45:46.5462262Z [error] (core / Test / testOnly) sbt.TestsFailedException: Tests unsuccessful",
    "2025-11-25T22:45:46.5554683Z [error] Total time: 149 s (0:02:29.0), completed Nov 25, 2025, 10:45:46 PM",
    "2025-11-25T22:45:46.9490271Z ",
    "2025-11-25T22:45:46.9517625Z ##[error]Script failed with exit code: 1",
    "2025-11-25T22:45:46.9527630Z [command]/opt/hostedtoolcache/Python/3.8.18/x64/bin/az account clear",
    "2025-11-25T22:45:47.5952373Z ##[section]Finishing: Unit Test"
  ]
}
